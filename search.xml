<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>mongodb 高可用集群</title>
      <link href="/2020-04-23-mongodb%E5%AE%B9%E5%99%A8%E5%8C%96%E6%96%B9%E6%A1%88/"/>
      <url>/2020-04-23-mongodb%E5%AE%B9%E5%99%A8%E5%8C%96%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Kubernetes部署Mongodb高可用集群"><a href="#Kubernetes部署Mongodb高可用集群" class="headerlink" title="Kubernetes部署Mongodb高可用集群"></a>Kubernetes部署Mongodb高可用集群</h1><h2 id="Mongo介绍"><a href="#Mongo介绍" class="headerlink" title="Mongo介绍"></a>Mongo介绍</h2><p>Mongodb是时下流行的NoSql数据库，它的存储方式是文档式存储，并不是Key-Value形式。关于Mongodb的特点，这里就不多介绍了，大家查看<a href="http://docs.mongodb.org/manual/" target="_blank" rel="external nofollow noopener noreferrer">官方说明</a>。</p><h2 id="Mongodb高可用集群方案介绍"><a href="#Mongodb高可用集群方案介绍" class="headerlink" title="Mongodb高可用集群方案介绍"></a>Mongodb高可用集群方案介绍</h2><h3 id="Replica-set-模式"><a href="#Replica-set-模式" class="headerlink" title="Replica set 模式"></a>Replica set 模式</h3><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-8b0665137347d64a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="mongo_replica_set.png"></p><p>如上图所示是mongodb 的 Replica Set集群模式，主备节点存储数据，仲裁节点不存储数据。客户端同时连接主节点与备节点，不连接仲裁节点。</p><p>默认设置下，主节点提供所有增删查改服务，备节点不提供任何服务。但是可以通过设置使备节点提供查询服务，这样就可以减少主节点的压力，当客户端进行数据查询时，请求自动转到备节点上。这个设置叫做Read Preference Modes，同时客户端提供了简单的配置方式，可以不必直接对数据库进行操作。</p><p>仲裁节点是一种特殊的节点，它本身并不存储数据，主要的作用是决定哪一个备节点在主节点挂掉之后提升为主节点，所以客户端不需要连接此节点。这里虽然只有一个备节点，但是仍然需要一个仲裁节点来提升备节点级别。</p><p>Mongodb的Replica Set即副本集方式主要有两个目的，一个是数据冗余做故障恢复使用，当发生硬件故障或者其它原因造成的宕机时，可以使用副本进行恢复。另一个是做读写分离，读的请求分流到副本上，减轻主（Primary）的读压力。</p><h3 id="Master-Slaver-模式"><a href="#Master-Slaver-模式" class="headerlink" title="Master-Slaver 模式"></a>Master-Slaver 模式</h3><p>这个是最简答的集群搭建，不过准确说也不能算是集群，只能说是主备。并且官方已经不推荐这种方式。</p><h3 id="Sharding-模式"><a href="#Sharding-模式" class="headerlink" title="Sharding 模式"></a>Sharding 模式</h3><p>sharding模式最为完备，和Replica Set类似，都需要一个仲裁节点，但是Sharding还需要配置节点和路由节点。就三种集群搭建方式来说，这种是最复杂的。</p><h2 id="Mongodb-Kubernetes-部署-Replica-set-模式"><a href="#Mongodb-Kubernetes-部署-Replica-set-模式" class="headerlink" title="Mongodb Kubernetes 部署(Replica set 模式)"></a>Mongodb Kubernetes 部署(Replica set 模式)</h2><p><strong>注：</strong> 部署MongoDB主要用到的是mongo-db-sidecar。来设置replica set集群模式。</p><h3 id="创建headless-service"><a href="#创建headless-service" class="headerlink" title="创建headless service"></a>创建headless service</h3><pre><code>apiVersion: v1kind: Servicemetadata:  name: mongo  labels:    app: mongospec:  ports:    - name: mongo      port: 27017      targetPort: 27017  clusterIP: None  selector:    app: mongo</code></pre><h3 id="创建StorageClass"><a href="#创建StorageClass" class="headerlink" title="创建StorageClass"></a>创建StorageClass</h3><pre><code>apiVersion: storage.k8s.io/v1kind: StorageClassmetadata:  name: mongodb-dataprovisioner: fuseim.pri/ifs</code></pre><h3 id="创建Statefulset"><a href="#创建Statefulset" class="headerlink" title="创建Statefulset"></a>创建Statefulset</h3><pre><code>apiVersion: apps/v1beta1kind: StatefulSetmetadata:  name: mongospec:  selector:    matchLabels:      app: mongo  serviceName: &quot;mongo&quot;  replicas: 3  template:    metadata:      labels:        app: mongo        role: mongo        environment: prod    spec:      terminationGracePeriodSeconds: 10      containers:        - name: mongo          image: 10.19.85.58:6666/mongo:latest          command:            - mongod            - &quot;--replSet&quot;            - rs0            - &quot;--smallfiles&quot;            - &quot;--noprealloc&quot;          ports:            - containerPort: 27017          volumeMounts:            - name: mongo-persistent-storage              mountPath: /data/db        - name: mongo-sidecar          image: 10.19.85.58:6666/mongo-k8s-sidecar:latest          env:            - name: MONGO_SIDECAR_POD_LABELS              value: &quot;role=mongo,environment=prod&quot;          resources:            limits:              memory: &quot;{{ .ContainerMemory }}Gi&quot;              cpu: &quot;{{ .ContainerCPU }}&quot;  volumeClaimTemplates:  - metadata:      name: mongo-persistent-storage    spec:      accessModes: [&quot;ReadWriteOnce&quot;]      storageClassName: mongodb-data      resources:        requests:          storage: 10Gi</code></pre><h3 id="创建并查看以上服务"><a href="#创建并查看以上服务" class="headerlink" title="创建并查看以上服务"></a>创建并查看以上服务</h3><p><strong>查看service服务</strong></p><pre><code># kubectl get service  -n mongoNAME            CLUSTER-IP      EXTERNAL-IP   PORT(S)           AGEmongo           None            &lt;none&gt;        27017/TCP         2m</code></pre><p><strong>查看mongo服务</strong></p><pre><code># kubectl get pod -n mongoNAME        READY     STATUS    RESTARTS   AGEmongo-0     2/2       Running   0          2mmongo-1     2/2       Running   2          2mmongo-2     2/2       Running   0          2m </code></pre><p><strong>查看集群状态</strong></p><pre><code>#kubectl exec -it mongo-0  -- mongo -n mongo2020-04-24T11:17:33.030+0000 I CONTROL  [initandlisten] 2020-04-24T11:17:33.030+0000 I CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.2020-04-24T11:17:33.030+0000 I CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.2020-04-24T11:17:33.030+0000 I CONTROL  [initandlisten] ** WARNING: You are running this process as the root user, which is not recommended.2020-04-24T11:17:33.030+0000 I CONTROL  [initandlisten] 2020-04-24T11:17:34.040+0000 I CONTROL  [initandlisten] 2020-04-24T11:17:34.040+0000 I CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is &apos;always&apos;.2020-04-24T11:17:34.040+0000 I CONTROL  [initandlisten] **        We suggest setting it to &apos;never&apos;2020-04-24T11:17:34.040+0000 I CONTROL  [initandlisten] 2020-04-24T11:17:34.040+0000 I CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/defrag is &apos;always&apos;.2020-04-24T11:17:34.040+0000 I CONTROL  [initandlisten] **        We suggest setting it to &apos;never&apos;2020-04-24T11:17:34.040+0000 I CONTROL  [initandlisten] &gt; rs.status(){        &quot;info&quot; : &quot;run rs.initiate(...) if not yet done for the set&quot;,        &quot;ok&quot; : 0,        &quot;errmsg&quot; : &quot;no replset config has been received&quot;,        &quot;code&quot; : 94,        &quot;codeName&quot; : &quot;NotYetInitialized&quot;}</code></pre><p>结果显示集群状态不可以，没有组建成集群。</p><p>查看日志结果如下：</p><pre><code>#kubectl logs mongo-0 mongo-sidecar -n mongo...Error in workloop { [Error: [object Object]]message:{ kind: &apos;Status&apos;,    apiVersion: &apos;v1&apos;,    metadata: {},    status: &apos;Failure&apos;,    message:    &apos;pods is forbidden: User &quot;system:serviceaccount:mongo:default&quot; cannot list resource &quot;pods&quot; in API group &quot;&quot; at the cluster scope&apos;,    reason: &apos;Forbidden&apos;,    details: { kind: &apos;pods&apos; },    code: 403 },statusCode: 403 }</code></pre><p>日志信息显示默认分配的sa账号没有list此namespace下pods的权限。</p><p><strong>namespace 权限问题解决方案</strong></p><p>对默认的clusterrole view权限进行赋权，我们可以使用clusterrole对sa特定namespace进行赋权，如下ClusterRoleBinding yaml方案：</p><pre><code>apiVersion: v1kind: ClusterRoleBindingmetadata:  name: viewroleRef:  name: viewsubjects:- kind: ServiceAccount  name: default  namespace: mongouserNames:- system:serviceaccount:mongo:default</code></pre><p>添加完该namespace权限之后，再次进行查看。</p><pre><code>kubectl exec -it mongo-0  -- mongo -n mongo...rs0:PRIMARY&gt; rs.status(){        &quot;set&quot; : &quot;rs0&quot;,        &quot;date&quot; : ISODate(&quot;2020-04-23T03:30:31.502Z&quot;),        &quot;myState&quot; : 1,        &quot;term&quot; : NumberLong(3),        &quot;syncingTo&quot; : &quot;&quot;,        &quot;syncSourceHost&quot; : &quot;&quot;,        &quot;syncSourceId&quot; : -1,        &quot;heartbeatIntervalMillis&quot; : NumberLong(2000),        &quot;majorityVoteCount&quot; : 2,        &quot;writeMajorityCount&quot; : 2,        &quot;optimes&quot; : {                &quot;lastCommittedOpTime&quot; : {                        &quot;ts&quot; : Timestamp(1587612621, 1),                        &quot;t&quot; : NumberLong(3)                },                &quot;lastCommittedWallTime&quot; : ISODate(&quot;2020-04-23T03:30:21.699Z&quot;),                &quot;readConcernMajorityOpTime&quot; : {                        &quot;ts&quot; : Timestamp(1587612621, 1),                        &quot;t&quot; : NumberLong(3)                },                &quot;readConcernMajorityWallTime&quot; : ISODate(&quot;2020-04-23T03:30:21.699Z&quot;),                &quot;appliedOpTime&quot; : {                        &quot;ts&quot; : Timestamp(1587612621, 1),                        &quot;t&quot; : NumberLong(3)                },                &quot;durableOpTime&quot; : {                        &quot;ts&quot; : Timestamp(1587612621, 1),                        &quot;t&quot; : NumberLong(3)                },                &quot;lastAppliedWallTime&quot; : ISODate(&quot;2020-04-23T03:30:21.699Z&quot;),                &quot;lastDurableWallTime&quot; : ISODate(&quot;2020-04-23T03:30:21.699Z&quot;)        },        &quot;lastStableRecoveryTimestamp&quot; : Timestamp(1587612591, 1),        &quot;lastStableCheckpointTimestamp&quot; : Timestamp(1587612591, 1),        &quot;electionCandidateMetrics&quot; : {                &quot;lastElectionReason&quot; : &quot;electionTimeout&quot;,                &quot;lastElectionDate&quot; : ISODate(&quot;2020-04-22T10:42:49.199Z&quot;),                &quot;electionTerm&quot; : NumberLong(3),                &quot;lastCommittedOpTimeAtElection&quot; : {                        &quot;ts&quot; : Timestamp(1587552113, 1),                        &quot;t&quot; : NumberLong(1)                },                &quot;lastSeenOpTimeAtElection&quot; : {                        &quot;ts&quot; : Timestamp(1587552113, 1),                        &quot;t&quot; : NumberLong(1)                },                &quot;numVotesNeeded&quot; : 2,                &quot;priorityAtElection&quot; : 1,                &quot;electionTimeoutMillis&quot; : NumberLong(10000),                &quot;numCatchUpOps&quot; : NumberLong(0),                &quot;newTermStartDate&quot; : ISODate(&quot;2020-04-22T10:42:49.910Z&quot;),                &quot;wMajorityWriteAvailabilityDate&quot; : ISODate(&quot;2020-04-22T10:42:50.777Z&quot;)        },        &quot;members&quot; : [                {                        &quot;_id&quot; : 0,                        &quot;name&quot; : &quot;171.248.3.105:27017&quot;,                        &quot;health&quot; : 1,                        &quot;state&quot; : 2,                        &quot;stateStr&quot; : &quot;SECONDARY&quot;,                        &quot;uptime&quot; : 2012,                        &quot;optime&quot; : {                                &quot;ts&quot; : Timestamp(1587612621, 1),                                &quot;t&quot; : NumberLong(3)                        },                        &quot;optimeDurable&quot; : {                                &quot;ts&quot; : Timestamp(1587612621, 1),                                &quot;t&quot; : NumberLong(3)                        },                        &quot;optimeDate&quot; : ISODate(&quot;2020-04-23T03:30:21Z&quot;),                        &quot;optimeDurableDate&quot; : ISODate(&quot;2020-04-23T03:30:21Z&quot;),                        &quot;lastHeartbeat&quot; : ISODate(&quot;2020-04-23T03:30:29.622Z&quot;),                        &quot;lastHeartbeatRecv&quot; : ISODate(&quot;2020-04-23T03:30:29.622Z&quot;),                        &quot;pingMs&quot; : NumberLong(0),                        &quot;lastHeartbeatMessage&quot; : &quot;&quot;,                        &quot;syncingTo&quot; : &quot;171.248.1.86:27017&quot;,                        &quot;syncSourceHost&quot; : &quot;171.248.1.86:27017&quot;,                        &quot;syncSourceId&quot; : 2,                        &quot;infoMessage&quot; : &quot;&quot;,                        &quot;configVersion&quot; : 143974                },                {                        &quot;_id&quot; : 1,                        &quot;name&quot; : &quot;171.248.2.3:27017&quot;,                        &quot;health&quot; : 1,                        &quot;state&quot; : 2,                        &quot;stateStr&quot; : &quot;SECONDARY&quot;,                        &quot;uptime&quot; : 60495,                        &quot;optime&quot; : {                                &quot;ts&quot; : Timestamp(1587612621, 1),                                &quot;t&quot; : NumberLong(3)                        },                        &quot;optimeDurable&quot; : {                                &quot;ts&quot; : Timestamp(1587612621, 1),                                &quot;t&quot; : NumberLong(3)                        },                        &quot;optimeDate&quot; : ISODate(&quot;2020-04-23T03:30:21Z&quot;),                        &quot;optimeDurableDate&quot; : ISODate(&quot;2020-04-23T03:30:21Z&quot;),                        &quot;lastHeartbeat&quot; : ISODate(&quot;2020-04-23T03:30:31.410Z&quot;),                        &quot;lastHeartbeatRecv&quot; : ISODate(&quot;2020-04-23T03:30:31.408Z&quot;),                        &quot;pingMs&quot; : NumberLong(0),                        &quot;lastHeartbeatMessage&quot; : &quot;&quot;,                        &quot;syncingTo&quot; : &quot;171.248.1.86:27017&quot;,                        &quot;syncSourceHost&quot; : &quot;171.248.1.86:27017&quot;,                        &quot;syncSourceId&quot; : 2,                        &quot;infoMessage&quot; : &quot;&quot;,                        &quot;configVersion&quot; : 143974                },                {                        &quot;_id&quot; : 2,                        &quot;name&quot; : &quot;171.248.1.86:27017&quot;,                        &quot;health&quot; : 1,                        &quot;state&quot; : 1,                        &quot;stateStr&quot; : &quot;PRIMARY&quot;,                        &quot;uptime&quot; : 60503,                        &quot;optime&quot; : {                                &quot;ts&quot; : Timestamp(1587612621, 1),                                &quot;t&quot; : NumberLong(3)                        },                        &quot;optimeDate&quot; : ISODate(&quot;2020-04-23T03:30:21Z&quot;),                        &quot;syncingTo&quot; : &quot;&quot;,                        &quot;syncSourceHost&quot; : &quot;&quot;,                        &quot;syncSourceId&quot; : -1,                        &quot;infoMessage&quot; : &quot;&quot;,                        &quot;electionTime&quot; : Timestamp(1587552169, 1),                        &quot;electionDate&quot; : ISODate(&quot;2020-04-22T10:42:49Z&quot;),                        &quot;configVersion&quot; : 143974,                        &quot;self&quot; : true,                        &quot;lastHeartbeatMessage&quot; : &quot;&quot;                }        ],        &quot;ok&quot; : 1,        &quot;$clusterTime&quot; : {                &quot;clusterTime&quot; : Timestamp(1587612621, 1),                &quot;signature&quot; : {                        &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;),                        &quot;keyId&quot; : NumberLong(0)                }        },        &quot;operationTime&quot; : Timestamp(1587612621, 1)}</code></pre><p>此时集群状态显示正常节点同步信息也正常。</p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Kubernetes 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mongodb </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang 垃圾回收机制介绍</title>
      <link href="/2020-04-21-Golang_garbage_receive/"/>
      <url>/2020-04-21-Golang_garbage_receive/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Golang垃圾回收机制"><a href="#Golang垃圾回收机制" class="headerlink" title="Golang垃圾回收机制"></a>Golang垃圾回收机制</h1><h2 id="常见的垃圾回收机制"><a href="#常见的垃圾回收机制" class="headerlink" title="常见的垃圾回收机制"></a>常见的垃圾回收机制</h2><h2 id="Go中的垃圾回收机制"><a href="#Go中的垃圾回收机制" class="headerlink" title="Go中的垃圾回收机制"></a>Go中的垃圾回收机制</h2>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Golang 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang range 的坑</title>
      <link href="/2020-04-14-Golang-range/"/>
      <url>/2020-04-14-Golang-range/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Golang-range-的坑"><a href="#Golang-range-的坑" class="headerlink" title="Golang range 的坑"></a>Golang range 的坑</h1><p>使用 Go 语言经常会犯的错误比如当我们在遍历一个数组时，如果获取 range 返回变量的地址并保存到另一个数组或者哈希时，就会遇到令人困惑的现象：</p><h2 id="错误示例"><a href="#错误示例" class="headerlink" title="错误示例"></a>错误示例</h2><pre><code>package mainimport (    &quot;fmt&quot;)func main() {    arr := []int{1, 2, 3}    newArr := []*int{}    for _, v := range arr {        newArr = append(newArr, &amp;v)    }    for _, v := range newArr {        fmt.Println(*v)    }}</code></pre><p><strong>输出</strong></p><pre><code>333</code></pre><p><strong>原因</strong></p><p>对于所有的 range 循环，Go 语言都会在编译期将原切片或者数组赋值给一个新的变量 ha，在赋值的过程中就发生了拷贝，所以我们遍历的切片已经不是原始的切片变量了。</p><p>而遇到这种同时遍历索引和元素的 range 循环时，Go 语言会额外创建一个新的 v2 变量存储切片中的元素，循环中使用的这个变量 v2 会在每一次迭代被重新赋值而覆盖，在赋值时也发生了拷贝。</p><h2 id="正确示例"><a href="#正确示例" class="headerlink" title="正确示例"></a>正确示例</h2><pre><code>package mainimport (    &quot;fmt&quot;)func main() {    arr := []int{1, 2, 3}    newArr := []*int{}    for i, _ := range arr {        newArr = append(newArr, &amp;arr[i])    }    for _, v := range newArr {        fmt.Println(*v)    }}</code></pre><p><strong>输出</strong></p><pre><code>123</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Golang 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes(十三)之Service资源对象</title>
      <link href="/2020-04-13-Kubernetes(%E5%8D%81%E4%B8%89)%E4%B9%8BService%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1/"/>
      <url>/2020-04-13-Kubernetes(%E5%8D%81%E4%B8%89)%E4%B9%8BService%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Service资源对象"><a href="#Service资源对象" class="headerlink" title="Service资源对象"></a>Service资源对象</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>在生产环境中，我们不能期望Pod一直是健壮的。假设Pod的容器很可能因为各种原因发送故障而挂掉。Deployment等Controller会通过动态创建和销毁Pod来保证应用整体的健壮性。</p><p>在创建的每个Pod中，都有自己的IP地址，当Controller用新Pod替代发生故障的Pod时，新Pod会分配到新的IP地址。那么这样就产生一个问题，如果在Pod是对外提供服务的，如HTTP服务，它们在重新创建时，IP地址也就发生了变化，那么客户如何找到并访问这个服务呢？此时Kubernetes就会有了Service。</p><p>Service是一个抽象概念，定义了一个服务的多个pod逻辑合集和访问pod的策略，一般把Service称为微服务。借助 Service，应用可以方便的实现服务发现与负载均衡，并实现应用的零宕机升级。Service 通过标签来选取服务后端，一般配合 Replication Controller 或者 Deployment 来保证后端容器的正常运行。这些匹配标签的 Pod IP 和端口列表组成 endpoints，由 kube-proxy 负责将服务 IP 负载均衡到这些 endpoints 上。</p><h2 id="Service类型—发布服务"><a href="#Service类型—发布服务" class="headerlink" title="Service类型—发布服务"></a>Service类型—发布服务</h2><ul><li><strong>ClusterIP：</strong> 默认类型，自动分配一个仅 cluster 内部可以访问的虚拟 IP。</li><li><strong>NodePort：</strong> 在 ClusterIP 基础上为 Service 在每台机器上绑定一个端口，这样就可以通过 NodeIP:NodePort 来访问该服务。如果 kube-proxy 设置了 – - nodeport-addresses=10.240.0.0/16（v1.10 支持），那么仅该 NodePort 仅对设置在范围内的 IP 有效。</li><li><strong>LoadBalancer：</strong> 在 NodePort 的基础上，借助 cloud provider 创建一个外部的负载均衡器，并将请求转发到 :NodePort</li><li><strong>ExternalName：</strong> 将服务通过 DNS CNAME 记录方式转发到指定的域名（通过 spec.externlName 设定）。需要 kube-dns 版本在 1.7 以上。</li></ul><h2 id="网络代理模式"><a href="#网络代理模式" class="headerlink" title="网络代理模式"></a>网络代理模式</h2><ul><li><p><strong>userspace</strong> ：client先请求serviceip，经由iptables转发到kube-proxy上之后再转发到pod上去。这种方式效率比较低。</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://d33wubrfki0l68.cloudfront.net/e351b830334b8622a700a8da6568cb081c464a9b/13020/images/docs/services-userspace-overview.svg"  alt="userspace.jpg"></p></li><li><p><strong>iptables</strong> ：lient请求serviceip后会直接转发到pod上。这种模式性能会高很多。kube-proxy就会负责将pod地址生成在node节点iptables规则中。</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://d33wubrfki0l68.cloudfront.net/27b2978647a8d7bdc2a96b213f0c0d3242ef9ce0/e8c9b/images/docs/services-iptables-overview.svg"  alt="iptables.jpg"></p></li><li><p><strong>ipvs</strong> ：它是直接有内核中的ipvs规则来接受Client Pod请求，并处理该请求,再有内核封包后，直接发给指定的Server Pod。</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://d33wubrfki0l68.cloudfront.net/2d3d2b521cf7f9ff83238218dac1c019c270b1ed/9ac5c/images/docs/services-ipvs-overview.svg"  alt="ipvs.jpg"></p></li></ul><p><strong>注：</strong></p><p>　以上不论哪种，kube-proxy都通过watch的方式监控着kube-APIServer写入etcd中关于Pod的最新状态信息,它一旦检查到一个Pod资源被删除了或新建，它立即将这些变化，反应在iptables 或 ipvs规则中，以便iptables和ipvs在调度Clinet Pod请求到Server Pod时，不会出现Server Pod不存在的情况。</p><h2 id="创建服务"><a href="#创建服务" class="headerlink" title="创建服务"></a>创建服务</h2><pre><code>apiVersion: v1kind: Servicemetadata:  name: &quot;maxscale&quot;  labels:    mariadb: &quot;mariadb&quot;    entrypoint.mariadb: &quot;mariadb&quot;spec:  type: NodePort  ports:    - name: maxscale-readwrite      port: 4006      targetPort: 4006      nodePort: 31783    - name: maxscale-readonly      port: 4008      targetPort: 4008  selector:    maxscale.mariadb: &quot;mariadb&quot;</code></pre><h3 id="yaml说明："><a href="#yaml说明：" class="headerlink" title="yaml说明："></a>yaml说明：</h3><ul><li><strong>selector：</strong> 指定了为哪一个标签的app进行负载均衡。</li><li><strong>nodePort：</strong> 节点数监听的端口。</li><li><strong>targetPort:</strong> Pod监听的端口。</li></ul><h2 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h2><h3 id="headless-service-无头service"><a href="#headless-service-无头service" class="headerlink" title="headless service(无头service)"></a>headless service(无头service)</h3><p><strong>headless service:</strong> 没有ClusterIP的service, 它仅有一个service name.这个服务名解析得到的不是service的集群IP，而是Pod的IP,当其它人访问该service时，将直接获得Pod的IP,进行直接访问。</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><pre><code>apiVersion: v1kind: Servicemetadata:  labels:    app: &quot;es-cluster-discovery&quot;  name: &quot;es-cluster-discovery&quot;spec:  selector:    app: &quot;es-node-instanceid&quot;  ports:    - port: 9300      name: discovery      targetPort: 9300</code></pre><p>以上es-cluster-discovery服务是用作es集群通过9300来发现其他待加入节点的Pod IP。es的“DISCOVERY_ZEN_PING_UNICAST_HOSTS”参数是待加入集群节点列表，此时可以将”es-cluster-discovery”作为该参数的值，进行解析，直接获取到Pod的Ip。具体详见 <a href="https://www.frederickhou.com/2020/03/24/Elasticsearch-(%E4%B8%89)%E5%AE%B9%E5%99%A8%E5%8C%96%E6%96%B9%E6%A1%88/">Elasticsearch容器化</a>。</p><p>参考：<a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/" target="_blank" rel="external nofollow noopener noreferrer">https://kubernetes.io/zh/docs/concepts/services-networking/service/</a></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Kubernetes 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang select介绍</title>
      <link href="/2020-04-14-Golang-select/"/>
      <url>/2020-04-14-Golang-select/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Golang-select"><a href="#Golang-select" class="headerlink" title="Golang select"></a>Golang select</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Go 语言中的 <strong>select</strong> 关键字也能够让 Goroutine 同时等待多个 Channel 的可读或者可写，在多个文件或者 Channel 发生状态改变之前，select 会一直阻塞当前线程或者 Goroutine。</p><p>select 是一种与 switch 相似的控制结构，与 switch 不同的是，select 中虽然也有多个 case，但是这些 case 中的表达式<strong>必须都是 Channel 的收发操作</strong>。</p><h2 id="示例1"><a href="#示例1" class="headerlink" title="示例1"></a>示例1</h2><pre><code>package mainimport (    &quot;fmt&quot;    &quot;time&quot;)func test(consumer1, consumer2,consumer3 chan int,startTime time.Time) {    fmt.Println(&quot;Blocking on read...&quot;)    select {        case &lt;- consumer1:            fmt.Printf(&quot;Unblocked %v later.\n&quot;, time.Since(startTime))        case &lt;- consumer2:            fmt.Printf(&quot;ch2 case...&quot;)        case &lt;- consumer3:            fmt.Printf(&quot;ch3 case...&quot;)        default:            fmt.Printf(&quot;default go...&quot;)    }}func main() {    startTime := time.Now()    consumer1 := make(chan int)    consumer2 := make(chan int)    consumer3 := make(chan int)    go func() {        time.Sleep(4*time.Second)        close(consumer1)    }()    go func() {        time.Sleep(3*time.Second)        consumer2 &lt;- 3    }()    go func() {        time.Sleep(3*time.Second)        consumer3 &lt;- 5    }()    test(consumer1, consumer2,consumer3,startTime)}</code></pre><p>输出：</p><pre><code>Blocking on read...default go...</code></pre><p>运行上述代码，由于当前时间还未到3s。所以，目前程序会走default的case。</p><p>修改代码，将default注释:输出：</p><pre><code>Blocking on read...ch3 case...</code></pre><p>这时，select语句会阻塞，直到监测到一个可以执行的IO操作为止。这里，先会执行完睡眠3s的gorountine,此时两个channel(consumer2,consumer3)都满足条件，这时系统会随机选择一个case继续操作。</p><h2 id="现象总结"><a href="#现象总结" class="headerlink" title="现象总结"></a>现象总结</h2><p>通过上面示例，我们发现在 Go 语言中使用 select 控制结构时，会遇到两个有趣的现象：</p><ul><li><ol><li>select 能在 Channel 上进行非阻塞的收发操作(<strong>有default操作时</strong> 直接出发default)；</li></ol></li><li><ol start="2"><li>select 能在 Channel 上进行阻塞的收发操作(<strong>无default操作时</strong> 阻塞等待channel消息)；</li></ol></li><li><ol start="3"><li>select 在遇到多个 Channel 同时响应时会随机挑选 case 执行；</li></ol></li></ul><h2 id="示例2"><a href="#示例2" class="headerlink" title="示例2"></a>示例2</h2><pre><code>package mainimport &quot;fmt&quot;var ch1 chan intvar ch2 chan intvar chs = []chan int{ch1, ch2}var numbers = []int{1, 2, 3, 4, 5}func getNumber(i int) int {    fmt.Printf(&quot;numbers[%d]\n&quot;, i)    return numbers[i]}func getChan(i int) chan int {    fmt.Printf(&quot;chs[%d]\n&quot;, i)    return chs[i]}func main () {    select {    case getChan(0) &lt;- getNumber(2):        fmt.Println(&quot;1th case is selected.&quot;)    case getChan(1) &lt;- getNumber(3):        fmt.Println(&quot;2th case is selected.&quot;)    default:        fmt.Println(&quot;default!.&quot;)        }}</code></pre><p>输出：</p><pre><code>chs[0]numbers[2]chs[1]numbers[3]default!.</code></pre><p>运行上述例子，发现输出select 挨着输出。并且输出了default对应的case。</p><h2 id="现象总结-1"><a href="#现象总结-1" class="headerlink" title="现象总结"></a>现象总结</h2><p>所有channel表达式都会被求值、所有被发送的表达式都会被求值。求值顺序：自上而下、从左到右。</p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Golang 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang 工厂模式</title>
      <link href="/2020-04-11-Golang-factory-model/"/>
      <url>/2020-04-11-Golang-factory-model/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Golang-工厂模式"><a href="#Golang-工厂模式" class="headerlink" title="Golang 工厂模式"></a>Golang 工厂模式</h1><h2 id="简单工厂模式"><a href="#简单工厂模式" class="headerlink" title="简单工厂模式"></a>简单工厂模式</h2><p><strong>简单工厂模式（Simple Factory Pattern）</strong> ：定义一个工厂类，它可以根据参数的不同返回不同类的实例，被创建的实例通常都具有共同的父类。因为在简单工厂模式中用于创建实例的方法是静态（static）方法，因此简单工厂模式又被称为静态工厂方法（Static Factory Method）模式，它属于类创建型模式。</p><h3 id="简单工厂需要"><a href="#简单工厂需要" class="headerlink" title="简单工厂需要:"></a>简单工厂需要:</h3><ul><li>工厂结构体</li><li>产品接口</li><li>产品结构体</li></ul><h3 id="示例说明"><a href="#示例说明" class="headerlink" title="示例说明"></a>示例说明</h3><p>创建一个饺子店工厂结构体，和饺子类的接口。该工厂的其中一个方法用来生产不同口味的饺子，如韭菜的猪肉馅的。</p><pre><code>type DumplingsShop struct{    Generate(t string) *Dumplings}type Dumplingsinterface interface {    create()}</code></pre><p>创建肉馅和韭菜馅的饺子结构体，并且实现对应接口的方法。</p><pre><code>  type DumplingsMeat struct{}  func (* DumplingsMeat)create(){      fmt.Println(&quot;DumplingsMeat create&quot;)  }  type DumplingsChives struct{}  func (* DumplingsChives)create(){      fmt.Println(&quot;DumplingsMeat create&quot;)  }func(* DumplingsShop)Create(type string)*Dumplings{    switch type {        case &quot;meat&quot;:        return new(DumplingsMeat)        case &quot;chives&quot;:        return new(DumplingsChives)        default:        return nil    }}</code></pre><p>工厂实例化调用</p><pre><code>var type stringdumplingFactory := DumplingsShop{}type = &quot;meat&quot;meat := dumplingFactory.Create(type)//返回肉馅饺子对象meat.create()type = &quot;chives&quot;chives := dumplingFactory.Create(type) //返回韭菜馅饺子对象chives.create()</code></pre><h2 id="简单工厂模式优缺点"><a href="#简单工厂模式优缺点" class="headerlink" title="简单工厂模式优缺点"></a>简单工厂模式优缺点</h2><ul><li><p><strong>优点:</strong> 工厂类是整个工厂模式的核心，我们只需要传入给定的信息，就可以创建所需实例，在多人协作的时候，无需知道对象之间的内部依赖，可以直接创建，有利于整个软件体系结构的优化。</p></li><li><p><strong>缺点:</strong> 工厂类中包含了所有实例的创建逻辑，一旦这个工厂类出现问题，所有实例都会受到影响，并且，工厂类中生产的产品都基于一个共同的接口，一旦要添加不同种类的产品，这就会增加工厂类的复杂度，将不同种类的产品混合在一起，违背了单一职责，系统的灵活性和可维护性都会降低，并且当新增产品的时候，必须要修改工厂类，违背了『系统对扩展开放，对修改关闭』的原则。</p></li></ul><h2 id="工厂方法模式"><a href="#工厂方法模式" class="headerlink" title="工厂方法模式"></a>工厂方法模式</h2><p><strong>工厂方法模式（英语：Factory method pattern）</strong> 是一种实现了“工厂”概念的面向对象设计模式。就像其他创建型模式一样，它也是处理在不指定对象具体类型的情况下创建对象的问题。工厂方法模式的实质是“定义一个创建对象的接口，但让实现这个接口的类来决定实例化哪个类。工厂方法让类的实例化推迟到子类中进行。”，实际应用中工厂方法模式针对的是一个产品等级结构。</p><h3 id="工厂方法需要"><a href="#工厂方法需要" class="headerlink" title="工厂方法需要:"></a>工厂方法需要:</h3><ul><li>工厂接口</li><li>工厂结构体</li><li>产品接口</li><li>产品结构体</li></ul><h3 id="示例说明-1"><a href="#示例说明-1" class="headerlink" title="示例说明"></a>示例说明</h3><p>创建一个饺子店工厂接口，和饺子类的接口。该工厂用来生产不同口味的饺子，如韭菜的猪肉馅的。</p><pre><code>type DumplingsShopinterface interface{    Generate(t string) *Dumplings}type Dumplingsinterface interface {    create()}</code></pre><p>创建北京和西安对应馅的饺子结构体，并且实现对应接口的方法。</p><pre><code>type BeijingDumplingsMeat struct{}func (* BeijingDumplingsMeat)create(){    fmt.Println(&quot;BeijingDumplingsMeat create&quot;)}type BeijingDumplingsChives struct{}...type XianDumplingsMeat struct{}...type XianDumplingsChives struct{}...</code></pre><p>创建北京和西安工厂</p><pre><code>type BeijingDumplings struct{}type XianDumplings struct{}func(* BeijingDumplings)Generate(t string) *Dumplings{    switch t {     case &quot;chives&quot; :    return new(BeijingDumplingsChives)     case &quot;meat&quot; :    return new(BeijingDumplingsMeat)     default:    return nil    }}func(* XianDumplings)Generate(t string) *Dumplings{    switch t{}    case &quot;chives&quot; :    return new(XianDumplingsChives)     case &quot;meat&quot; :    return new(XianDumplingsMeat)     default:    return nil}</code></pre><p>工厂实例化调用</p><pre><code>var DumplingsShopFactory DumplingsShopinterfaceDumplingsShopFactory := new(BeijingDumplings)b = DumplingsShopFactory.Generate(&quot;meat&quot;)  // 传入肉馅的参数，会返回北京市的肉馅饺子b.create()DumplingsShopFactory := new(XianDumplings)b = DumplingsShopFactory.Generate(&quot;meat&quot;) // 同样传入肉馅的参数，会返回北京市的肉馅饺子b.create()</code></pre><h3 id="工厂方法模式的优缺点"><a href="#工厂方法模式的优缺点" class="headerlink" title="工厂方法模式的优缺点"></a>工厂方法模式的优缺点</h3><ul><li><p><strong>优点:</strong> 符合“开闭”原则，具有很强的的扩展性、弹性和可维护性。修改时只需要添加对应的工厂类即可使用了依赖倒置原则，依赖抽象而不是具体，使用（客户）和实现（具体类）松耦合。客户只需要知道所需产品的具体工厂，而无须知道具体工厂的创建产品的过程，甚至不需要知道具体产品的类名。</p></li><li><p><strong>缺点:</strong> 每增加一个产品时，都需要一个具体类和一个具体创建者，使得类的个数成倍增加，导致系统类数目过多，复杂性增加对简单工厂，增加功能修改的是工厂类；对工厂方法，增加功能修改的是产品类。</p></li></ul><h2 id="抽象工厂模式"><a href="#抽象工厂模式" class="headerlink" title="抽象工厂模式"></a>抽象工厂模式</h2><p><strong>抽象工厂模式（英语：Abstract factory pattern）</strong> 是一种软件开发设计模式。抽象工厂模式提供了一种方式，可以将一组具有同一主题的单独的工厂封装起来。在正常使用中，客户端程序需要创建抽象工厂的具体实现，然后使用抽象工厂作为接口来创建这一主题的具体对象。客户端程序不需要知道（或关心）它从这些内部的工厂方法中获得对象的具体类型，因为客户端程序仅使用这些对象的通用接口。抽象工厂模式将一组对象的实现细节与他们的一般使用分离开来。实际应用中针对的多个产品等级结构。</p><h2 id="示例说明-2"><a href="#示例说明-2" class="headerlink" title="示例说明"></a>示例说明</h2><p>创建一个肉馅饺子店工厂接口和韭菜馅饺子店工厂接口，以及饺子类的接口。</p><pre><code>type DumplingsShopinterface interface{    GenerateMeatDumpling() *Dumplingsinterface    GenerateChivesDumpling() *Dumplingsinterface}type Dumplingsinterface interface {    create()}</code></pre><p>实现北京肉馅饺子、北京韭菜饺子、西安肉馅饺子、西安韭菜饺子4中实例对象。</p><pre><code>type BeijingDumplingsMeat struct{}func (* BeijingDumplingsMeat)create(){    fmt.Println(&quot;BeijingDumplingsMeat create&quot;)}type BeijingDumplingsChives struct{}...type XianDumplingsMeat struct{}...type XianDumplingsChives struct{}...</code></pre><p>创建北京和西安工厂</p><pre><code>type BeijingDumplingsFactory struct{}type XianDumplingsFactory struct{}func(* BeijingDumplingsFactory)GenerateMeatDumpling() *Dumplings{    return new(BeijingDumplingsMeat)     }}func(* BeijingDumplingsFactory)GenerateChivesDumpling() *Dumplings{    return new(BeijingDumplingsChives)     }}func(* XianDumplingsFactory)GenerateMeatDumpling() *Dumplings{    return new(XianDumplingsMeat)     }}func(* XianDumplingsFactory)GenerateChivesDumpling() *Dumplings{    return new(XianDumplingsChives)     }}</code></pre><p>工厂示例调用</p><pre><code>var DumplingsShopFactory DumplingsShopinterfaceDumplingsShopFactory := new(BeijingDumplingsFactory)b = DumplingsShopFactory.GenerateMeatDumpling()  // 传入肉馅的参数，会返回北京市的肉馅饺子b.create()...</code></pre><h3 id="抽象工厂模式的优缺点"><a href="#抽象工厂模式的优缺点" class="headerlink" title="抽象工厂模式的优缺点"></a>抽象工厂模式的优缺点</h3><ul><li><p><strong>优点:</strong> 抽象工厂模式除了具有工厂方法模式的优点外，最主要的优点就是可以在类的内部对产品族进行约束。所谓的产品族，一般或多或少的都存在一定的关联，抽象工厂模式就可以在类内部对产品族的关联关系进行定义和描述，而不必专门引入一个新的类来进行管理。</p></li><li><p><strong>缺点:</strong> 产品族的扩展将是一件十分费力的事情，假如产品族中需要增加一个新的产品，则几乎所有的工厂类都需要进行修改。所以使用抽象工厂模式时，对产品等级结构的划分是非常重要的</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Golang 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang client-go 源码分析</title>
      <link href="/2020-04-10-Golang-client-go-analysis/"/>
      <url>/2020-04-10-Golang-client-go-analysis/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="client-go-源码分析"><a href="#client-go-源码分析" class="headerlink" title="client-go 源码分析"></a>client-go 源码分析</h1><h2 id="client-go-简介"><a href="#client-go-简介" class="headerlink" title="client-go 简介"></a>client-go 简介</h2><p>client-go是一个调用kubernetes集群资源对象API的客户端，即通过client-go实现对kubernetes集群中资源对象（包括deployment、service、ingress、replicaSet、pod、namespace、node等）的增删改查等操作。大部分对kubernetes进行前置API封装的二次开发都通过client-go这个第三方包来实现。</p><p>​client-go官方文档：<a href="https://github.com/kubernetes/client-go" target="_blank" rel="external nofollow noopener noreferrer">https://github.com/kubernetes/client-go</a></p><h2 id="client-go-源码目录结构"><a href="#client-go-源码目录结构" class="headerlink" title="client-go 源码目录结构"></a>client-go 源码目录结构</h2><ul><li>The <strong>kubernetes</strong> package contains the clientset to access Kubernetes API.</li><li>The <strong>discovery</strong> package is used to discover APIs supported by a Kubernetes API server.</li><li>The <strong>dynamic</strong> package contains a dynamic client that can perform generic operations on arbitrary Kubernetes API objects.</li><li>The <strong>transport</strong> package is used to set up auth and start a connection.</li><li>The <strong>tools/cache</strong> package is useful for writing controllers.</li></ul><h3 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h3><pre><code>#demo.gopackage mainimport (    &quot;flag&quot;    &quot;fmt&quot;    &quot;os&quot;    &quot;path/filepath&quot;    &quot;time&quot;    metav1 &quot;k8s.io/apimachinery/pkg/apis/meta/v1&quot;    &quot;k8s.io/client-go/kubernetes&quot;    &quot;k8s.io/client-go/tools/clientcmd&quot;)func main() {    kubeconfig := ./config    config, err := clientcmd.BuildConfigFromFlags(&quot;&quot;, kubeconfig)    if err != nil {        panic(err.Error())    }    // creates the clientset    clientset, err := kubernetes.NewForConfig(config)    if err != nil {        panic(err.Error())    }    pods, err := clientset.CoreV1().Pods(&quot;&quot;).List(metav1.ListOptions{})    if err != nil {        panic(err.Error())    }    fmt.Printf(&quot;There are %d pods in the cluster\n&quot;, len(pods.Items))}</code></pre><p>client-go库版本</p><pre><code>go get  k8s.io/client-go v0.0.0-20191114101535-6c5935290e33</code></pre><h4 id="kubeconfig"><a href="#kubeconfig" class="headerlink" title="kubeconfig"></a>kubeconfig</h4><p>获取kubernetes配置文件kubeconfig的绝对路径。一般路径为$HOME/.kube/config。该文件主要用来配置本地连接的kubernetes集群。config配置文件支持集群内和集群外访问方式。(只要在网络策略访问范围内)</p><p><strong>config文件形式如下所示：</strong></p><pre><code>apiVersion: v1clusters:- cluster:    certificate-authority-data: { .Certificate-authority-data}    server: https://ip:6443name: kubernetescontexts:- context:    cluster: kubernetes    user: kubernetes-adminname: kubernetes-admin@kubernetescurrent-context: kubernetes-admin@kuberneteskind: Configpreferences: {}users:- name: kubernetes-adminuser:    client-certificate-data: { .Client-certificate-data}    client-key-data: { .Client-key-data}</code></pre><h4 id="rest-config-对象"><a href="#rest-config-对象" class="headerlink" title="rest.config 对象"></a>rest.config 对象</h4><pre><code>config, err := clientcmd.BuildConfigFromFlags(&quot;&quot;, kubeconfig)</code></pre><p>通过参数（master的url或者kubeconfig路径）用BuildConfigFromFlags方法来获取rest.Config对象，一般是通过参数kubeconfig的路径。</p><h3 id="Clientset对象创建"><a href="#Clientset对象创建" class="headerlink" title="Clientset对象创建"></a>Clientset对象创建</h3><pre><code>clientset, err := kubernetes.NewForConfig(config)</code></pre><p>通过config对象为入参，调用NewForConfig函数获取clients对象，clients是多个client的集合。里面包含着各个版本的client。源码地址：k8s.io/client-go/kubernetes/clientset.go</p><pre><code>// NewForConfig creates a new Clientset for the given config.// If config&apos;s RateLimiter is not set and QPS and Burst are acceptable,// NewForConfig will generate a rate-limiter in configShallowCopy.func NewForConfig(c *rest.Config) (*Clientset, error) {    configShallowCopy := *c    if configShallowCopy.RateLimiter == nil &amp;&amp; configShallowCopy.QPS &gt; 0 {        if configShallowCopy.Burst &lt;= 0 {            return nil, fmt.Errorf(&quot;Burst is required to be greater than 0 when RateLimiter is not set and QPS is set to greater than 0&quot;)        }        configShallowCopy.RateLimiter = flowcontrol.NewTokenBucketRateLimiter(configShallowCopy.QPS, configShallowCopy.Burst)    }    var cs Clientset    var err error    cs.admissionregistrationV1, err = admissionregistrationv1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.admissionregistrationV1beta1, err = admissionregistrationv1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.appsV1, err = appsv1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.appsV1beta1, err = appsv1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.appsV1beta2, err = appsv1beta2.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.auditregistrationV1alpha1, err = auditregistrationv1alpha1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.authenticationV1, err = authenticationv1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.authenticationV1beta1, err = authenticationv1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.authorizationV1, err = authorizationv1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.authorizationV1beta1, err = authorizationv1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.autoscalingV1, err = autoscalingv1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.autoscalingV2beta1, err = autoscalingv2beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.autoscalingV2beta2, err = autoscalingv2beta2.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.batchV1, err = batchv1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.batchV1beta1, err = batchv1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.batchV2alpha1, err = batchv2alpha1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.certificatesV1beta1, err = certificatesv1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.coordinationV1beta1, err = coordinationv1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.coordinationV1, err = coordinationv1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    //coreV1 对象创建    cs.coreV1, err = corev1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.discoveryV1alpha1, err = discoveryv1alpha1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.eventsV1beta1, err = eventsv1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.extensionsV1beta1, err = extensionsv1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.networkingV1, err = networkingv1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.networkingV1beta1, err = networkingv1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.nodeV1alpha1, err = nodev1alpha1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.nodeV1beta1, err = nodev1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.policyV1beta1, err = policyv1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.rbacV1, err = rbacv1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.rbacV1beta1, err = rbacv1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.rbacV1alpha1, err = rbacv1alpha1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.schedulingV1alpha1, err = schedulingv1alpha1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.schedulingV1beta1, err = schedulingv1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.schedulingV1, err = schedulingv1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.settingsV1alpha1, err = settingsv1alpha1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.storageV1beta1, err = storagev1beta1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.storageV1, err = storagev1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.storageV1alpha1, err = storagev1alpha1.NewForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    cs.DiscoveryClient, err = discovery.NewDiscoveryClientForConfig(&amp;configShallowCopy)    if err != nil {        return nil, err    }    return &amp;cs, nil}</code></pre><p>NewForConfig函数根据传入的rest.config对象创建一个Clientset对象,此对象可以操作CoreV1()方法。</p><h4 id="Clientset-结构体"><a href="#Clientset-结构体" class="headerlink" title="Clientset 结构体"></a>Clientset 结构体</h4><p><strong>其结构体具体参数如下所示：</strong></p><pre><code>// Clientset contains the clients for groups. Each group has exactly one// version included in a Clientset.type Clientset struct {    *discovery.DiscoveryClient    admissionregistrationV1      *admissionregistrationv1.AdmissionregistrationV1Client    admissionregistrationV1beta1 *admissionregistrationv1beta1.AdmissionregistrationV1beta1Client    appsV1                       *appsv1.AppsV1Client    appsV1beta1                  *appsv1beta1.AppsV1beta1Client    appsV1beta2                  *appsv1beta2.AppsV1beta2Client    auditregistrationV1alpha1    *auditregistrationv1alpha1.AuditregistrationV1alpha1Client    authenticationV1             *authenticationv1.AuthenticationV1Client    authenticationV1beta1        *authenticationv1beta1.AuthenticationV1beta1Client    authorizationV1              *authorizationv1.AuthorizationV1Client    authorizationV1beta1         *authorizationv1beta1.AuthorizationV1beta1Client    autoscalingV1                *autoscalingv1.AutoscalingV1Client    autoscalingV2beta1           *autoscalingv2beta1.AutoscalingV2beta1Client    autoscalingV2beta2           *autoscalingv2beta2.AutoscalingV2beta2Client    batchV1                      *batchv1.BatchV1Client    batchV1beta1                 *batchv1beta1.BatchV1beta1Client    batchV2alpha1                *batchv2alpha1.BatchV2alpha1Client    certificatesV1beta1          *certificatesv1beta1.CertificatesV1beta1Client    coordinationV1beta1          *coordinationv1beta1.CoordinationV1beta1Client    coordinationV1               *coordinationv1.CoordinationV1Client    coreV1                       *corev1.CoreV1Client    discoveryV1alpha1            *discoveryv1alpha1.DiscoveryV1alpha1Client    eventsV1beta1                *eventsv1beta1.EventsV1beta1Client    extensionsV1beta1            *extensionsv1beta1.ExtensionsV1beta1Client    networkingV1                 *networkingv1.NetworkingV1Client    networkingV1beta1            *networkingv1beta1.NetworkingV1beta1Client    nodeV1alpha1                 *nodev1alpha1.NodeV1alpha1Client    nodeV1beta1                  *nodev1beta1.NodeV1beta1Client    policyV1beta1                *policyv1beta1.PolicyV1beta1Client    rbacV1                       *rbacv1.RbacV1Client    rbacV1beta1                  *rbacv1beta1.RbacV1beta1Client    rbacV1alpha1                 *rbacv1alpha1.RbacV1alpha1Client    schedulingV1alpha1           *schedulingv1alpha1.SchedulingV1alpha1Client    schedulingV1beta1            *schedulingv1beta1.SchedulingV1beta1Client    schedulingV1                 *schedulingv1.SchedulingV1Client    settingsV1alpha1             *settingsv1alpha1.SettingsV1alpha1Client    storageV1beta1               *storagev1beta1.StorageV1beta1Client    storageV1                    *storagev1.StorageV1Client    storageV1alpha1              *storagev1alpha1.StorageV1alpha1Client}</code></pre><h4 id="Clientset-实现的接口"><a href="#Clientset-实现的接口" class="headerlink" title="Clientset 实现的接口"></a>Clientset 实现的接口</h4><pre><code>type Interface interface {    Discovery() discovery.DiscoveryInterface    AdmissionregistrationV1() admissionregistrationv1.AdmissionregistrationV1Interface    AdmissionregistrationV1beta1() admissionregistrationv1beta1.AdmissionregistrationV1beta1Interface    AppsV1() appsv1.AppsV1Interface    AppsV1beta1() appsv1beta1.AppsV1beta1Interface    AppsV1beta2() appsv1beta2.AppsV1beta2Interface    AuditregistrationV1alpha1() auditregistrationv1alpha1.AuditregistrationV1alpha1Interface    AuthenticationV1() authenticationv1.AuthenticationV1Interface    AuthenticationV1beta1() authenticationv1beta1.AuthenticationV1beta1Interface    AuthorizationV1() authorizationv1.AuthorizationV1Interface    AuthorizationV1beta1() authorizationv1beta1.AuthorizationV1beta1Interface    AutoscalingV1() autoscalingv1.AutoscalingV1Interface    AutoscalingV2beta1() autoscalingv2beta1.AutoscalingV2beta1Interface    AutoscalingV2beta2() autoscalingv2beta2.AutoscalingV2beta2Interface    BatchV1() batchv1.BatchV1Interface    BatchV1beta1() batchv1beta1.BatchV1beta1Interface    BatchV2alpha1() batchv2alpha1.BatchV2alpha1Interface    CertificatesV1beta1() certificatesv1beta1.CertificatesV1beta1Interface    CoordinationV1beta1() coordinationv1beta1.CoordinationV1beta1Interface    CoordinationV1() coordinationv1.CoordinationV1Interface    CoreV1() corev1.CoreV1Interface    DiscoveryV1alpha1() discoveryv1alpha1.DiscoveryV1alpha1Interface    EventsV1beta1() eventsv1beta1.EventsV1beta1Interface    ExtensionsV1beta1() extensionsv1beta1.ExtensionsV1beta1Interface    NetworkingV1() networkingv1.NetworkingV1Interface    NetworkingV1beta1() networkingv1beta1.NetworkingV1beta1Interface    NodeV1alpha1() nodev1alpha1.NodeV1alpha1Interface    NodeV1beta1() nodev1beta1.NodeV1beta1Interface    PolicyV1beta1() policyv1beta1.PolicyV1beta1Interface    RbacV1() rbacv1.RbacV1Interface    RbacV1beta1() rbacv1beta1.RbacV1beta1Interface    RbacV1alpha1() rbacv1alpha1.RbacV1alpha1Interface    SchedulingV1alpha1() schedulingv1alpha1.SchedulingV1alpha1Interface    SchedulingV1beta1() schedulingv1beta1.SchedulingV1beta1Interface    SchedulingV1() schedulingv1.SchedulingV1Interface    SettingsV1alpha1() settingsv1alpha1.SettingsV1alpha1Interface    StorageV1beta1() storagev1beta1.StorageV1beta1Interface    StorageV1() storagev1.StorageV1Interface    StorageV1alpha1() storagev1alpha1.StorageV1alpha1Interface}</code></pre><p>Clientset结构体实现了以上结构定义的所有方法。源码地址：k8s.io/client-go/kubernetes/clientset.go</p><p>因为Clientset可使用其中任意函数调用，如获取Pod列表。</p><pre><code>pods, err := clientset.CoreV1().Pods(&quot;&quot;).List(metav1.ListOptions{})</code></pre><h3 id="CoreV1Client对象创建"><a href="#CoreV1Client对象创建" class="headerlink" title="CoreV1Client对象创建"></a>CoreV1Client对象创建</h3><p>在创建Clientset对象时，Clientset 中的变量coreV1也被一起初始化创建。即创建了CoreV1Client对象。</p><pre><code>//coreV1 对象创建cs.coreV1, err = corev1.NewForConfig(&amp;configShallowCopy)</code></pre><h4 id="NewForConfig"><a href="#NewForConfig" class="headerlink" title="NewForConfig"></a>NewForConfig</h4><pre><code>// NewForConfig creates a new CoreV1Client for the given config.func NewForConfig(c *rest.Config) (*CoreV1Client, error) {    config := *c    if err := setConfigDefaults(&amp;config); err != nil {        return nil, err    }    client, err := rest.RESTClientFor(&amp;config)    if err != nil {        return nil, err    }    return &amp;CoreV1Client{client}, nil}</code></pre><h4 id="CoreV1Interface"><a href="#CoreV1Interface" class="headerlink" title="CoreV1Interface"></a>CoreV1Interface</h4><p>如下所示：</p><pre><code>type CoreV1Interface interface {    RESTClient() rest.Interface    ComponentStatusesGetter    ConfigMapsGetter    EndpointsGetter    EventsGetter    LimitRangesGetter    NamespacesGetter    NodesGetter    PersistentVolumesGetter    PersistentVolumeClaimsGetter    PodsGetter    PodTemplatesGetter    ReplicationControllersGetter    ResourceQuotasGetter    SecretsGetter    ServicesGetter    ServiceAccountsGetter}</code></pre><p>CoreV1Interface中包含了各种kubernetes对象的调用接口，例如PodsGetter是对kubernetes中pod对象增删改查操作的接口。ServicesGetter是对service对象的操作的接口。</p><h4 id="CoreV1Client-结构体"><a href="#CoreV1Client-结构体" class="headerlink" title="CoreV1Client 结构体"></a>CoreV1Client 结构体</h4><pre><code>type CoreV1Client struct {    restClient rest.Interface}</code></pre><p>CoreV1Client结构体实现了CoreV1Interface所有的定义函数。</p><pre><code>//CoreV1Client的方法func (c *CoreV1Client) ComponentStatuses() ComponentStatusInterface//ConfigMapsfunc (c *CoreV1Client) ConfigMaps(namespace string) ConfigMapInterface//Endpointsfunc (c *CoreV1Client) Endpoints(namespace string) EndpointsInterfacefunc (c *CoreV1Client) Events(namespace string) EventInterfacefunc (c *CoreV1Client) LimitRanges(namespace string) LimitRangeInterface//namespacefunc (c *CoreV1Client) Namespaces() NamespaceInterface //nodesfunc (c *CoreV1Client) Nodes() NodeInterface //pvfunc (c *CoreV1Client) PersistentVolumes() PersistentVolumeInterface //pvcfunc (c *CoreV1Client) PersistentVolumeClaims(namespace string) PersistentVolumeClaimInterface //pods func (c *CoreV1Client) Pods(namespace string) PodInterface func (c *CoreV1Client) PodTemplates(namespace string) PodTemplateInterface //rcfunc (c *CoreV1Client) ReplicationControllers(namespace string) ReplicationControllerInterface func (c *CoreV1Client) ResourceQuotas(namespace string) ResourceQuotaInterface //secretfunc (c *CoreV1Client) Secrets(namespace string) SecretInterface //servicefunc (c *CoreV1Client) Services(namespace string) ServiceInterface func (c *CoreV1Client) ServiceAccounts(namespace string) ServiceAccountInterface </code></pre><h3 id="PodsGetter接口"><a href="#PodsGetter接口" class="headerlink" title="PodsGetter接口"></a>PodsGetter接口</h3><pre><code>type PodsGetter interface {    Pods(namespace string) PodInterface}func (c *CoreV1Client) Pods(namespace string) PodInterface {    return newPods(c, namespace)}</code></pre><p>PodsGetter接口中定义了Pods方法此方法返回PodInterface，这样就可以用Clients.Corev1().Pods()方法对Pod进行增删改查操作了。</p><h3 id="Pod对象创建"><a href="#Pod对象创建" class="headerlink" title="Pod对象创建"></a>Pod对象创建</h3><pre><code>func (c *CoreV1Client) Pods(namespace string) PodInterface {    return newPods(c, namespace)}// newPods returns a Podsfunc newPods(c *CoreV1Client, namespace string) *pods {    return &amp;pods{        client: c.RESTClient(),        ns:     namespace,    }}</code></pre><p>调用Pods方法，再通过newPods函数创建一个Pods的对象。pods对象继承了rest.Interface接口，即最终的实现本质是RESTClient的HTTP调用。</p><h4 id="PodInterface接口"><a href="#PodInterface接口" class="headerlink" title="PodInterface接口"></a>PodInterface接口</h4><pre><code>// PodInterface has methods to work with Pod resources.type PodInterface interface {    Create(*v1.Pod) (*v1.Pod, error)    Update(*v1.Pod) (*v1.Pod, error)    UpdateStatus(*v1.Pod) (*v1.Pod, error)    Delete(name string, options *metav1.DeleteOptions) error    DeleteCollection(options *metav1.DeleteOptions, listOptions metav1.ListOptions) error    Get(name string, options metav1.GetOptions) (*v1.Pod, error)    List(opts metav1.ListOptions) (*v1.PodList, error)    Watch(opts metav1.ListOptions) (watch.Interface, error)    Patch(name string, pt types.PatchType, data []byte, subresources ...string) (result *v1.Pod, err error)    GetEphemeralContainers(podName string, options metav1.GetOptions) (*v1.EphemeralContainers, error)    UpdateEphemeralContainers(podName string, ephemeralContainers *v1.EphemeralContainers) (*v1.EphemeralContainers, error)    PodExpansion}</code></pre><p>PodInterface接口定义了Pod对象操作的所有方法。</p><h4 id="Pod结构体"><a href="#Pod结构体" class="headerlink" title="Pod结构体"></a>Pod结构体</h4><pre><code>// pods implements PodInterfacetype pods struct {    client rest.Interface    ns     string}</code></pre><p>Pod对象中继承了rest.Interface，上面提到过此client便是进行http请求调用。</p><h4 id="Pod-List方法"><a href="#Pod-List方法" class="headerlink" title="Pod List方法"></a>Pod List方法</h4><pre><code>// List takes label and field selectors, and returns the list of Pods that match those selectors.func (c *pods) List(opts metav1.ListOptions) (result *v1.PodList, err error) {    var timeout time.Duration    if opts.TimeoutSeconds != nil {        timeout = time.Duration(*opts.TimeoutSeconds) * time.Second    }    result = &amp;v1.PodList{}    err = c.client.Get().        Namespace(c.ns).        Resource(&quot;pods&quot;).        VersionedParams(&amp;opts, scheme.ParameterCodec).        Timeout(timeout).        Do().        Into(result)    return}</code></pre><p>以上分析了clientset.CoreV1().Pods(“”).List(metav1.ListOptions{})对pod资源获取的过程，最终是调用RESTClient的方法实现。</p><h3 id="rest-client-对象创建"><a href="#rest-client-对象创建" class="headerlink" title="rest client 对象创建"></a>rest client 对象创建</h3><pre><code>// NewForConfig creates a new CoreV1Client for the given config.func NewForConfig(c *rest.Config) (*CoreV1Client, error) {    config := *c    if err := setConfigDefaults(&amp;config); err != nil {        return nil, err    }    client, err := rest.RESTClientFor(&amp;config)    if err != nil {        return nil, err    }    return &amp;CoreV1Client{client}, nil}</code></pre><p>在CoreV1Client对象创建的时候也根据config对象调用est.RESTClientFor(&amp;config)函数创建了rest client对象。在创建Pod时将CoreV1Client对象的restClient赋值给Pod的client。</p><h4 id="rest-Interface"><a href="#rest-Interface" class="headerlink" title="rest.Interface"></a>rest.Interface</h4><pre><code>type Interface interface {    GetRateLimiter() flowcontrol.RateLimiter    Verb(verb string) *Request    Post() *Request    Put() *Request    Patch(pt types.PatchType) *Request    Get() *Request    Delete() *Request    APIVersion() schema.GroupVersion}</code></pre><p>此接口定义了http请求的方法。</p><h4 id="RESTClient结构体"><a href="#RESTClient结构体" class="headerlink" title="RESTClient结构体"></a>RESTClient结构体</h4><pre><code>type RESTClient struct {    // base is the root URL for all invocations of the client    base *url.URL    // versionedAPIPath is a path segment connecting the base URL to the resource root    versionedAPIPath string    // contentConfig is the information used to communicate with the server.    contentConfig ContentConfig    // serializers contain all serializers for underlying content type.    serializers Serializers    // creates BackoffManager that is passed to requests.    createBackoffMgr func() BackoffManager    // TODO extract this into a wrapper interface via the RESTClient interface in kubectl.    Throttle flowcontrol.RateLimiter    // Set specific behavior of the client.  If not set http.DefaultClient will be used.    Client *http.Client}</code></pre><h4 id="RESTClient对象实现的接口函数"><a href="#RESTClient对象实现的接口函数" class="headerlink" title="RESTClient对象实现的接口函数"></a>RESTClient对象实现的接口函数</h4><pre><code>func (c *RESTClient) Verb(verb string) *Request {    backoff := c.createBackoffMgr()    if c.Client == nil {        return NewRequest(nil, verb, c.base, c.versionedAPIPath, c.contentConfig, c.serializers, backoff, c.Throttle, 0)    }    return NewRequest(c.Client, verb, c.base, c.versionedAPIPath, c.contentConfig, c.serializers, backoff, c.Throttle, c.Client.Timeout)}// Post begins a POST request. Short for c.Verb(&quot;POST&quot;).func (c *RESTClient) Post() *Request {    return c.Verb(&quot;POST&quot;)}// Put begins a PUT request. Short for c.Verb(&quot;PUT&quot;).func (c *RESTClient) Put() *Request {    return c.Verb(&quot;PUT&quot;)}// Patch begins a PATCH request. Short for c.Verb(&quot;Patch&quot;).func (c *RESTClient) Patch(pt types.PatchType) *Request {    return c.Verb(&quot;PATCH&quot;).SetHeader(&quot;Content-Type&quot;, string(pt))}// Get begins a GET request. Short for c.Verb(&quot;GET&quot;).func (c *RESTClient) Get() *Request {    return c.Verb(&quot;GET&quot;)}// Delete begins a DELETE request. Short for c.Verb(&quot;DELETE&quot;).func (c *RESTClient) Delete() *Request {    return c.Verb(&quot;DELETE&quot;)}// APIVersion returns the APIVersion this RESTClient is expected to use.func (c *RESTClient) APIVersion() schema.GroupVersion {    return *c.contentConfig.GroupVersion}</code></pre><p>通过以上实现可以看出对着的接口调用都转到了Verb方法的调用。Verb方法通过传参调用NewRequest函数最终执行了一次http请求操作。</p><h4 id="NewRequest"><a href="#NewRequest" class="headerlink" title="NewRequest"></a>NewRequest</h4><pre><code>// NewRequest creates a new request helper object for accessing runtime.Objects on a server.func NewRequest(client HTTPClient, verb string, baseURL *url.URL, versionedAPIPath string, content ContentConfig, serializers Serializers, backoff BackoffManager, throttle flowcontrol.RateLimiter, timeout time.Duration) *Request {    if backoff == nil {        klog.V(2).Infof(&quot;Not implementing request backoff strategy.&quot;)        backoff = &amp;NoBackoff{}    }    pathPrefix := &quot;/&quot;    if baseURL != nil {        pathPrefix = path.Join(pathPrefix, baseURL.Path)    }    r := &amp;Request{        client:      client,        verb:        verb,        baseURL:     baseURL,        pathPrefix:  path.Join(pathPrefix, versionedAPIPath),        content:     content,        serializers: serializers,        backoffMgr:  backoff,        throttle:    throttle,        timeout:     timeout,    }    switch {    case len(content.AcceptContentTypes) &gt; 0:        r.SetHeader(&quot;Accept&quot;, content.AcceptContentTypes)    case len(content.ContentType) &gt; 0:        r.SetHeader(&quot;Accept&quot;, content.ContentType+&quot;, */*&quot;)    }    return r}</code></pre><p>可以看到NewRequest最终将参数组成http请求参数进行了http请求调用。至此clientset.CoreV1().Pods(“”).List(metav1.ListOptions{})调用完成，最终将结果返回。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>client-go对kubernetes资源对象的调用操作，需要先获取kubernetes的配置信息，即$HOME/.kube/config。(master节点)</p><p>具体流程如下图所示：</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-18812fcf012e02b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="client-go-request.png"></p><h2 id="client-go对k8s资源的调用"><a href="#client-go对k8s资源的调用" class="headerlink" title="client-go对k8s资源的调用"></a>client-go对k8s资源的调用</h2><h3 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h3><pre><code>Clientset.CoreV1().Services(nameSpace).Create(serviceObj)Clientset.CoreV1().Services(nameSpace).Update(serviceObj)Clientset.CoreV1().Services(nameSpace).Delete(serviceName, &amp;meta_v1.DeleteOptions{})Clientset.CoreV1().Services(nameSpace).Get(serviceName, meta_v1.GetOptions{})Clientset.CoreV1().Services(nameSpace).List(meta_v1.ListOptions{})Clientset.CoreV1().Services(nameSpace).Watch(meta_v1.ListOptions{})</code></pre><h3 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h3><pre><code>Clientset.AppsV1beta1().Deployments(nameSpace).Create(deploymentObj)Clientset.AppsV1beta1().Deployments(nameSpace).Update(deploymentObj)Clientset.AppsV1beta1().Deployments(nameSpace).Delete(deploymentName, &amp;meta_v1.DeleteOptions{})Clientset.AppsV1beta1().Deployments(nameSpace).Get(deploymentName, meta_v1.GetOptions{})Clientset.AppsV1beta1().Deployments(nameSpace).List(meta_v1.ListOptions{})Clientset.AppsV1beta1().Deployments(nameSpace).Watch(meta_v1.ListOptions{})</code></pre><h3 id="ReplicaSet"><a href="#ReplicaSet" class="headerlink" title="ReplicaSet"></a>ReplicaSet</h3><pre><code>Clientset.ExtensionsV1beta1().ReplicaSets(nameSpace).Create(replicasetsObj)Clientset.ExtensionsV1beta1().ReplicaSets(nameSpace).Update(replicasetsObj)Clientset.ExtensionsV1beta1().ReplicaSets(nameSpace).Delete(replicaSetName, &amp;meta_v1.DeleteOptions{})Clientset.ExtensionsV1beta1().ReplicaSets(nameSpace).Get(replicaSetName, meta_v1.GetOptions{})Clientset.ExtensionsV1beta1().ReplicaSets(nameSpace).List(meta_v1.ListOptions{})Clientset.ExtensionsV1beta1().ReplicaSets(nameSpace).Watch(meta_v1.ListOptions{})</code></pre><h3 id="Ingresse"><a href="#Ingresse" class="headerlink" title="Ingresse"></a>Ingresse</h3><pre><code>Clientset.ExtensionsV1beta1().Ingresses(nameSpace).Create(ingressObj)Clientset.ExtensionsV1beta1().Ingresses(nameSpace).Update(ingressObj)Clientset.ExtensionsV1beta1().Ingresses(nameSpace).Delete(ingressName, &amp;meta_v1.DeleteOptions{})Clientset.ExtensionsV1beta1().Ingresses(nameSpace).Get(ingressName, meta_v1.GetOptions{})Clientset.ExtensionsV1beta1().Ingresses(nameSpace).List(meta_v1.ListOptions{})</code></pre><h3 id="StatefulSet"><a href="#StatefulSet" class="headerlink" title="StatefulSet"></a>StatefulSet</h3><pre><code>Clientset.AppsV1beta1().StatefulSets(nameSpace).Create(statefulSetObj)Clientset.AppsV1beta1().StatefulSets(nameSpace).Update(statefulSetObj)Clientset.AppsV1beta1().StatefulSets(nameSpace).Delete(statefulSetName, &amp;meta_v1.DeleteOptions{})Clientset.AppsV1beta1().StatefulSets(nameSpace).Get(statefulSetName, meta_v1.GetOptions{})Clientset.AppsV1beta1().StatefulSets(nameSpace).List(meta_v1.ListOptions{})</code></pre><h3 id="DaemonSet"><a href="#DaemonSet" class="headerlink" title="DaemonSet"></a>DaemonSet</h3><pre><code>Clientset.ExtensionsV1beta1().DaemonSets(nameSpace).Create(daemonSetObj)Clientset.ExtensionsV1beta1().DaemonSets(nameSpace).Update(daemonSetObj)Clientset.ExtensionsV1beta1().DaemonSets(nameSpace).Delete(daemonSetName, &amp;meta_v1.DeleteOptions{})Clientset.ExtensionsV1beta1().DaemonSets(nameSpace).Get(daemonSetName, meta_v1.GetOptions{})Clientset.ExtensionsV1beta1().DaemonSets(nameSpace).List(meta_v1.ListOptions{})</code></pre><h3 id="ReplicationController"><a href="#ReplicationController" class="headerlink" title="ReplicationController"></a>ReplicationController</h3><pre><code>Clientset.CoreV1().ReplicationControllers(nameSpace).Create(replicationControllerObj)Clientset.CoreV1().ReplicationControllers(nameSpace).Update(replicationControllerObj)Clientset.CoreV1().ReplicationControllers(nameSpace).Delete(replicationControllerName, &amp;meta_v1.DeleteOptions{})Clientset.CoreV1().ReplicationControllers(nameSpace).Get(replicationControllerName, meta_v1.GetOptions{})Clientset.CoreV1().ReplicationControllers(nameSpace).List(meta_v1.ListOptions{})</code></pre><h3 id="Secret"><a href="#Secret" class="headerlink" title="Secret"></a>Secret</h3><pre><code>Clientset.CoreV1().Secrets(nameSpace).Create(secretObj)Clientset.CoreV1().Secrets(nameSpace).Update(secretObj)Clientset.CoreV1().Secrets(nameSpace).Delete(secretName, &amp;meta_v1.DeleteOptions{})Clientset.CoreV1().Secrets(nameSpace).Get(secretName, meta_v1.GetOptions{})Clientset.CoreV1().Secrets(nameSpace).List(meta_v1.ListOptions{})</code></pre><h3 id="ConfigMap"><a href="#ConfigMap" class="headerlink" title="ConfigMap"></a>ConfigMap</h3><pre><code>Clientset.CoreV1().ConfigMaps(nameSpace).Create(configMapObj)Clientset.CoreV1().ConfigMaps(nameSpace).Update(configMapObj)Clientset.CoreV1().ConfigMaps(nameSpace).Delete(configMapName, &amp;meta_v1.DeleteOptions{})Clientset.CoreV1().ConfigMaps(nameSpace).Get(configMapName, meta_v1.GetOptions{})Clientset.CoreV1().ConfigMaps(nameSpace).List(meta_v1.ListOptions{})</code></pre><h3 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h3><pre><code>Clientset.CoreV1().Pods(nameSpace).Get(podName, meta_v1.GetOptions{})Clientset.CoreV1().Pods(nameSpace).List(meta_v1.ListOptions{})Clientset.CoreV1().Pods(nameSpace).Delete(podName, &amp;meta_v1.DeleteOptions{})</code></pre><h3 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h3><pre><code>Clientset.CoreV1().Namespaces().Create(nsSpec)Clientset.CoreV1().Namespaces().Get(nameSpace, meta_v1.GetOptions{})Clientset.CoreV1().Namespaces().List(meta_v1.ListOptions{})</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Golang 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>共享内存的使用实现原理</title>
      <link href="/2020-04-09-share-memory/"/>
      <url>/2020-04-09-share-memory/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="享内存的使用实现原理"><a href="#享内存的使用实现原理" class="headerlink" title="享内存的使用实现原理"></a>享内存的使用实现原理</h1><p>共享内存可以说是最有用的进程间通信方式，也是最快的IPC形式。两个不同进程A、B共享内存的意思是，同一块物理内存被映射到进程A、B各自的进程地址空间。进程A可以即时看到进程B对共享内存中数据的更新，反之亦然。由于多个进程共享同一块内存区域，必然需要某种同步机制，互斥锁和信号量都可以。使用共享内存时需要注意多个进程对共享内存的同步访问。</p><h3 id="共享内存段最大限制"><a href="#共享内存段最大限制" class="headerlink" title="共享内存段最大限制"></a>共享内存段最大限制</h3><p>SHMMNI为128，表示系统中最多可以有128个共享内存对象。</p><h2 id="ELF-是什么-？"><a href="#ELF-是什么-？" class="headerlink" title="ELF 是什么 ？"></a>ELF 是什么 ？</h2><p>其大小与程序中全局变量的是否初始化有什么关系（注意未初始化的数据放在 bss 段）</p><p><strong>Linux ELF</strong><br>ELF = Executable and Linkable Format ，可执行连接格式</p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 效率 </tag>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>死锁介绍</title>
      <link href="/2020-04-09-linux_dead_mutex/"/>
      <url>/2020-04-09-linux_dead_mutex/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="什么是死锁？"><a href="#什么是死锁？" class="headerlink" title="什么是死锁？"></a>什么是死锁？</h1><p>当我们第一次加锁以后，再次进行加锁，这样会发生什么？<br>当我们第二次申请锁的时候，这个时候锁已经被占用了，该线程就会被挂起，但是刚好这个线程就是拥有锁的线程了，那么这个线程就永远挂起等待了，这个我们就叫 <strong>死锁</strong> 。</p><h2 id="死锁产生的原因"><a href="#死锁产生的原因" class="headerlink" title="死锁产生的原因"></a>死锁产生的原因</h2><ul><li><p><strong>1</strong> 一个线程两次申请锁。</p></li><li><p><strong>2</strong> 两个线程互相申请对方的锁，但是对方都不释放锁。</p></li></ul><h2 id="死锁产生的必要条件"><a href="#死锁产生的必要条件" class="headerlink" title="死锁产生的必要条件"></a>死锁产生的必要条件</h2><ul><li><p><strong>互斥：</strong> 一次只有一个进程可以使用一个资源。其他进程不能访问已分配给其他进程的资源。</p></li><li><p><strong>占有且等待</strong> ：当一个进程在等待分配得到其他资源时，其继续占有已分配得到的资源。</p></li><li><p><strong>非抢占：</strong> 不能强行抢占进程中已占有的资源。</p></li><li><p><strong>循环等待：</strong> 存在一个封闭的进程链，使得每个资源至少占有此链中下一个进程所需要的一个资源。</p></li></ul><h2 id="处理死锁的方法"><a href="#处理死锁的方法" class="headerlink" title="处理死锁的方法"></a>处理死锁的方法</h2><ul><li><p><strong>死锁预防：</strong> 通过确保死锁的一个必要条件不会满足，保证不会发生死锁。</p></li><li><p><strong>死锁检测：</strong> 允许死锁的发生，但是可以通过系统设置的检测结构及时的检测出死锁的发生，采取一些措施，将死锁清除掉。</p></li><li><p><strong>死锁避免：</strong> 在资源分配过程中，使用某种方法避免系统进入不安全的状态，从而避免发生死锁。</p></li><li><p><strong>死锁解除：</strong> 与死锁检测相配套的一种措施。当检测到系统中已发生死锁，需将进程从死锁状态中解脱出来。</p></li></ul><p><strong>常用方法：</strong> 撤销或挂起一些进程，以便回收一些资源，再将这些资源分配给已处于阻塞状态的进程。</p><h2 id="死锁避免算法："><a href="#死锁避免算法：" class="headerlink" title="死锁避免算法："></a>死锁避免算法：</h2><h3 id="银行家算法："><a href="#银行家算法：" class="headerlink" title="银行家算法："></a>银行家算法：</h3><ul><li><p><strong>1.</strong> 如果request&lt;=need，转向步骤2；否则认为出错，因为请求资源大于需要资源。</p></li><li><p><strong>2.</strong> 如果request&lt;=available，转向步骤3,；否则尚无足够资源，进程p阻塞。</p></li><li><p><strong>3.</strong> 系统尝试为把资源分配给进程P，并修改available、allocation和need的数值。</p></li><li><p><strong>4.</strong> 系统执行安全性算法，检查此次分配后系统是否处于 <strong>安全状态</strong> ，若安全，才正式将资源分配给进程P，否则将本次试探性分配作废，让进程P等待。</p></li></ul><p><strong>安全状态：</strong> 系统能按照某种进程顺序，为每个进程分配资源，直至满足每个进程对资源的最大需求，使每个进程都可顺利完成。</p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 效率 </tag>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang interface</title>
      <link href="/2020-04-09-Golang-interface/"/>
      <url>/2020-04-09-Golang-interface/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Golang-interface"><a href="#Golang-interface" class="headerlink" title="Golang interface"></a>Golang interface</h1><h2 id="接口概念"><a href="#接口概念" class="headerlink" title="接口概念"></a>接口概念</h2><p><strong>接口</strong> 即一组方法定义的集合，定义了对象的一组行为，由具体的类型实例实现具体的方法。换句话说，一个接口就是定义（规范或约束），而方法就是实现，接口的作用应该是将定义与实现分离，降低耦合度。习惯用“er”结尾来命名，例如“Reader”。接口与对象的关系是多对多，即一个对象可以实现多个接口，一个接口也可以被多个对象实现。</p><p><strong>​接口(interface)</strong> 是Go语言整个类型系统的基石，其他语言的接口是不同组件之间的契约的存在，对契约的实现是强制性的，必须显式声明实现了该接口，这类接口称之为“侵入式接口”。而Go语言的接口是隐式存在，只要实现了该接口的所有函数则代表已经实现了该接口，并不需要显式的接口声明。</p><h2 id="接口的作用"><a href="#接口的作用" class="headerlink" title="接口的作用"></a>接口的作用</h2><p>​接口是实现语言的多态性，<strong>多态性（polymorphisn）</strong> 是允许你将父对象设置成为和一个或更多的他的子对象相等的技术，赋值之后，父对象就可以根据当前赋值给它的子对象的特性以不同的方式运作。</p><p>简而言之，就是允许将子类类型的指针赋值给父类类型的指针。</p><p>即一个引用变量倒底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。不修改程序代码就可以改变程序运行时所绑定的具体代码，让程序可以选择多个运行状态，这就是多态性。多态分为编译时多态（静态多态）和运行时多态（动态多态），编译时多态一般通过方法重载实现，运行时多态一般通过方法重写实现。</p><h2 id="接口示例"><a href="#接口示例" class="headerlink" title="接口示例"></a>接口示例</h2><p><strong>非侵入式接口：</strong> 一个类只需要实现了接口要求的所有函数就表示实现了该接口，并不需要显式声明</p><pre><code>package mainimport (    &quot;fmt&quot;)// 接口1type File interface{    Read(buf []byte)error    Write(buf []byte)error    Close()error}// 接口2type Receiver interface{    Close()error}type Note struct{}func (* Note)Read(buf []byte)error{    fmt.Println(&quot;Note Read&quot;)    return nil}func (* Note)Write(buf []byte)error{    fmt.Println(&quot;Note Write&quot;)    return nil}func (*Note)Close()error{    fmt.Println(&quot;Note Close&quot;)    return nil}func main() {    //接口赋值,Note类实现了File和Receiver接口，即接口所包含的所有方法    var file File = new(Note)    var recv Receiver = new(Note)    file.Close()    recv.Close()}</code></pre><h3 id="接口赋值给另一个接口"><a href="#接口赋值给另一个接口" class="headerlink" title="接口赋值给另一个接口"></a>接口赋值给另一个接口</h3><ul><li><p><strong>1.</strong> 只要两个接口拥有相同的方法列表（与次序无关），即是两个相同的接口，可以相互赋值</p></li><li><p><strong>2.</strong> 接口赋值只需要接口A的方法列表是接口B的子集（即假设接口A中定义的所有方法，都在接口B中有定义），那么B接口的实例可以赋值给A的对象。反之不成立，即子接口B包含了父接口A，因此可以将子接口的实例赋值给父接口。<br>即子接口实例实现了子接口的所有方法，而父接口的方法列表是子接口的子集，则子接口实例自然实现了父接口的所有方法，因此可以将子接口实例赋值给父接口。</p><pre><code>package mainimport (    &quot;fmt&quot;)type Writer interface{    //父接口 父接口是子接口的子集    Write(buf []byte)error}type ReadWriter interface{    //子接口    Read(buf []byte)error    Write(buf []byte)error}type Note struct{}func (* Note)Read(buf []byte)error{    fmt.Println(&quot;Note Read&quot;)    return nil}func (* Note)Write(buf []byte)error{    fmt.Println(&quot;Note Write&quot;)    return nil}func main() {    var file1 ReadWriter=new(Note)   //子接口实例    var file2 Writer=file1     file1.Write(nil)     file2.Write(nil)}</code></pre></li></ul><h3 id="接口组合"><a href="#接口组合" class="headerlink" title="接口组合"></a>接口组合</h3><pre><code>//接口组合类似类型组合，只不过只包含方法，不包含成员变量package mainimport (    &quot;fmt&quot;)type Receiver interface{    //父接口 父接口是子接口的子集    Close(buf []byte)error}type ReadWriter interface{    //子接口    Read(buf []byte)error    Write(buf []byte)error}type File interface{    Receiver    ReadWriter}type Note struct{}func (* Note)Read(buf []byte)error{    fmt.Println(&quot;Note Read&quot;)    return nil}func (* Note)Write(buf []byte)error{    fmt.Println(&quot;Note Write&quot;)    return nil}func (* Note)Close(buf []byte)error{    fmt.Println(&quot;Note Close&quot;)    return nil}func main() {    var file1 File=new(Note)   //子接口实例    file1.Write(nil) }</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Golang 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang 内存分配</title>
      <link href="/2020-04-03-Golang_memory_manager/"/>
      <url>/2020-04-03-Golang_memory_manager/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Golang-内存分配"><a href="#Golang-内存分配" class="headerlink" title="Golang 内存分配"></a>Golang 内存分配</h1><h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><p>Go语言内置运行时（就是runtime），不同于传统的内存分配方式，go为自主管理，最开始是基于 <strong>tcmalloc（thread-caching-malloc）</strong> 架构，后面逐步迭新。自主管理可实现更好的内存使用模式，如内存池、预分配等，从而避免了系统调用所带来的性能问题。</p><h2 id="基本策略"><a href="#基本策略" class="headerlink" title="基本策略"></a>基本策略</h2><ul><li>申请一块较大的地址空间（虚拟内存），用于内存分配及管理（golang：spans+bitmap+arena-&gt;512M+16G+512G）</li><li>当空间不足时，向系统申请一块较大的内存，如100KB或者1MB<br>申请到的内存块按特定的size，被分割成多种小块内存（golang：_NumSizeClasses = 67），并用链表管理起来</li><li>创建对象时，按照对象大小，从空闲链表中查找到最适合的内存块</li><li>销毁对象时，将对应的内存块返还空闲链表中以复用</li><li>空闲内存达到阈值时，返还操作系统</li></ul><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="内存块"><a href="#内存块" class="headerlink" title="内存块"></a>内存块</h3><ul><li><p><strong>span：</strong> 即上面所说的操作系统分配的大块内存，由多个地址连续的页组成；</p><p>  内存分配器按照页数来区分不同大小的span，如以页数为单位将span存放到管理数组中，且以页数作为索引；</p><p>  　　span大小并非不变，在没有获取到合适大小的闲置span时，返回页数更多的span，然后进行剪裁，多余的页数构成新的span，放回管理数组；</p><p>  　　分配器还可以将相邻的空闲span合并，以构建更大的内存块，减少碎片提供更灵活的分配策略。</p><p>  <img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-5ef8b3da2b764920.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="span.png"></p><p>  如上图所示span1占用2个页，span2占用4个页，span3占用3个页。</p><p>  <strong>数据结构如下：</strong></p><pre><code>//mheap.gotype mspan struct {    next *mspan   //双向链表 next span in list, or nil if none    prev *mspan   //previous span in list, or nil if none    list *mSpanList  //用于调试。TODO: Remove.    //起始序号 = （address &gt;&gt; _PageShift）    startAddr uintptr  //address of first byte of span aka s.base()    npages    uintptr  //number of pages in span    //待分配的object链表    manualFreeList gclinkptr  //list of free objects in mSpanManual spans}</code></pre></li><li><p><strong>object：</strong> 由span按特定大小切分的小块内存，每一个可存储一个对象；object，按8字节倍数分为n种。如，大小为24的object可存储范围在17~24字节的对象。在造成一些内存浪费的同时减少了小块内存的规格，优化了分配和复用的管理策略，分配器还会将多个微小对象组合到一个object块内，以节约内存。</p><p>  span 列表(mspan)分为67个大小级别的多种小块内存(go：_NumSizeClasses = 67)并用链表管理。从8 bytes到32k bytes，这样就可以存储不同大小的对象object。如下图所示：</p><p>  <img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-a85a61f69363401e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="span-size-classes.png"></p></li></ul><p>按照用途，span面向内部管理，object面向对象分配。</p><h3 id="存储对象分类"><a href="#存储对象分类" class="headerlink" title="存储对象分类"></a>存储对象分类</h3><ul><li>小对象（tiny）: size &lt; 16byte;</li><li>普通对象： 16byte ~ 32K;</li><li>大对象（large）：size &gt; 32K;</li></ul><h3 id="内存分配器"><a href="#内存分配器" class="headerlink" title="内存分配器"></a>内存分配器</h3><p><strong>cache：</strong> 每个运行期工作线程都会绑定一个cache，用于无锁object分配(Central组件其实也是一个缓存，但它缓存的不是小对象内存块，而是一组一组的内存page(一个page占4k大小))。每个mcache有大小为67的mspan数组，存储不同级别大小的mspan<br><strong>数据结构如下所示：</strong></p><pre><code>//mcache.gotype mcache struct{     以spanClass为索引管理多个用于分配的span     alloc [numSpanClasses]*mspan // spans to allocate from, indexed by spanClass   }</code></pre><p><strong>central：</strong> 全局内存，为所有cache提供切分好的后备span资源。</p><p><strong>数据结构如下所示：</strong></p><pre><code>//mcentral.gotype mcentral struct{    spanclass   spanClass             //规格    //链表：尚有空闲object的span    nonempty mSpanList // list of spans with a free object, ie a nonempty free list          // 链表：没有空闲object，或已被cache取走的span    empty    mSpanList // list of spans with no free objects (or cached in an mcache)}</code></pre><p><strong>heap：</strong> 全局内存，管理闲置span，需要时间向操作系统申请新内存(堆分配器，以8192byte页进行管理)。</p><p><strong>数据结构如下所示：</strong></p><pre><code>type mheap struct{largealloc  uint64                  // bytes allocated for large objects //页数大于127（&gt;=127）的闲置span链表                                                                                                                     largefree   uint64                  // bytes freed for large objects (&gt;maxsmallsize)    nlargefree  uint64                  // number of frees for large objects (&gt;maxsmallsize) //页数在127以内的闲置span链表数组                                                                                                                     nsmallfree  [_NumSizeClasses]uint64 // number of frees for small objects (&lt;=maxsmallsize)//每个central对应一种sizeclasscentral [numSpanClasses]struct {    mcentral mcentral    pad      [cpu.CacheLinePadSize - unsafe.Sizeof(mcentral{})%cpu.CacheLinePadSize]byte</code></pre><p>}</p><h2 id="示例引入"><a href="#示例引入" class="headerlink" title="示例引入"></a>示例引入</h2><pre><code>package maintype smallStruct struct {a, b int64c, d float64}func main() {smallAllocation()}//go:noinlinefunc smallAllocation() *smallStruct {return &amp;smallStruct{}}</code></pre><p><strong>注释：</strong> <strong>“//go:noinline”</strong> 表示该函数禁止进行内联。内联优化是避免栈和抢占检查这些成本的经典优化方法。在没有内联优化的时候new函数会调用newobject在堆上分配内存。</p><p>我们使用逃逸分析命令: <strong>“go tool compile “-m” test.go”</strong> 来分析Go的内存分配。</p><pre><code>#go tool compile &quot;-m&quot; test.go/test.go:8:6: can inline main./test.go:14:11: &amp;smallStruct literal escapes to heap</code></pre><p>使命命令:”go tool compile -S test.go”查看内存分配过程细节。</p><pre><code>#go tool compile -S test.go0x0000 00000 (./test.go:13)     TEXT    &quot;&quot;.smallAllocation(SB), ABIInternal, $24-80x0000 00000 (./test.go:13)     MOVQ    (TLS), CX0x0009 00009 (./test.go:13)     CMPQ    SP, 16(CX)0x000d 00013 (./test.go:13)     JLS     650x000f 00015 (./test.go:13)     SUBQ    $24, SP0x0013 00019 (./test.go:13)     MOVQ    BP, 16(SP)0x0018 00024 (./test.go:13)     LEAQ    16(SP), BP0x001d 00029 (./test.go:13)     FUNCDATA        $0, gclocals·9fb7f0986f647f17cb53dda1484e0f7a(SB)0x001d 00029 (./test.go:13)     FUNCDATA        $1, gclocals·69c1753bd5f81501d95132d08af04464(SB)0x001d 00029 (./test.go:13)     FUNCDATA        $3, gclocals·9fb7f0986f647f17cb53dda1484e0f7a(SB)0x001d 00029 (./test.go:14)     PCDATA  $2, $10x001d 00029 (./test.go:14)     PCDATA  $0, $00x001d 00029 (./test.go:14)     LEAQ    type.&quot;&quot;.smallStruct(SB), AX0x0024 00036 (./test.go:14)     PCDATA  $2, $00x0024 00036 (./test.go:14)     MOVQ    AX, (SP)0x0028 00040 (./test.go:14)     CALL    runtime.newobject(SB)0x002d 00045 (./test.go:14)     PCDATA  $2, $10x002d 00045 (./test.go:14)     MOVQ    8(SP), AX0x0032 00050 (./test.go:14)     PCDATA  $2, $00x0032 00050 (./test.go:14)     PCDATA  $0, $10x0032 00050 (./test.go:14)     MOVQ    AX, &quot;&quot;.~r0+32(SP)0x0037 00055 (./test.go:14)     MOVQ    16(SP), BP0x003c 00060 (./test.go:14)     ADDQ    $24, SP0x0040 00064 (./test.go:14)     RET0x0041 00065 (./test.go:14)     NOP0x0041 00065 (./test.go:13)     PCDATA  $0, $-10x0041 00065 (./test.go:13)     PCDATA  $2, $-10x0041 00065 (./test.go:13)     CALL    runtime.morestack_noctxt(SB)</code></pre><p>可以看到在运行到smallAllocation函数时调用了runtime.newobject函数来申请的内存。<strong>在此创建过程发生了什么？具体看下面讲解。</strong></p><h3 id="微小对象分配"><a href="#微小对象分配" class="headerlink" title="微小对象分配"></a>微小对象分配</h3><p>小于32kb的微小对象内存分配。Go 将从叫做mcache的本地缓存中获取内存。这个缓存管理一个span链表(32kb的内存块）称为mspan。其中包含可分配的内存。如下图所示：<br><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-53534f89088e5340.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="allocation-with-mcache.png"></p><p>根据PMG调度模型大家应该知道每个线程M将分配一个处理器P,并且一次最多处理一个goroutine。在分配内存时，当前的goroutine将使用其当前P的本地缓存mcache，在mspan列表中找出第一个空闲的对象。使用本地缓存mcache不需要锁，这样可以使内存分配效率更高。</p><p>例如上述示例中结构体占用内存是32bytes 将给分配32bytes span 。则申请示意图如下所示：</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-2774d10c0b23d6b4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="code-demo.png"></p><p><strong>现在，我们想象一下如果span 再分配的时候没有空闲的内存，将发生什么？</strong></p><p><strong>1.</strong> 先来看一下这个概念，Go 中central维护同样大小classes span的链表，叫做mcentral，此数据结构用来表示对应大小classes的span中已经被使用的object和空闲的object 链表。如下图所示：</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-6832962f272102ac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="central-lists-of-spans.png"></p><p>根据上图可以看出一个mcentral维护两个链表nonempty 和empty 链表。并且每个链表包含当前的span 和下一个span。 nonempty 链表的 span意味着至少有一个可分配的内存。也包含着一些在使用中的内存分配。当垃圾回收器对这块使用中的内存进行回收时，他将清除span这部分内存，在span中此部分将被标记成没有被使用状态。并且将添加回nonempty 链表中去。</p><p><strong>2.</strong> 再回到问题，我们知道这个mcentral后,便可得知如果一个span没有了可分配的内存了，便可以从central链表(全局内存)中重新获取一个。如下图所示：</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-dc3510dd229be832.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="span-from-central.png"></p><p>假如P的一个运行的goroutine，系统分配一个8 bytes的内存，通过本地缓存mcache去mspan 链表中申请，如果没有可分配的8 bytes的对象了，那么就会在后备span资源mcentral中去重新申请一个对应size classes的span。</p><p><strong>3.</strong> 那么问题来了，如果central 链表中没有可分配的新span。那么在Go中新的span将会在heap中申请得到，并且将新的span的对象存储状态关联到central链表中去，如下图所示。</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-e3727b2d0e33793d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="span-from-heap.png"></p><p>当需要时，heap将从系统中申请一片内存(小内存)。此外如果需要更大的内存，heap将从系统中申请一大段内存，叫做arena。(在64位架构系统中将申请64MB,其他的大多数架构系统将申请4MB)。arena也映射spans的内存页。如下图所示</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-ccd830361bcb768a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="arena-to-span.png"></p><h2 id="大对象分配"><a href="#大对象分配" class="headerlink" title="大对象分配"></a>大对象分配</h2><p>在Go中不用本地缓存 mcache管理大对象内存分配。这些分配通常指大于32kb内存。页内存将直接在heap上申请。</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-05149ac769cb999c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="large-allocation.png"></p><h2 id="内存分配示意图"><a href="#内存分配示意图" class="headerlink" title="内存分配示意图"></a>内存分配示意图</h2><p>通过以上概念引入，再到举例切入，认识和了解Go的内存分配流程，再从宏观来看一下内存分配，如下图所示。</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-f923a2783f0235ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="memory-allocation.png"></p><h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><p>根据示例引入的例子，内存分析此看到是runtime.newobject()函数调用，是Go的内存分配内置函数。源码如下：</p><pre><code>//malloc.go// implementation of new builtin// compiler (both frontend and SSA backend) knows the signature// of this functionfunc newobject(typ *_type) unsafe.Pointer {    return mallocgc(typ.size, typ, true)}// Allocate an object of size bytes.// Small objects are allocated from the per-P cache&apos;s free lists.// Large objects (&gt; 32 kB) are allocated straight from the heap.///分配一个大小为字节的对象。小对象是从per-P缓存的空闲列表中分配的。 大对象（&gt; 32 kB）直接从堆中分配。func mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer {    if gcphase == _GCmarktermination { //垃圾回收有关        throw(&quot;mallocgc called with gcphase == _GCmarktermination&quot;)    }    if size == 0 {        return unsafe.Pointer(&amp;zerobase)    }    if debug.sbrk != 0 {        align := uintptr(16)        if typ != nil {            align = uintptr(typ.align)        }        return persistentalloc(size, align, &amp;memstats.other_sys)  //围绕sysAlloc的包装程序，可以分配小块。没有相关的自由操作。用于功能/类型/调试相关的持久数据。如果align为0，则使用默认的align（当前为8）。返回的内存将被清零。考虑将持久分配的类型标记为go：notinheap。    }    // assistG是要为此分配收费的G，如果GC当前未激活，则为n。    var assistG *g    ...    // Set mp.mallocing to keep from being preempted by GC.    //加锁放防止GC被抢占。    mp := acquirem()    if mp.mallocing != 0 {        throw(&quot;malloc deadlock&quot;)    }    if mp.gsignal == getg() {        throw(&quot;malloc during signal&quot;)    }    mp.mallocing = 1    shouldhelpgc := false    dataSize := size    //当前线程所绑定的cache    c := gomcache()    var x unsafe.Pointer    // 判断分配的对象是否 是nil或非指针类型    noscan := typ == nil || typ.kind&amp;kindNoPointers != 0    //微小对象    if size &lt;= maxSmallSize {        //无须扫描非指针微小对象（16）        if noscan &amp;&amp; size &lt; maxTinySize {            // Tiny allocator.            //微小的分配器将几个微小的分配请求组合到一个内存块中。当所有子对象均不可访问时，将释放结果存储块。子对象必须是noscan（没有指针），以确保限制可能浪费的内存量。            //用于合并的存储块的大小（maxTinySize）是可调的。当前设置为16字节.            //小分配器的主要目标是小字符串和独立的转义变量。在json基准上，分配器将分配数量减少了约12％，并将堆大小减少了约20％。            off := c.tinyoffset            // 对齐所需（保守）对齐的小指针。调整偏移量。            if size&amp;7 == 0 {                off = round(off, 8)            } else if size&amp;3 == 0 {                off = round(off, 4)            } else if size&amp;1 == 0 {                off = round(off, 2)            }            //如果剩余空间足够.  当前mcache上绑定的tiny 块内存空间足够，直接分配，并返回            if off+size &lt;= maxTinySize &amp;&amp; c.tiny != 0 {                // 返回指针，调整偏移量为下次分配做好准备。                x = unsafe.Pointer(c.tiny + off)                c.tinyoffset = off + size                c.local_tinyallocs++                mp.mallocing = 0                releasem(mp)                return x            }            //当前mcache上的 tiny 块内存空间不足，分配新的maxTinySize块。就是从sizeclass=2的span.freelist获取一个16字节object。            span := c.alloc[tinySpanClass]            // 尝试从 allocCache 获取内存，获取不到返回0            v := nextFreeFast(span)            if v == 0 {            // 没有从 allocCache 获取到内存，netxtFree函数 尝试从 mcentral获取一个新的对应规格的内存块（新span），替换原先内存空间不足的内存块，并分配内存，后面解析 nextFree 函数                v, _, shouldhelpgc = c.nextFree(tinySpanClass)            }            x = unsafe.Pointer(v)            (*[2]uint64)(x)[0] = 0            (*[2]uint64)(x)[1] = 0            // 对比新旧两个tiny块剩余空间，看看我们是否需要用剩余的自由空间来替换现有的微型块。新块分配后其tinyyoffset = size,因此比对偏移量即可            if size &lt; c.tinyoffset || c.tiny == 0 {                //用新块替换                c.tiny = uintptr(x)                c.tinyoffset = size            }            //消费一个新的完整tiny块            size = maxTinySize        } else {            // 这里开始 正常对象的 内存分配            // 首先查表，以确定 sizeclass            var sizeclass uint8            if size &lt;= smallSizeMax-8 {                sizeclass = size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]            } else {                sizeclass = size_to_class128[(size-smallSizeMax+largeSizeDiv-1)/largeSizeDiv]            }            size = uintptr(class_to_size[sizeclass])            spc := makeSpanClass(sizeclass, noscan)            //找到对应规格的span.freelist，从中提取object            span := c.alloc[spc]            // 同小对象分配一样，尝试从 allocCache 获取内存，获取不到返回0            v := nextFreeFast(span)            //没有可用的object。从central获取新的span。            if v == 0 {                v, span, shouldhelpgc = c.nextFree(spc)            }            x = unsafe.Pointer(v)            if needzero &amp;&amp; span.needzero != 0 {                memclrNoHeapPointers(unsafe.Pointer(v), size)            }        }    } else {        // 这里开始大对象的分配        // 大对象的分配与 小对象 和普通对象 的分配有点不一样，大对象直接从 mheap 上分配        var s *mspan        shouldhelpgc = true        systemstack(func() {            s = largeAlloc(size, needzero, noscan)        })        s.freeindex = 1        s.allocCount = 1        //span.start实际由address &gt;&gt; pageshift生成。        x = unsafe.Pointer(s.base())        size = s.elemsize    }    // bitmap标记...    // 检查出发条件，启动垃圾回收 ...    return x}</code></pre><p><strong>代码基本思路：</strong></p><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-4f75203b9a36bd92.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="code-flow.png"></p><p>　　1. 判定对象是大对象、小对象还是微小对象。</p><p>　　2. 如果是微小对象：</p><ul><li>直接从 mcache 的alloc 找到对应 classsize 的 mspan；</li><li>如果当前mspan有足够空间，分配并修改mspan的相关属性（nextFreeFast函数中实现）；</li><li>如果当前mspan的空间不足，则从 mcentral重新获取一块 对应 classsize的 mspan，替换原先的mspan，然后分配并修改mspan的相关属性；</li><li>对于微小对象，它不能是指针，因为多个微小对象被组合到一个object里，显然无法应对辣鸡扫描。其次它从span.freelist获取一个16字节的object，然后利用偏移量来记录下一次分配的位置。</li></ul><p>　　3. 如果是小对象，内存分配逻辑大致同微小对象：</p><ul><li><p>首先查表，以确定 需要分配内存的对象的 sizeclass，并找到 对应 classsize的 mspan；</p></li><li><p>若当前mspan有足够的空间，分配并修改mspan的相关属性（nextFreeFast函数中实现）；</p></li><li><p>若当前mspan没有足够的空间，从 mcentral重新获取一块对应 classsize的 mspan，替换原先的mspan，然后分配并修改mspan的相关属性；</p></li></ul><p>　　4. 如果是大对象，直接从mheap进行分配，这里的实现依靠 largeAlloc 函数实现。</p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Golang 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang 数组和切片</title>
      <link href="/2020-04-03-Golang_array_slice/"/>
      <url>/2020-04-03-Golang_array_slice/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Golang-数组和切片"><a href="#Golang-数组和切片" class="headerlink" title="Golang 数组和切片"></a>Golang 数组和切片</h1><h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>在Go语言中，数组是一种具有<strong>相同类型固定大小</strong>的一种数据结构。</p><p>我们先来看看数组的使用，数组类型声明时的方式是 []T ,前面的[]指定数组的大小，T指定数组的类型，如下我们声明了一下数组，数组的大小是3，在没指定数组初始值时数组默认初始值是{0，0，0}</p><pre><code>package mainimport (    &quot;fmt&quot;)func main() {    array1 := [3]int{}    //我们可以通过如下方式给数组赋值    array1[0] = 1    array1[1] = 2    array1[2] = 3    fmt.Println(array1)    //下面这种也是数组声明的一种方式，并且初始化数组的值为{1,2}    array2 := [2]int {1,2}    fmt.Println(array2)}</code></pre><p><strong>结果输出：</strong></p><pre><code>[1 2 3][1 2]</code></pre><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><h4 id="数组可以进行比较吗？"><a href="#数组可以进行比较吗？" class="headerlink" title="数组可以进行比较吗？"></a>数组可以进行比较吗？</h4><p>答案：可以，也不可以(分情况)通过以下两个例子进行</p><p><strong>1.示例：</strong></p><pre><code>package mainimport (    &quot;fmt&quot;)func main() {    array1 := [3]int{1,2,3}    //我们可以通过如下方式给数组赋值    fmt.Println(array1)    //下面这种也是数组声明的一种方式，并且初始化数组的值为{1,2}    array2 := [3]int {1,2,4}    fmt.Println(array2)    if array1 == array2{        fmt.Println(&quot;true&quot;)    }else{        fmt.Println(&quot;false&quot;)    }}</code></pre><p><strong>结果输出：</strong></p><pre><code>false</code></pre><p><strong>注释:</strong> 没有报错，即可以进行比较</p><p><strong>2.示例：</strong></p><pre><code>package mainimport (    &quot;fmt&quot;)func main() {    array1 := [3]int{1,2,3}    //我们可以通过如下方式给数组赋值    fmt.Println(array1)    //下面这种也是数组声明的一种方式，并且初始化数组的值为{1,2}    array2 := [2]int {1,2}    fmt.Println(array2)    if array1 == array2{        fmt.Println(&quot;true&quot;)    }else{        fmt.Println(&quot;false&quot;)    }}</code></pre><p> <strong>结果输出：</strong></p><pre><code># command-line-arguments.\test.go:13:12: invalid operation: array1 == array2 (mismatched types [3]int and [2]int)</code></pre><p><strong>注释:</strong> 程序报错，即不可以进行比较。</p><h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><p>通过以上两个例子，我们可以得到，首先在进行比较时此类型必须是可比较类型，如 map，[]切片是不可比较类型。在可比较类型的前提下，必须是固定长度且类型相同才可以进行比较。</p><h2 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h2><h3 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h3><p>在Go语言中，切片是数组的一种高级运用，相对于数组，切片是一种更加方便，灵活，高效的数据结构。，切片并不存储任何元素而只是对现有数组的引用（不是值拷贝，是指针）</p><h3 id="定义切片"><a href="#定义切片" class="headerlink" title="定义切片"></a>定义切片</h3><pre><code>package mainimport (    &quot;fmt&quot;)func main() {    array1 := [3]int{1,2,3}    //将数组下标从1处到下标2处的元素转换为一个切片(前闭后开)    slice1 := array1[1:2]    fmt.Println(slice1)    slice2 := []int{1,2,3}    fmt.Println(slice2)    slice3   := make([]int,3,6)    //给切片赋值    slice3[0] = 0    slice3[1] = 1    slice3[2] = 2    //通过len([]Type) cap([]Type)两个函数查看切片的长度和容量    fmt.Println(slice3)    fmt.Println(len(slice3),cap(slice3))}</code></pre><p><strong>输出结果：</strong></p><pre><code>[2][1 2 3][0 1 2]3 6</code></pre><p><strong>注释:</strong> 以上示例用三种方式定义一个切片，（这里大家有个疑问，我不管怎么看都觉得它是一个数组啊）<strong>记住，再go语言中，区别一个变量是数组还是切片，就看有没有定义长度，有定义长度就是数组反之就是切片。</strong> </p><h2 id="数组和切片的底层存储"><a href="#数组和切片的底层存储" class="headerlink" title="数组和切片的底层存储"></a>数组和切片的底层存储</h2><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-d4e5fcdbb49d46ae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="array_slice.png"></p><p>基于上图我们会发现，切片的底层就是数组，切片是通过指针的形式指向不同数组的位置从而形成不同的切片，切片对本身元素的修改，也会影响到数组和其它的切片。看下面示例代码</p><pre><code>package mainimport (    &quot;fmt&quot;)func main() {    array11 := [5]int{1,2,3,4,5} //[1,2,3,4,5]    slice11 := array11[0:3] //[1,2,3]    slice11[0] = 10 //[10,2,3]    sliceTemp := append(array11[:2],array11[3:]...) //[10,2,4,5]    slice11[0] = 11 //[11,2,4]    fmt.Println(array11,slice11,sliceTemp) //[11,2,4,5,5] [11,2,4] [11,2,4,5]}</code></pre><p><strong>输出结果：</strong></p><pre><code>[11 2 4 5 5] [11 2 4] [11 2 4 5]</code></pre><p><strong>注释:</strong><br>第一行：创建了一个长度为5，且存储的元素类型是int的数组array11并且初始化为[1,2,3,4,5] </p><p>第二行：基于数组array11创建了一个切片slice11，切片内容是array11数组的第一个元素到第三个元素的切分。值为[1,2,3]</p><p>第三行：将切片的slice11第1个元素重新复制为10，即slice11值为[10,2,3].由于切片是指向数据的指针，因为重新赋值就是将数组对应下标的值改掉。此时数组array11的值为[10,2,3,4,5]</p><p>第四行：基于数组array11创建切片sliceTemp，所取的值是数组array11前两个元素[10,2]和后两个值[4,5]所以sliceTemp值为[10,2,4,5]。此时sliceTemp是由于数组array11作为原数组，将其前两个元素保留[10,2]再将后两个元素[4,5]做重新赋值给array11第三个和第四个元素，此时array11的值就发生了变化为[10,2,4,5,5]</p><p>第五行：slice11又重新给第1个元素复制为11，由于第四行操作已经改变了array11的值,因此slice11的值也会发生变化为[11,2,4,5,5]，此时slice11的值为[11,2,4]。<br>sliceTemp的值也变为[11,2,4,5]</p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Golang 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang 闭包</title>
      <link href="/2020-04-03-Golang_closure/"/>
      <url>/2020-04-03-Golang_closure/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="闭包函数"><a href="#闭包函数" class="headerlink" title="闭包函数"></a>闭包函数</h1><h2 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a>匿名函数</h2><p>匿名函数：不带函数名的函数，可以像变量一样被传递</p><pre><code>func(a,b int,z float32) bool{  //没有函数名return a*b&lt;int(z)}f:=func(x,y int) int{return x+y}</code></pre><h2 id="闭包函数介绍"><a href="#闭包函数介绍" class="headerlink" title="闭包函数介绍"></a>闭包函数介绍</h2><p>闭包是可以包含自由变量（未绑定到特定的对象）的代码块，这些变量不在代码块内或全局上下文中定义，而在定义代码块的环境中定义。要执行的代码块为自由变量提供绑定的计算环境（作用域）。闭包的价值在于可以作为一个变量对象来进行传递和返回。即可以把函数本身看作是一个变量，Go的匿名函数是一个闭包，Go闭包常用在go和defer关键字中。</p><h2 id="闭包函数的坑"><a href="#闭包函数的坑" class="headerlink" title="闭包函数的坑"></a>闭包函数的坑</h2><p>在for range中goroutine的方式使用闭包，如果没有给匿名函数传入一个变量，或新建一个变量存储迭代的变量，那么goroutine执行的结果会是最后一个迭代变量的结果，而不是每个迭代变量的结果。这是因为如果没有通过一个变量来拷贝迭代变量，那么闭包因为绑定了变量，当每个groutine运行时，迭代变量可能被更改。</p><p><strong>示例如下：</strong></p><ul><li><p>问题case:</p><pre><code>package mainimport (    &quot;fmt&quot;    &quot;sync&quot;)func main() {    var go_sync sync.WaitGroup    values := []int{1,2,3}    for _, val := range values {        go func() {            fmt.Println(val)            defer go_sync.Done()        }()        go_sync.Add(1)    }    go_sync.Wait()}</code></pre><p>  <strong>结果输出：</strong></p><pre><code>333</code></pre></li><li><p>规范case:</p><pre><code>package mainimport (    &quot;fmt&quot;    &quot;sync&quot;)func main() {    var go_sync sync.WaitGroup    values := []int{1,2,3}    for _, val := range values {        go func(val interface{}) {            fmt.Println(val)            defer go_sync.Done()        }(val)        go_sync.Add(1)    }    go_sync.Wait()}</code></pre><p>  <strong>结果输出：</strong></p><pre><code>312</code></pre></li></ul><h2 id="闭包函数应用示例"><a href="#闭包函数应用示例" class="headerlink" title="闭包函数应用示例"></a>闭包函数应用示例</h2><pre><code>package mainimport &quot;fmt&quot;func adder() func(int) int {    sum := 0    return func(x int) int {        sum += x        return sum    }}func main() {    pos, neg := adder(), adder()    for i := 0; i &lt; 10; i++ {        fmt.Println(pos(i),neg(-2*i),        )    }}</code></pre><p><strong>结果输出：</strong></p><pre><code>0 01 -23 -66 -1210 -2015 -3021 -4228 -5636 -7245 -90</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>闭包并不是一门编程语言不可缺少的功能，但闭包的表现形式一般是以匿名函数的方式出现，就象上面说到的，能够动态灵活的创建以及传递，体现出函数式编程的特点。所以在一些场合，我们就多了一种编码方式的选择，适当的使用闭包可以使得我们的代码简洁高效。</p><h2 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h2><p>由于闭包会使得函数中的变量都被保存在内存中，内存消耗很大，所以不能滥用闭包</p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Golang 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang 不定参数</title>
      <link href="/2020-04-03-Golang_parameters/"/>
      <url>/2020-04-03-Golang_parameters/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="不定参"><a href="#不定参" class="headerlink" title="不定参"></a>不定参</h1><p>可以把不定参数理解为一个数组切片，你可以自己组织一个数组切片，然后将其作为不定参数传给一个可以接受不定参数的函数,而且只能放在参数中的最后面。<br>特殊字符标志：<strong>“…”</strong>。</p><h2 id="不定参数函数"><a href="#不定参数函数" class="headerlink" title="不定参数函数"></a>不定参数函数</h2><pre><code>package mainimport (    &quot;fmt&quot;)//不定参数函数func Add(a int, args ...int) (result int) {    result += a    for _, arg := range args {        result += arg    }    return}func main() {    fmt.Println(Add(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))    // 或者    argsList := []int{2, 3, 4, 5, 6, 7, 8, 9, 10}    fmt.Println(Add(1,argsList...))}</code></pre><h2 id="任意类型的不定参数"><a href="#任意类型的不定参数" class="headerlink" title="任意类型的不定参数"></a>任意类型的不定参数</h2><pre><code>package mainimport (    &quot;fmt&quot;)/*任意类型的不定参数，用interface{}表示*/func MyPrintf(args ...interface{}) {    for _, arg := range args { //迭代不定参数        switch arg.(type) {        case int:            fmt.Println(arg, &quot;is int&quot;)        case string:            fmt.Println(arg, &quot;is string&quot;)        case float64:            fmt.Println(arg, &quot;is float64&quot;)        case bool:            fmt.Println(arg, &quot; is bool&quot;)        default:            fmt.Println(&quot;Unknow&quot;)        }    }}func main() {    MyPrintf(1, &quot;test&quot;, 1.5, false, -1.5)}</code></pre><p><strong>输出结果：</strong></p><pre><code>1 is inttest is string1.5 is float64false  is bool-1.5 is float64</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Golang 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang 异常处理</title>
      <link href="/2020-04-03-Golang_exception/"/>
      <url>/2020-04-03-Golang_exception/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Golang-异常处理"><a href="#Golang-异常处理" class="headerlink" title="Golang 异常处理"></a>Golang 异常处理</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Go语言追求简洁优雅，所以，Go语言不支持传统的 try…catch…finally 这种异常，因为Go语言的设计者们认为，将异常与控制结构混在一起会很容易使得代码变得混乱。因为开发者很容易滥用异常，甚至一个小小的错误都抛出一个异常。在Go语言中，使用多值返回来返回错误。不要用异常代替错误，更不要用来控制流程。在极个别的情况下，也就是说，遇到真正的异常的情况下（比如除数为0了）。才使用Go中引入的Exception处理：defer, panic, recover。</p><h2 id="defer函数"><a href="#defer函数" class="headerlink" title="defer函数"></a>defer函数</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>defer语句是Go中一个非常有用的特性，可以将一个方法延迟到包裹该方法的方法返回时执行，在实际应用中，defer语句可以充当其他语言中try…catch…的角色，也可以用来处理关闭文件句柄等收尾操作。</p><p> <strong>有以下特点：</strong></p><ul><li><p><strong>1.</strong> defer在声明时不会执行，而是推迟执行，在return执行前，<strong>倒序执行defer[先进后出]</strong>，一般用于释放资源，清理数据，记录日志，异常处理等。</p></li><li><p><strong>2.</strong> defer有一个特性：<strong>即使函数抛出异常，defer仍会被执行</strong>，这样不会出现程序错误导致资源不被释放，或者因为第三方包的异常导致程序崩溃。</p></li></ul><h3 id="defer函数示例"><a href="#defer函数示例" class="headerlink" title="defer函数示例"></a>defer函数示例</h3><pre><code>package mainimport &quot;fmt&quot;func stackingDefers() {    defer func() {        fmt.Println(&quot;1&quot;)    }()    defer func() {        fmt.Println(&quot;2&quot;)    }()    defer func() {        fmt.Println(&quot;3&quot;)    }()}func main() {    stackingDefers()}</code></pre><p><strong>输出结果：</strong></p><pre><code>321</code></pre><p><strong>注释：</strong> 根据输出结果发现：当一个方法中有多个defer时， defer会将要延迟执行的方法“压栈”，当defer被触发时，将所有“压栈”的方法“出栈”并执行。所以defer的执行顺序是LIFO的。</p><h3 id="defer-在匿名函数中的坑"><a href="#defer-在匿名函数中的坑" class="headerlink" title="defer 在匿名函数中的坑"></a>defer 在匿名函数中的坑</h3><pre><code>package mainimport &quot;fmt&quot;func returnValues() int {    var result int    defer func() {        result++        fmt.Println(&quot;defer&quot;)    }()    return result}func namedReturnValues() (result int) {    defer func() {        result++        fmt.Println(&quot;defer&quot;)    }()    return result}func main() {    fmt.Println(returnValues())    fmt.Println(namedReturnValues())}</code></pre><p><strong>输出结果：</strong></p><pre><code>defer0defer1</code></pre><p><strong>注释:</strong> 上面的方法看到输出0，下面的方法输出1。上面的方法使用了匿名返回值，下面的使用了命名返回值，除此之外其他的逻辑均相同，为什么输出的结果会有区别呢？</p><p>要搞清这个问题首先需要了解defer的执行逻辑，文档中说defer语句在方法返回“时”触发，也就是说return和defer是“同时”执行的。以匿名返回值方法举例，过程如下。</p><p>将result赋值给返回值（可以理解成Go自动创建了一个返回值retValue，相当于执行retValue = result）<br>然后检查是否有defer，如果有则执行<br>返回刚才创建的返回值（retValue）<br>在这种情况下，defer中的修改是对result执行的，而不是retValue，所以defer返回的依然是retValue。在命名返回值方法中，由于返回值在方法定义时已经被定义，所以没有创建retValue的过程，result就是retValue，defer对于result的修改也会被直接返回。</p><h3 id="判断执行没有err之后，再defer释放资源"><a href="#判断执行没有err之后，再defer释放资源" class="headerlink" title="判断执行没有err之后，再defer释放资源"></a>判断执行没有err之后，再defer释放资源</h3><pre><code>resp, err := http.Get(url)// 先判断操作是否成功if err != nil {    return err}// 如果操作成功，再进行Close操作defer resp.Body.Close()</code></pre><p><strong>注释：</strong> 一些获取资源的操作可能会返回err参数，我们可以选择忽略返回的err参数，但是如果要使用defer进行延迟释放的的话，需要在使用defer之前先判断是否存在err，如果资源没有获取成功，即没有必要也不应该再对资源执行释放操作。如果不判断获取资源是否成功就执行释放操作的话，还有可能导致释放方法执行错误。</p><h3 id="调用os-Exit时defer不会被执行"><a href="#调用os-Exit时defer不会被执行" class="headerlink" title="调用os.Exit时defer不会被执行"></a>调用os.Exit时defer不会被执行</h3><pre><code>package mainimport (    &quot;fmt&quot;    &quot;os&quot;)func deferExit() {    defer func() {        fmt.Println(&quot;defer&quot;)    }()    fmt.Println(&quot;exit&quot;)    os.Exit(0)}func main() {    deferExit()}</code></pre><p><strong>结果输出：</strong></p><pre><code>exit</code></pre><p><strong>注释:</strong> 当发生panic时，所在goroutine的所有defer会被执行，但是当调用os.Exit()方法退出程序时，defer并不会被执行。</p><h2 id="panic-和recover-函数"><a href="#panic-和recover-函数" class="headerlink" title="panic()和recover()函数"></a>panic()和recover()函数</h2><p>Golang 语言内置函数panic()和recover()来处理程序中的错误。</p><pre><code>func recover() interface{}func panic(interface{})</code></pre><h3 id="panic-函数"><a href="#panic-函数" class="headerlink" title="panic()函数"></a>panic()函数</h3><p>当函数执行触发了panic()函数时，如果没有使用到defer关键字，函数执行流程会被立即终止；如果使用了defer关键字，则会逐层执行defer语句，直到所有的函数被终止。</p><p>错误信息，包括panic函数传入的参数，将会被报告出来。</p><pre><code>package mainfunc raiseErr(err interface{}){    panic(err)}func main() {    raiseErr(&quot;Unknow err&quot;)}</code></pre><p><strong>输出结果：</strong></p><pre><code>panic: Unknow errgoroutine 1 [running]:main.raiseErr(...)        E:/coding/go/test/test.go:5main.main()        E:/coding/go/test/test.go:9 +0x40</code></pre><p><strong>注释:</strong> 以上程序直接终止抛出异常。、相当于C++/Python里面的异常抛出，如果外围函数没有接住异常，便使得程序终止退出。</p><h3 id="recover-函数"><a href="#recover-函数" class="headerlink" title="recover()函数"></a>recover()函数</h3><p>recover()函数用于终止错误处理流程。一般使用在defer关键字后以有效截取错误处理流程。如果没有在发生异常的goroutine中明确调用恢复过程（使用recover关键字） ，会导致该goroutine所属的进程打印异常信息后直接退出。</p><pre><code>package mainimport (    &quot;fmt&quot;)func raiseErr(err interface{}){    panic(err)}func main() {    defer func() {        if r := recover(); r != nil {            fmt.Printf(&quot;Exception error caught: %v\n&quot;, r)        }    }()    raiseErr(&quot;Unknow err&quot;)}</code></pre><p><strong>结果输出：</strong></p><pre><code>Exception error caught: Unknow err</code></pre><p><strong>注释:</strong> raiseErr(“Unknow err”))中触发了错误处理流程，该匿名defer函数都将在函数退出时得到执行。 recover()函数执行将使得该错误处理过程终止。此时错误处理流程被触发时，程序传给panic函数的参数不为nil，则该函数还会打印详细的错误信息。</p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Golang 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang channel</title>
      <link href="/2020-04-02-Golang_channel/"/>
      <url>/2020-04-02-Golang_channel/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="channel简介"><a href="#channel简介" class="headerlink" title="channel简介"></a>channel简介</h2><p>channel俗称管道，用于数据传递或数据共享，其本质是一个先进先出的队列，使用goroutine+channel进行数据通讯简单高效，同时也线程安全，多个goroutine可同时修改一个channel，<strong>不需要加锁</strong> 。</p><p>channel可分为三种类型：</p><ul><li><p>只读channel：只能读channel里面数据，不可写入</p></li><li><p>只写channel：只能写数据，不可读</p></li><li><p>一般channel：可读可写</p></li></ul><h3 id="channel使用"><a href="#channel使用" class="headerlink" title="channel使用"></a>channel使用</h3><p>定义和声明</p><pre><code>var readOnlyChan &lt;-chan int            // 只读chanvar writeOnlyChan chan&lt;- int           // 只写chanvar mychan  chan int                     //读写channel//定义完成以后需要make来分配内存空间，不然使用会deadlockmychannel = make(chan int,10)//或者read_only := make (&lt;-chan int,10)//定义只读的channelwrite_only := make (chan&lt;- int,10)//定义只写的channelread_write := make (chan int,10)//可同时读写//操作write_only &lt;- &quot;wd&quot;  //写数据a := &lt;- read_only //读取数据a, ok := &lt;- read_only  //优雅的读取数据</code></pre><p><strong>注：</strong></p><ul><li>读写操作注意：<ul><li>管道如果未关闭，在读取超时会则会引发deadlock异常</li><li>管道如果关闭进行写入数据会pannic</li><li>当管道中没有数据时候再行读取或读取到默认值，如int类型默认值是0</li></ul></li><li>循环管道注意：<ul><li>使用range循环管道，如果管道未关闭会引发deadlock错误。</li><li>如果采用for死循环已经关闭的管道，当管道没有数据时候，读取的数据会是管道的默认值，并且循环不会退出。</li></ul></li></ul><p>示例代码：</p><pre><code>package mainimport (    &quot;fmt&quot;    &quot;time&quot;)func main() {    mychannel := make(chan int,10)    for i := 0;i &lt; 10;i++{        mychannel &lt;- i    }    close(mychannel)  //关闭管道    fmt.Println(&quot;data lenght: &quot;,len(mychannel))    for  v := range mychannel {  //循环管道        fmt.Println(v)    }    fmt.Printf(&quot;data lenght:  %d&quot;,len(mychannel))}</code></pre><h3 id="带缓冲区channel和不带缓冲区channel"><a href="#带缓冲区channel和不带缓冲区channel" class="headerlink" title="带缓冲区channel和不带缓冲区channel"></a>带缓冲区channel和不带缓冲区channel</h3><p>带缓冲区channel：定义声明时候制定了缓冲区大小(长度)，可以保存多个数据。</p><pre><code>ch := make(chan int ,10) //带缓冲区</code></pre><p>不带缓冲区channel：只能存一个数据，并且只有当该数据被取出时候才能存下一个数据。</p><pre><code>ch := make(chan int) //不带缓冲区</code></pre><h3 id="channel实现作业池"><a href="#channel实现作业池" class="headerlink" title="channel实现作业池"></a>channel实现作业池</h3><p>创建三个channel，一个channel用于接受任务，一个channel用于保持结果，还有个channel用于决定程序退出的时候。</p><pre><code>package mainimport (    &quot;fmt&quot;)func Task(taskch, resch chan int, exitch chan bool) {    defer func() {   //异常处理        err := recover()        if err != nil {            fmt.Println(&quot;do task error：&quot;, err)            return        }    }()    for t := range taskch { //  处理任务        fmt.Println(&quot;do task :&quot;, t)        resch &lt;- t //    }    exitch &lt;- true //处理完发送退出信号}func main() {    taskch := make(chan int, 20) //任务管道    resch := make(chan int, 20)  //结果管道    exitch := make(chan bool, 5) //退出管道    go func() {        for i := 0; i &lt; 10; i++ {            taskch &lt;- i        }        close(taskch)    }()    for i := 0; i &lt; 5; i++ {  //启动5个goroutine做任务        go Task(taskch, resch, exitch)    }    go func() { //等5个goroutine结束        for i := 0; i &lt; 5; i++ {            &lt;-exitch        }        close(resch)  //任务处理完成关闭结果管道，不然range报错        close(exitch)  //关闭退出管道    }()    for res := range resch{  //打印结果        fmt.Println(&quot;task res：&quot;,res)    }}</code></pre><h3 id="select-case实现非阻塞channel"><a href="#select-case实现非阻塞channel" class="headerlink" title="select-case实现非阻塞channel"></a>select-case实现非阻塞channel</h3><p>原理通过select+case加入一组管道，当满足（这里说的满足意思是有数据可读或者可写)select中的某个case时候，那么该case返回，若都不满足case，则走default分支。</p><pre><code>package mainimport (    &quot;fmt&quot;)func send(c chan int)  {    for i :=1 ; i&lt;10 ;i++  {    c &lt;-i    fmt.Println(&quot;send data : &quot;,i)    }}func main() {    resch := make(chan int,20)    strch := make(chan string,10)    go send(resch)    strch &lt;- &quot;wd&quot;    select {    case a := &lt;-resch:        fmt.Println(&quot;get data : &quot;, a)    case b := &lt;-strch:        fmt.Println(&quot;get data : &quot;, b)    default:        fmt.Println(&quot;no channel actvie&quot;)    }}</code></pre><h3 id="channel频率控制"><a href="#channel频率控制" class="headerlink" title="channel频率控制"></a>channel频率控制</h3><p>在对channel进行读写的时，go还提供了非常人性化的操作，那就是对读写的频率控制，通过time.Ticke实现</p><pre><code>package mainimport (    &quot;time&quot;    &quot;fmt&quot;)func main(){    requests:= make(chan int ,5)    for i:=1;i&lt;5;i++{        requests&lt;-i    }    close(requests)    limiter := time.Tick(time.Second*1)    for req:=range requests{        &lt;-limiter        fmt.Println(&quot;requets&quot;,req,time.Now()) //执行到这里，需要隔1秒才继续往下执行，time.Tick(timer)上面已定义    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Golang 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes(十二)之ConfigMap资源对象</title>
      <link href="/2020-04-02-Kubernetes(%E5%8D%81%E4%BA%8C)%E4%B9%8BConfigMap%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1/"/>
      <url>/2020-04-02-Kubernetes(%E5%8D%81%E4%BA%8C)%E4%B9%8BConfigMap%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="ConfigMap资源对象"><a href="#ConfigMap资源对象" class="headerlink" title="ConfigMap资源对象"></a>ConfigMap资源对象</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>ConfigMap对象实现了将配置文件从容器镜像中解耦，从而增强了容器应用的可移植性。简而言之，一个ConfigMap就是一系列配置数据的集合(如单个属性，或粗粒度信息如整个配置文件或JSON对象)，这些数据可“注入”到Pod对象中，并为容器应用所使用，注入方式有挂载为存储卷和传递为环境变量两种。</p><p>ConfigMap 对象将配置数据以键值对的形式存储，这些数据可以在Pod对象中使用或者为系统组件提供配置。</p><h2 id="ConfigMap使用方式"><a href="#ConfigMap使用方式" class="headerlink" title="ConfigMap使用方式"></a>ConfigMap使用方式</h2><ul><li>填充环境变量</li><li>设置容器内的命令行参数</li><li>填充卷的配置文件</li></ul><h2 id="ConfigMap创建方式"><a href="#ConfigMap创建方式" class="headerlink" title="ConfigMap创建方式"></a>ConfigMap创建方式</h2><ul><li><p>直接在命令行中指定configmap参数创建，即–from-literal</p></li><li><p>指定文件创建，即将一个配置文件创建为一个ConfigMap–from-file=&lt;文件&gt;</p></li><li><p>指定目录创建，即将一个目录下的所有配置文件创建为一个ConfigMap，–from-file=&lt;目录&gt;</p></li><li><p>先写好标准的configmap的yaml文件，然后kubectl create -f 创建</p></li></ul><h2 id="Yaml创建方式示例"><a href="#Yaml创建方式示例" class="headerlink" title="Yaml创建方式示例"></a>Yaml创建方式示例</h2><h3 id="场景介绍"><a href="#场景介绍" class="headerlink" title="场景介绍"></a>场景介绍</h3><p>在Kubernetes中部署Elasticsearch集群创建时，需要配置集群名称以及集群待加入节点信息，和设置集群master最少节点要求等配置，使用confmap来作为填充卷方式让Pod进行挂载容器内的文件路径/usr/share/elasticsearch/config/elasticsearch.yml，来提供elasticsearch.yml配置文件内容。</p><h3 id="ConfigMap-Yaml"><a href="#ConfigMap-Yaml" class="headerlink" title="ConfigMap Yaml"></a>ConfigMap Yaml</h3><pre><code>apiVersion: v1kind: ConfigMapmetadata:  name: &quot;es-config&quot;data:  elasticsearch.yml: |    cluster.name: ${CLUSTER_NAME}    network.host: &quot;0.0.0.0&quot;    bootstrap.memory_lock: false    node.master: ${NODE_MASTER}    discovery.zen.ping.unicast.hosts: ${DISCOVERY_ZEN_PING_UNICAST_HOSTS}    discovery.zen.minimum_master_nodes: ${DISCOVERY_ZEN_MINIMUM_MASTER_NODES}</code></pre><h3 id="Pod-局部定义YAML"><a href="#Pod-局部定义YAML" class="headerlink" title="Pod 局部定义YAML"></a>Pod 局部定义YAML</h3><pre><code>spec:  initContainers:    - name: fix-permissions      image: &quot;{{ .ImageBusyBox }}&quot;      command: [&quot;sh&quot;, &quot;-c&quot;, &quot;chown -R 1000:1000 /usr/share/elasticsearch/data&quot;]      securityContext:        privileged: true      volumeMounts:        - name: data          mountPath: /usr/share/elasticsearch/data    - name: increase-vm-max-map      image: &quot;{{ .ImageBusyBox }}&quot;      command: [&quot;sysctl&quot;, &quot;-w&quot;, &quot;vm.max_map_count=262144&quot;]      securityContext:        privileged: true    - name: increase-fd-ulimit      image: &quot;{{ .ImageBusyBox }}&quot;      command: [&quot;sh&quot;, &quot;-c&quot;, &quot;ulimit -n 65536&quot;]      securityContext:        privileged: true  containers:    - name: elasticsearch      image: &quot;{{ .ImageEs}}&quot;      imagePullPolicy: Always      env:        - name: CLUSTER_NAME          value: &quot;sb-{{ .InstanceID }}-es-cluster&quot;        - name:  NODE_MASTER          value: &quot;true&quot;        - name: ES_JAVA_OPTS          value: &quot;-Xms512m -Xmx512m&quot;        - name: DISCOVERY_ZEN_PING_UNICAST_HOSTS          value: &quot;sb-{{ .InstanceID }}-es-cluster-discovery&quot;        - name: DISCOVERY_ZEN_MINIMUM_MASTER_NODES          value: &quot;{{ .MasterMinNumber }}&quot;      # - name: &quot;bootstrap.memory_lock&quot;      #   value: &quot;true&quot;      ports:        - containerPort: 9200          protocol: TCP          name: discovery        - containerPort: 9300          protocol: TCP          name: transport      volumeMounts:        - mountPath: /usr/share/elasticsearch/data          name: data        - mountPath: /usr/share/elasticsearch/logs          name: data        - mountPath: /usr/share/elasticsearch/config/elasticsearch.yml          name: elasticsearch-config          subPath: elasticsearch.yml      resources:        limits:          memory: &quot;{{ .ContainerMemory }}Gi&quot;          cpu: &quot;{{ .ContainerCPU }}&quot;  nodeSelector:    kubernetes.io/hostname: &quot;{{ .TempHost }}&quot;  volumes:    - name: data      hostPath:        path: &quot;{{ .TempDataPath}}&quot;    - name: elasticsearch-config      configMap:        name: &quot;es-config&quot;</code></pre><p>volumeMounts:将容器内要替换的配置文件路径/usr/share/elasticsearch/config/elasticsearch.yml设置为挂载点。将configmap设置成挂载卷的防止进行使用。</p><h3 id="容器内部查看"><a href="#容器内部查看" class="headerlink" title="容器内部查看"></a>容器内部查看</h3><pre><code>[root@sb-bsi-es-12161721-33-es-instanceid-0-0 config]# pwd/usr/share/elasticsearch/config[root@sb-bsi-es-12161721-33-es-instanceid-0-0 config]# lselasticsearch.keystore  jvm.options        role_mapping.yml  userselasticsearch.yml       log4j2.properties  roles.yml         users_roles[root@sb-bsi-es-12161721-33-es-instanceid-0-0 config]# cat elasticsearch.ymlcluster.name: ${CLUSTER_NAME}network.host: &quot;0.0.0.0&quot;bootstrap.memory_lock: falsenode.master: ${NODE_MASTER}discovery.zen.ping.unicast.hosts: ${DISCOVERY_ZEN_PING_UNICAST_HOSTS}discovery.zen.minimum_master_nodes: ${DISCOVERY_ZEN_MINIMUM_MASTER_NODES}[root@sb-bsi-es-12161721-33-es-instanceid-0-0 config]#</code></pre><p>通过运行起来的服务我们进容器中查看目标挂载文件，已经从configmap设置的配置文件挂载进来了。</p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Kubernetes 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang goroutine</title>
      <link href="/2020-04-02-Golang_goroutine/"/>
      <url>/2020-04-02-Golang_goroutine/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="goroutine简介"><a href="#goroutine简介" class="headerlink" title="goroutine简介"></a>goroutine简介</h2><p>goroutine是go语言中最为NB的设计，也是其魅力所在，goroutine的本质是协程，是实现并行计算的核心。goroutine使用方式非常的简单，只需使用go关键字即可启动一个协程，并且它是处于异步方式运行，你不需要等它运行完成以后在执行以后的代码。GO默认是使用一个CPU核的，除非设置runtime.GOMAXPROCS。</p><pre><code>go func()//通过go关键字启动一个协程来运行函数   </code></pre><h2 id="概念普及"><a href="#概念普及" class="headerlink" title="概念普及"></a>概念普及</h2><ul><li><strong>并发</strong>：</li></ul><p><strong>一个cpu上</strong>能同时执行多项任务，在很短时间内，cpu来回切换任务执行(在某段很短时间内执行程序a，然后又迅速得切换到程序b去执行)，有时间上的重叠（宏观上是同时的，微观仍是顺序执行）,这样看起来多个任务像是同时执行，这就是并发。</p><ul><li><strong>并行</strong><br>当系统有<strong>多个CPU</strong>(多核)时,每个CPU同一时刻都运行任务，互不抢占自己所在的CPU资源，同时进行，称为并行。</li><li><strong>进程</strong><br>cpu在切换程序的时候，如果不保存上一个程序的状态（也就是我们常说的context–上下文），直接切换下一个程序，就会丢失上一个程序的一系列状态，于是引入了进程这个概念，用以划分好程序运行时所需要的资源。因此进程就是一个程序运行时候的所需要的基本资源单位（也可以说是程序运行的一个实体）。(系统进行资源分配和调度的基本单位)</li><li><strong>线程</strong><br>cpu切换多个进程的时候，会花费不少的时间，因为切换进程需要切换到内核态，而每次调度需要内核态都需要读取用户态的数据，进程一旦多起来，cpu调度会消耗一大堆资源，因此引入了线程的概念，线程本身几乎不占有资源，他们共享进程里的资源，内核调度起来不会那么像进程切换那么耗费资源。</li><li><strong>协程</strong><br>协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此，协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态，换种说法：进入上一次离开时所处逻辑流的位置。线程和进程的操作是由程序触发系统接口，最后的执行者是系统；协程的操作执行者则是用户自身程序，goroutine也是协程。协程位于线程级别</li></ul><h2 id="调度模型简介"><a href="#调度模型简介" class="headerlink" title="调度模型简介"></a>调度模型简介</h2><p>groutine能拥有强大的并发实现是通过GPM调度模型实现。<br>Go的调度器内部有四个重要的结构：M，P，G，Sched</p><ul><li><strong>M</strong> :代表内核级线程，一个M就是一个线程，goroutine就是跑在M之上的；M是一个很大的结构，里面维护小对象内存cache（mcache）、当前执行的goroutine、随机数发生器等等非常多的信息。</li><li><strong>G</strong> :代表一个goroutine，它有自己的栈，instruction pointer和其他信息（正在等待的channel等等），用于调度。</li><li><strong>P</strong> :全称是Processor，处理器，它的主要用途就是用来执行goroutine的，所以它也维护了一个goroutine队列，里面存储了所有需要它来执行的goroutine。</li><li><strong>Sched</strong> ：代表调度器，它维护有存储M和G的队列以及调度器的一些状态信息等。</li></ul><h2 id="调度实现场景"><a href="#调度实现场景" class="headerlink" title="调度实现场景"></a>调度实现场景</h2><p><strong>一般调度如下图所示：</strong></p><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-cb5bc6d48c41a052.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="goroutine.png"> </p><p>从上图中看，有2个物理线程M1和M2，每一个M都拥有一个处理器P，每一个也都有一个正在运行的goroutine。<br>P的数量可以通过GOMAXPROCS()来设置，它其实也就代表了真正的并发度，即有多少个goroutine可以同时运行。<br>图中灰色的那些goroutine并没有运行，而是出于ready的就绪态，正在等待被调度。P维护着这个队列（称之为runqueue），<br>Go语言里，启动一个goroutine很容易：go function 就行，所以每有一个go语句被执行，runqueue队列就在其末尾加入一个<br>goroutine，在下一个调度点，就从runqueue中取出（如何决定取哪个goroutine？）一个goroutine执行。</p><p><strong>当一个OS线程M1陷入阻塞时：</strong></p><p>P转而在运行M2，图中的M2可能是正被创建，或者从线程缓存中取出。当M1返回时，它必须尝试取得一个P来运行goroutine，一般情况下，它会从其他的OS线程那里拿一个P过来，</p><p>如果没有拿到的话，它就把goroutine放在一个global runqueue里，然后自己睡眠（放入线程缓存里）。所有的P也会周期性的检查global runqueue并运行其中的goroutine，否则global runqueue上的goroutine永远无法执行。</p><p><strong>调度分配不均：如下图所示</strong></p><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-5ee5fd44bfd36c3e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="goroutine1.png"></p><p>P所分配的任务G很快就执行完了（分配不均），这就导致了这个处理器P很忙，但是其他的P还有任务，此时如果global runqueue没有任务G了，那么P不得不从其他的P里拿一些G来执行。一般来说，如果P从其他的P那里要拿任务的话，<strong>一般就拿run queue的一半</strong> ，这就确保了每个OS线程都能充分的使用。</p><h2 id="使用goroutine"><a href="#使用goroutine" class="headerlink" title="使用goroutine"></a>使用goroutine</h2><h3 id="goroutine异常捕获"><a href="#goroutine异常捕获" class="headerlink" title="goroutine异常捕获"></a>goroutine异常捕获</h3><pre><code>package mainimport (    &quot;fmt&quot;    &quot;time&quot;)func addele(a []int ,i int)  {    defer func() {    //匿名函数捕获错误        err := recover()        if err != nil {            fmt.Println(err)        }    }()a[i]=ifmt.Println(a)}func main() {    Arry := make([]int,4)    for i :=0 ; i&lt;10 ;i++{        go addele(Arry,i)    }    time.Sleep(time.Second * 2)}</code></pre><h3 id="同步的goroutine"><a href="#同步的goroutine" class="headerlink" title="同步的goroutine"></a>同步的goroutine</h3><p>由于goroutine是异步执行的，那很有可能出现主程序退出时还有goroutine没有执行完，此时goroutine也会跟着退出。此时如果想等到所有goroutine任务执行完毕才退出，go提供了sync包和channel来解决同步问题，当然如果你能预测每个goroutine执行的时间，你还可以通过time.Sleep方式等待所有的groutine执行完成以后在退出程序(如上面的列子)。</p><p><strong>示例一：使用sync包同步goroutine</strong></p><p>sync大致实现方式:<br>WaitGroup 等待一组goroutinue执行完毕. 主程序调用 Add 添加等待的goroutinue数量. 每个goroutinue在执行结束时调用 Done ，此时等待队列数量减1.，主程序通过Wait阻塞，直到等待队列为0.</p><pre><code>package mainimport (    &quot;fmt&quot;    &quot;sync&quot;)func cal(a int , b int ,n *sync.WaitGroup)  {    c := a+b    fmt.Printf(&quot;%d + %d = %d\n&quot;,a,b,c)    defer n.Done() //goroutinue完成后, WaitGroup的计数-1}func main() {    var go_sync sync.WaitGroup //声明一个WaitGroup变量    for i :=0 ; i&lt;10 ;i++{        go_sync.Add(1) // WaitGroup的计数加1        go cal(i,i+1,&amp;go_sync)      }    go_sync.Wait()  //等待所有goroutine执行完毕}</code></pre><p><strong>示例二：通过channel实现goroutine之间的同步。</strong></p><p>channel实现方式：<br>通过channel能在多个groutine之间通讯，当一个goroutine完成时候向channel发送退出信号,等所有goroutine退出时候，利用for循环channel,取channel中的信号，若取不到数据便会阻塞原理，等待所有goroutine执行完毕，使用该方法有个前提是你已经知道了你启动了多少个goroutine。</p><pre><code>package mainimport (    &quot;fmt&quot;    &quot;time&quot;)func cal(a int , b int ,Exitchan chan bool)  {    c := a+b    fmt.Printf(&quot;%d + %d = %d\n&quot;,a,b,c)    time.Sleep(time.Second*2)    Exitchan &lt;- true}func main() {    Exitchan := make(chan bool,10)  //声明并分配管道内存    for i :=0 ; i&lt;10 ;i++{        go cal(i,i+1,Exitchan)    }    for j :=0; j&lt;10; j++{           &lt;- Exitchan  //取信号数据，如果取不到则会阻塞    }    close(Exitchan) // 关闭管道}</code></pre><h3 id="goroutine之间的通讯"><a href="#goroutine之间的通讯" class="headerlink" title="goroutine之间的通讯"></a>goroutine之间的通讯</h3><p>goroutine本质上是协程，可以理解为不受内核调度，而受go调度器管理的线程。goroutine之间可以通过channel进行通信或者说是数据共享，当然你也可以使用全局变量来进行数据共享。<br>示例代码：采用生产者和消费者模式</p><pre><code>package mainimport (    &quot;fmt&quot;    &quot;sync&quot;)func Productor(mychan chan int,data int,wait *sync.WaitGroup)  {    mychan &lt;- data    fmt.Println(&quot;product data：&quot;,data)    defer wait.Done()}func Consumer(mychan chan int,wait *sync.WaitGroup)  {    a := &lt;- mychan    fmt.Println(&quot;consumer data：&quot;,a)    defer wait.Done()}func main() {    datachan := make(chan int, 100)   //通讯数据管道    var wg sync.WaitGroup    for i := 0; i &lt; 10; i++ {        go Productor(datachan, i,&amp;wg) //生产数据        wg.Add(1)    }    for j := 0; j &lt; 10; j++ {        go Consumer(datachan,&amp;wg)  //消费数据        wg.Add(1)    }    wg.Wait()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Golang 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>僵尸进程与孤儿进程</title>
      <link href="/2020-04-02-zombie-process/"/>
      <url>/2020-04-02-zombie-process/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="僵尸进程与孤儿进程"><a href="#僵尸进程与孤儿进程" class="headerlink" title="僵尸进程与孤儿进程"></a>僵尸进程与孤儿进程</h1><h3 id="进程状态："><a href="#进程状态：" class="headerlink" title="进程状态："></a>进程状态：</h3><p>就绪，运行，阻塞，阻塞挂起，就绪挂起</p><h3 id="僵尸进程："><a href="#僵尸进程：" class="headerlink" title="僵尸进程："></a>僵尸进程：</h3><p>即子进程先于父进程退出后，子进程的<strong>PCB</strong>需要其父进程释放，但是父进程并没有释放子进程的PCB，这样的子进程就称为僵尸进程，僵尸进程实际上是一个已经死掉的进程.用ps可以看到子进程后有一个<defunct> ,defunct是已死的，僵尸的意思.一个进程在调用exit命令结束自己的生命的时候，其实它并没有真正的被销毁，而是留下一个称为僵尸进程（Zombie）的数据结构（系统调用exit，它的作用是使进程退出，但也仅仅限于将一个正常的进程变成一个僵尸进程，并不能将其完全销毁）在Linux进程的状态中，僵尸进程是非常特殊的一种，它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程列表中保留一个位置,记载该进程的退出状态等信息供其他进程收集，除此之外，僵尸进程不再占有任何内存空间。这个僵尸进程需要它的父进程来为它收尸，如果他的父进程没有处理这个僵尸进程的措施，那么它就一直保持僵尸状态，如果这时父进程结束了，那么<strong>init</strong>进程自动会接手这个子进程，为它收尸，它还是能被清除的。<strong>但是如果如果父进程是一个循环</strong>，不会结束，那么子进程就会一直保持僵尸状态.</defunct></p><p><strong>注：</strong> 如果有大量的僵尸进程驻在系统之中，必然消耗大量的系统资源。但是系统资源是有限的，因此当僵尸进程达到一定数目时，系统因缺乏资源而导致奔溃。</p><h3 id="孤儿进程："><a href="#孤儿进程：" class="headerlink" title="孤儿进程："></a>孤儿进程：</h3><p>一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被<strong>init</strong>进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。</p><p>子进程死亡需要父进程来处理，那么意味着正常的进程应该是子进程先于父进程死亡。当父进程先于子进程死亡时，子进程死亡时没父进程处理，这个死亡的子进程就是孤儿进程。<br><strong>注：</strong> 但孤儿进程与僵尸进程不同的是，由于父进程已经死亡，系统会帮助父进程回收处理孤儿进程。所以孤儿进程实际上是不占用资源的，因为它终究是被系统回收了。不会像僵尸进程那样占用ID,损害运行系统。</p><h3 id="僵尸进程处理方式"><a href="#僵尸进程处理方式" class="headerlink" title="僵尸进程处理方式"></a>僵尸进程处理方式</h3><ul><li><p>1.暴力解决：<br>将其父进程杀死，那么它的子进程，即僵尸进程会变成孤儿进程，由系统来回收。但是这种做法在大多数情况下都是不可取的，如父进程是一个服务器程序，如果为了回收其子进程的资源，而杀死服务器程序，那么将导致整个服务器崩溃，得不偿失。显然这种回收进程的方式是不可取的，但其也有一定的存在意义。</p></li><li><p>2.SIGCHLD信号处理：<br>当子进程终止时，内核就会向它的父进程发送一个SIGCHLD信号，父进程可以选择忽略该信号，也可以提供一个接收到信号以后的处理函数。对于这种信号的系统默认动作是忽略它。我们不希望有过多的僵尸进程产生，所以当父进程接收到SIGCHLD信号后就应该调用 wait 或 waitpid 函数对子进程进行善后处理，释放子进程占用的资源。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 效率 </tag>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes(五)之POD控制器对象ReplicaSet</title>
      <link href="/2020-03-13-Kubernetes(%E4%BA%94)%E4%B9%8BPOD%E6%8E%A7%E5%88%B6%E5%99%A8%E5%AF%B9%E8%B1%A1ReplicaSet/"/>
      <url>/2020-03-13-Kubernetes(%E4%BA%94)%E4%B9%8BPOD%E6%8E%A7%E5%88%B6%E5%99%A8%E5%AF%B9%E8%B1%A1ReplicaSet/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="POD控制器对象ReplicaSet"><a href="#POD控制器对象ReplicaSet" class="headerlink" title="POD控制器对象ReplicaSet"></a>POD控制器对象ReplicaSet</h1><h2 id="ReplicaSet介绍"><a href="#ReplicaSet介绍" class="headerlink" title="ReplicaSet介绍"></a>ReplicaSet介绍</h2><h3 id="什么是ReplicaSet？"><a href="#什么是ReplicaSet？" class="headerlink" title="什么是ReplicaSet？"></a>什么是ReplicaSet？</h3><p>ReplicaSet是下一代复本控制器，是Replication Controller（RC）的升级版本。ReplicaSet和 Replication Controller之间的唯一区别是对选择器的支持。ReplicaSet支持labels user guide中描述的set-based选择器要求， 而Replication Controller仅支持equality-based的选择器要求。</p><h3 id="如何使用ReplicaSet？"><a href="#如何使用ReplicaSet？" class="headerlink" title="如何使用ReplicaSet？"></a>如何使用ReplicaSet？</h3><p>大多数kubectl 支持Replication Controller 命令的也支持ReplicaSets。rolling-update命令除外，如果要使用rolling-update，请使用Deployments来实现。</p><p>　　虽然ReplicaSets可以独立使用，但它主要被 <strong>Deployments</strong>用作pod 机制的创建、删除和更新。当使用Deployment时，你不必担心创建pod的ReplicaSets，因为可以通过Deployment实现管理ReplicaSets</p><h3 id="何时使用ReplicaSet？"><a href="#何时使用ReplicaSet？" class="headerlink" title="何时使用ReplicaSet？"></a>何时使用ReplicaSet？</h3><p><strong>ReplicaSet能确保运行指定数量的pod</strong>。然而，Deployment 是一个更高层次的概念，它能管理ReplicaSets，并提供对pod的更新等功能。因此，我们建议你使用Deployment来管理ReplicaSets，除非你需要自定义更新编排。</p><p>　　这意味着你可能永远不需要操作ReplicaSet对象，而是使用Deployment替代管理 。</p><h2 id="ReplicaSet对象定义"><a href="#ReplicaSet对象定义" class="headerlink" title="ReplicaSet对象定义"></a>ReplicaSet对象定义</h2><ul><li><strong>apiVersion</strong>: app/v1  版本</li><li><strong>kind</strong>:  ReplicaSet  类型</li><li><strong>metadata</strong>:  元数据</li><li><strong>spec</strong>:   期望状态<ul><li><strong>minReadySeconds</strong>: 应为新创建的pod准备好的最小秒数</li><li><strong>replicas</strong>: 副本数； 默认为1</li><li><strong>selector</strong>: 标签选择器</li><li><strong>template</strong>: pod模板<ul><li><strong>metadata</strong>: pod模板中的元数据</li><li><strong>spec</strong>: pod模板中的期望状态</li></ul></li></ul></li></ul><h2 id="ReplicaSet创建示例"><a href="#ReplicaSet创建示例" class="headerlink" title="ReplicaSet创建示例"></a>ReplicaSet创建示例</h2><h3 id="Yaml示例"><a href="#Yaml示例" class="headerlink" title="Yaml示例"></a>Yaml示例</h3><pre><code>apiVersion: apps/v1kind: ReplicaSetmetadata:  name: myapp  namespace: defaultspec:  replicas: 2  selector:    matchLabels:      app: myapp  template:    metadata:      name: myapp-pod      labels:        app: myapp    spec:      containers:      - name: myapp-container        image: docker.io/busybox:latest        command: [&quot;sh&quot;,&quot;-c&quot;,&quot;sleep 3600&quot;]</code></pre><h3 id="创建结果"><a href="#创建结果" class="headerlink" title="创建结果"></a>创建结果</h3><ul><li><p>创建</p><pre><code># kubectl create -f rs-demo.yamlreplicaset.apps/myapp created</code></pre></li><li><p>查看Replicaset状态</p><pre><code># kubectl get rsNAME      DESIRED   CURRENT   READY     AGEmyapp     2         2         2         23s</code></pre></li><li><p>查看pod 状态</p><pre><code># kubectl get podsNAME          READY     STATUS    RESTARTS   AGEmyapp-r4ss4   1/1       Running   0          25smyapp-zjc5l   1/1       Running   0          26s</code></pre><p>  生产的pod原则(多退少补)：根据replicas配置保证生成相应数量的pod。</p></li></ul><h2 id="ReplicaSet扩所容"><a href="#ReplicaSet扩所容" class="headerlink" title="ReplicaSet扩所容"></a>ReplicaSet扩所容</h2><ul><li><p>使用edit 修改replicaset 配置，将副本数改为5；即可实现动态扩容</p><pre><code># kubectl edit rs myapp... ...spec:replicas: 5... ...replicaset.extensions/myapp edited</code></pre></li><li><p>查看结果 </p><pre><code># kubectl get podsNAME          READY     STATUS    RESTARTS   AGEmyapp-bck7l   1/1       Running   0          16smyapp-h8cqr   1/1       Running   0          16smyapp-hfb72   1/1       Running   0          6mmyapp-r4ss4   1/1       Running   0          9mmyapp-vvpgf   1/1       Running   0          16s</code></pre></li></ul><h2 id="ReplicaSet在线升级"><a href="#ReplicaSet在线升级" class="headerlink" title="ReplicaSet在线升级"></a>ReplicaSet在线升级</h2><p>原理同扩所容同样，进行编辑replicaset 对containers对应的image进行版本升级修改。<strong>注</strong>：修改完并没有升级需删除pod，再自动生成新的pod时，就会升级成功；即可以实现灰度发布：删除一个，会自动启动一个版本升级成功的pod</p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Kubernetes 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes(八)亲和性与反亲和性</title>
      <link href="/2020-03-27-Kubernetes(%E5%85%AB)%E4%BA%B2%E5%92%8C%E6%80%A7%E4%B8%8E%E8%BF%94%E4%BA%B2%E5%92%8C%E6%80%A7/"/>
      <url>/2020-03-27-Kubernetes(%E5%85%AB)%E4%BA%B2%E5%92%8C%E6%80%A7%E4%B8%8E%E8%BF%94%E4%BA%B2%E5%92%8C%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="亲和性与反亲和性"><a href="#亲和性与反亲和性" class="headerlink" title="亲和性与反亲和性"></a>亲和性与反亲和性</h1><p>nodeSelector 提供了一个非常简单的方式，将 Pod 调度限定到包含特定标签的节点上。亲和性与反亲和性（affinity / anti-affinity）特性则极大地扩展了限定的表达方式。主要的增强点在于：</p><p>表达方式更加有效（不仅仅是多个精确匹配表达式的“和”关系）可以标识该规则为“soft” / “preference” （软性的、偏好的）而不是 hard requirement（必须的），此时，如果调度器发现该规则不能被满足，Pod 仍然可以被调度<br>可以对比节点上（或其他拓扑域 topological domain）已运行的其他 Pod 的标签，而不仅仅是节点自己的标签，此时，可以定义类似这样的规则：某两类 Pod 不能在同一个节点（或拓扑域）上共存</p><p>例如控制器DaemonSet 是决定了POD在集群中每个可调度节点上都保证运行1个副本存。但是对于DeployMent、ReplicatSet、StatefulSet。这种是保证在集群中可调度节点上运行一定数量Rplicas的Pod。对于只想在满足限制条件的节点上且运行一个POD那么久需要用到Pod的反亲和来实现。</p><h2 id="节点亲和性"><a href="#节点亲和性" class="headerlink" title="节点亲和性"></a>节点亲和性</h2><p>节点亲和性（node affinity）的概念与 nodeSelector 相似，可以基于节点的标签来限定 Pod 可以被调度到哪些节点上。</p><p>当前支持两种类型的节点亲和性：</p><ul><li><p><strong>requiredDuringSchedulingIgnoredDuringExecution</strong> （hard，目标节点必须满足此条件 </p></li><li><p><strong>preferredDuringSchedulingIgnoredDuringExecution</strong> （soft，目标节点最好能满足此条件）。</p></li></ul><p>名字中 <strong>IgnoredDuringExecution</strong> 意味着：如果 Pod 已经调度到节点上以后，节点的标签发生改变，使得节点已经不再匹配该亲和性规则了，Pod 仍将继续在节点上执行（这一点与 <strong>nodeSelector</strong> 相似）。将来，Kubernetes 将会提供 requiredDuringSchedulingRequiredDuringExecution 这个选项，该选项与 requiredDuringSchedulingIgnoredDuringExecution 相似，不同的是，当节点的标签不在匹配亲和性规则之后，Pod 将被从节点上驱逐。</p><p>requiredDuringSchedulingIgnoredDuringExecution 的一个例子是，只在 Intel CPU 上运行该 Pod，preferredDuringSchedulingIgnoredDuringExecution 的一个例子是，尽量在高可用区 XYZ 中运行这个 Pod，但是如果做不到，也可以在其他地方运行该 Pod。</p><p><strong>注：</strong> 如果某个 Pod 同时指定了 nodeSelector 和 nodeAffinity，则目标节点必须同时满足两个条件，才能将 Pod 调度到该节点上。</p><p>如果为 nodeAffinity 指定多个 nodeSelectorTerms，则目标节点只需要满足任意一个 nodeSelectorTerms 的要求，就可以将 Pod 调度到该节点上。</p><p>如果为 nodeSelectorTerms 指定多个 matchExpressions，则目标节点必须满足所有的 matchExpressions 的要求，才能将 Pod 调度到该节点上。</p><p>当 Pod 被调度到某节点上之后，如果移除或者修改节点的标签，Pod 将仍然继续在节点上运行。换句话说，节点亲和性规则只在调度该 Pod 时发生作用。</p><p><strong>示例说明：</strong></p><pre><code>apiVersion: v1kind: Podmetadata:  name: node-affinityspec:  affinity:    nodeAffinity:      requiredDuringSchedulingIgnoredDuringExecution:        nodeSelectorTerms:        - matchExpressions:          - key: kubernetes.io/appmanager            operator: In            values:            - true      preferredDuringSchedulingIgnoredDuringExecution:      - weight: 1        preference:          matchExpressions:          - key: another-node-label-key            operator: In            values:            - another-node-label-value  containers:  - name: node-affinity    image: docker.io/busybox:latest</code></pre><p>此处的亲和性规则表明，该 Pod 只能被调度到包含 key 为 kubernetes.io/appmanager 且 value 为 true  的标签的节点上。此外，如果节点已经满足了前述条件，将优先选择包含 key 为 another-node-label-key 且 value 为 another-node-label-value 的标签的节点。</p><h2 id="Pod亲和性与反亲和性"><a href="#Pod亲和性与反亲和性" class="headerlink" title="Pod亲和性与反亲和性"></a>Pod亲和性与反亲和性</h2><p>Pod之间的亲和性与反亲和性（inter-pod affinity and anti-affinity）可以基于已经运行在节点上的 Pod 的标签（而不是节点的标签）来限定 Pod 可以被调度到哪个节点上。此类规则的表现形式是</p><p><strong>示例说明：</strong></p><pre><code>apiVersion: extensions/v1beta1kind: ReplicaSetmetadata:  name: pod-antiaffinityspec:  replicas: 5  selector:    matchLabels:      app: pod-antiaffinity  template:    metadata:      labels:        app: pod-antiaffinity    spec:      affinity:        podAntiAffinity:          requiredDuringSchedulingIgnoredDuringExecution:            - labelSelector:                matchExpressions:                  - key: app                    operator: In                    values:                      - pod-antiaffinity              topologyKey: &quot;kubernetes.io/hostname&quot;      containers:        - name: pod-antiaffinity          image: docker.io/busybox:latest          command: [&quot;sh&quot;, &quot;-c&quot;, &quot;sleep  3600&quot;]          resources:            limits:              memory: 1Gi              cpu: 1      nodeSelector:        kubernetes.io/appmanager: &quot;true&quot;</code></pre><p>笔者此处举一个特殊例子的场景。Pod控制器ReplicaSet是保证在集群中启动一定数量的Pod。但是我们又不想让其在同一个节点上启动多个副本，此时我们用Pod反亲和性就可以得到解决，如上述例子。</p><ul><li>Pod 反亲和性规则要求，该 Pod 最好不要被调度到已经运行了包含 key 为 app 且 value 为 pod-antiaffinity 的标签的 Pod 的节点上，或者更准确地说，必须满足如下条件：<ul><li>如果 topologyKey 是 kubernetes.io/hostname，则，Pod不能被调度到同一个 zone 中的已经运行了包含标签 app: pod-antiaffinity 的节点上。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Kubernetes 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch(四)自动发现机制-Zen discovery</title>
      <link href="/2020-03-25-ElasticSearch(%E5%9B%9B)%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0%E6%9C%BA%E5%88%B6/"/>
      <url>/2020-03-25-ElasticSearch(%E5%9B%9B)%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="ElasticSearch-四-发现机制-Zen-discovery"><a href="#ElasticSearch-四-发现机制-Zen-discovery" class="headerlink" title="ElasticSearch(四)发现机制 - Zen discovery"></a>ElasticSearch(四)发现机制 - Zen discovery</h1><pre><code>注：本篇文章是基于ElasticSearch V6 大版本为基础</code></pre><h2 id="发现方式"><a href="#发现方式" class="headerlink" title="发现方式"></a>发现方式</h2><p>Elasticsearch的默认发现模块是Zen discovery。它提供了单播和基于文件的发现，可以通过插件扩展到支持云环境和其他形式的发现。</p><p>Zen Discovery 是与其他模块集成的，例如，节点之间的所有通信都使用 transport 模块完成。某个节点通过 发现机制 找到其他节点是使用 Ping 的方式实现的。</p><p>Zen Discovery 使用种子节点(seed nodes)列表来开始发现过程。在启动时，或者在选举新主节点的时候，Elasticsearch 会尝试连接到其列表中的每个种子节点，并与他们进行类似’闲聊’的对话，以查找其他节点并构建集群的完整成员图。</p><p>默认情况下，有两种方法可用于配置种子节点列表：单播和基于文件。建议种子节点列表主要由集群中那些 Master-eligible 的节点组成</p><pre><code>Master-eligible：node.master参数设置为 true（默认）的节点，使其有资格被选为控制集群的主节点</code></pre><h3 id="单播"><a href="#单播" class="headerlink" title="单播"></a>单播</h3><p>单播发现 配置静态主机列表以用作种子节点。 可以将这些主机指定为 主机名 或 IP地址。 指定为主机名的主机在每轮 ping 操作期间解析为 IP 地址。 请注意，如果您处于 DNS 解析随时间变化的环境中，则可能需要调整 JVM安全设置。</p><p>可以在 elasticsearch.yml 配置文件中使用discovery.zen.ping.unicast.hosts参数静态设置设置主机列表。如下所示：</p><pre><code>discovery.zen.ping.unicast.hosts: [&quot;node1&quot;, &quot;node2&quot;]</code></pre><p>具体的值是一个主机数组或逗号分隔的字符串。每个值应采用host：port或host的形式（其中port默认为设置transport.profiles.default.port，如果未设置则返回transport.tcp.port）。 请注意，必须将IPv6主机置于括号内。 此设置的默认值为127.0.0.1，[:: 1]。</p><p>另外，discovery.zen.ping.unicast.resolve_timeout 配置在每轮ping操作中等待DNS查找的时间。需要指定时间单位，默认为5秒。</p><p>或者在Kubernetes平台中创建Headless Service 通过9300端口来发现待加入的种子节点。具体事例请参照：<a href="https://www.frederickhou.com/2020/03/24/Elasticsearch-(%E4%B8%89)%E5%AE%B9%E5%99%A8%E5%8C%96%E6%96%B9%E6%A1%88/">Elasticsearch (三)容器化方案</a></p><pre><code>discovery.zen.ping.unicast.hosts: es-cluster-discovery</code></pre><h3 id="基于文件"><a href="#基于文件" class="headerlink" title="基于文件"></a>基于文件</h3><p>除了静态discovery.zen.ping.unicast.hosts 设置提供的主机之外，还可以通过外部文件提供主机列表。Elasticsearch在更改时会重新加载此文件，以便种子节点列表可以动态更改，而无需重新启动每个节点。例如，这为在Docker容器中运行的Elasticsearch实例提供了一种方便的机制，可以动态提供一个IP地址列表，以便在节点启动时无法知道这些IP地址时连接到Zen discovery。</p><p>要启用基于文件的发现，请文件按如下方式配置hosts提供程序</p><pre><code>discovery.zen.hosts_provider：file</code></pre><p>该文件的格式是每行指定一个节点条目。每个节点条目由主机（主机名或IP地址）和可选的传输端口号组成。如果指定了端口号，必须在主机（在同一行）之后使用“：”分割。如果未指定端口号，则使用默认值9300。</p><p>例如，这是 unicast_hosts.txt 具有四个参与单播发现的节点的集群的示例，其中一些节点未在默认端口上运行：</p><pre><code>192.168.1.5192.168.1.6:9305192.168.1.7:10005# an IPv6 address[2001:0db8:85a3:0000:0000:8a2e:0370:7334]:9301</code></pre><p>允许使用主机名而不是IP地址（类似于 discovery.zen.ping.unicast.hosts）。必须在括号中指定IPv6地址，并在括号后面添加端口。</p><h2 id="主节点选举"><a href="#主节点选举" class="headerlink" title="主节点选举"></a>主节点选举</h2><p>作为 ping 过程的一部分，一个集群的主节点需要是被选举或者加入进来的(即选举主节点也会执行ping，其他的操作也会执行ping)。这个过程是自动执行的。通过配置discovery.zen.ping_timeout来控制节点加入某个集群或者开始选举的响应时间(默认3s)。</p><p>在这段时间内有3个 ping 会发出。如果超时,重新启动 ping 程序。在网络缓慢时，3秒时间可能不够，这种情况下，需要慎重增加超时时间，增加超时时间会减慢选举进程。</p><p>一旦节点决定加入一个存在的集群，它会发出一个加入请求给主节点，这个请求的超时时间由discovery.zen.join_time控制，默认是 ping 超时时间(discovery.zen.ping_timeout)的20倍。</p><p>当主节点停止或者出现问题，集群中的节点会重新 ping 并选举一个新节点。有时一个节点也许会错误的认为主节点已死，所以这种 ping 操作也可以作为部分网络故障的保护性措施。在这种情况下，节点将只从其他节点监听有关当前活动主节点的信息。</p><p>如果discovery.zen.master_election.ignore_non_master_pings设置为true时（默认值为false），node.master为false的节点不参加主节点的选举，同时选票也不包含这种节点。</p><p>通过设置node.master为false，可以将节点设置为非备选主节点，永远没有机会成为主节点。</p><p>discovery.zen.minimum_master_nodes设置了最少有多少个备选主节点参加选举，同时也设置了一个主节点需要控制最少多少个备选主节点才能继续保持主节点身份。如果控制的备选主节点少于discovery.zen.minimum_master_nodes个，那么当前主节点下台，重新开始选举。</p><p>discovery.zen.minimum_master_nodes必须设置一个恰当的备选主节点值(quonum，一般设置 为备选主节点数/2+1)，尽量避免只有两个备选主节点，因为两个备选主节点quonum应该为2，那么如果一个节点出现问题，另一个节点的同意人数最多只能为1，永远也不能选举出新的主节点，这时就发生了<strong>脑裂</strong>现象。</p><h2 id="脑分裂（split-brain"><a href="#脑分裂（split-brain" class="headerlink" title="脑分裂（split-brain)"></a>脑分裂（split-brain)</h2><p>假设拥有一个10个节点组成的集群，有3个节点从集群中 断开连接，由于发现机制，这3个节点可能会组成一个新的集群，这样就产生了两个同名的集群，这就是脑分裂（split-brain)。 为了避免这种分裂的出现，可以设置以下属性：</p><pre><code>discovery.zen.minium_master_nodes:n/2+1</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch (三)高可用集群</title>
      <link href="/2020-03-23-Elasticsearch%20(%E4%B8%89)%E5%AE%B9%E5%99%A8%E5%8C%96%E6%96%B9%E6%A1%88/"/>
      <url>/2020-03-23-Elasticsearch%20(%E4%B8%89)%E5%AE%B9%E5%99%A8%E5%8C%96%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Kubernetes-编排部署Elasticsearch高可用集群以及Kibana"><a href="#Kubernetes-编排部署Elasticsearch高可用集群以及Kibana" class="headerlink" title="Kubernetes 编排部署Elasticsearch高可用集群以及Kibana"></a>Kubernetes 编排部署Elasticsearch高可用集群以及Kibana</h1><h2 id="Elasticsearch介绍"><a href="#Elasticsearch介绍" class="headerlink" title="Elasticsearch介绍"></a>Elasticsearch介绍</h2><p>请参考：<a href="https://www.frederickhou.com/2020/03/17/ElasticSearch-%E4%B8%80-%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D/">ElasticSearch(一)基础介绍</a></p><h2 id="Kibana介绍"><a href="#Kibana介绍" class="headerlink" title="Kibana介绍"></a>Kibana介绍</h2><p>Kibana是一个开源的分析与可视化平台，设计出来用于和Elasticsearch一起使用的。你可以用kibana搜索、查看存放在Elasticsearch中的数据。Kibana与Elasticsearch的交互方式是各种不同的图表、表格、地图等，直观的展示数据，从而达到高级的数据分析与可视化的目的。<br>Elasticsearch、Logstash和Kibana这三个技术就是我们常说的ELK技术栈，可以说这三个技术的组合是大数据领域中一个很巧妙的设计。一种很典型的MVC思想，模型持久层，视图层和控制层。Logstash担任控制层的角色，负责搜集和过滤数据。Elasticsearch担任数据持久层的角色，负责储存数据。而我们这章的主题Kibana担任视图层角色，拥有各种维度的查询和分析，并使用图形化的界面展示存放在Elasticsearch中的数据。</p><p>Kibana 的docker镜像运用 Centos:7作为基础镜像。发布过的相关Docker镜像包可以在<a href="http://www.docker.elastic.co官网进行查。笔者选用**6.8.7**版本进行安装演示。" target="_blank" rel="external nofollow noopener noreferrer">www.docker.elastic.co官网进行查。笔者选用**6.8.7**版本进行安装演示。</a></p><h2 id="创建Elasticsearch服务"><a href="#创建Elasticsearch服务" class="headerlink" title="创建Elasticsearch服务"></a>创建Elasticsearch服务</h2><h3 id="创建Elasticsearch-Service"><a href="#创建Elasticsearch-Service" class="headerlink" title="创建Elasticsearch  Service"></a>创建Elasticsearch  Service</h3><ul><li><p><strong>创建Elasticsearch集群节点发现服务（NodePort模式）</strong></p><p>  <strong>问题</strong>：es该如何发现其他节点？<br>  考虑到es的discovery.zen.ping.unicast.hosts参数可指定多IP域名，那么：</p><ul><li><p>为es创建headless service。</p></li><li><p>指定该参数为service名。</p><p>即可让es发现其他节点。</p><p>  apiVersion: v1<br>  kind: Service<br>  metadata:<br>  labels:</p><pre><code>app: es-cluster-discovery</code></pre><p>  name: es-cluster-discovery<br>  spec:<br>  selector:</p><pre><code>app: es-node-instanceid</code></pre><p>  ports:</p><pre><code>- port: 9300targetPort: 9300</code></pre></li></ul></li><li><p><strong>创建Elasticsearch集群节点访问服务</strong></p><pre><code>apiVersion: v1kind: Servicemetadata:labels:    app: es-cluster-servicename: es-cluster-servicespec:selector:    app: es-node-instanceidtype: NodePortports:    - port: 9200    targetPort: 9200</code></pre><p>创建结果如下：</p><h1 id="kubectl-get-service-n-local-pv-o-wide"><a href="#kubectl-get-service-n-local-pv-o-wide" class="headerlink" title="kubectl get service -n local-pv -o wide"></a>kubectl get service -n local-pv -o wide</h1><p>  NAME                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE     SELECTOR<br>  es-cluster-discovery   ClusterIP   10.101.18.179    <none>        9300/TCP         22h     app=es-node-instanceid<br>  es-cluster-service     NodePort    10.106.56.69     <none>        9200:30709/TCP   7h5m    app=es-node-instanceid</none></none></p></li></ul><h3 id="创建Elasticsearch-Statefulset"><a href="#创建Elasticsearch-Statefulset" class="headerlink" title="创建Elasticsearch  Statefulset"></a>创建Elasticsearch  Statefulset</h3><h4 id="参数说明："><a href="#参数说明：" class="headerlink" title="参数说明："></a>参数说明：</h4><ul><li><strong>cluster.name</strong>：集群名称，相同集群名称的节点会协调选举MASTER以及识别加入集群。</li><li><strong>discovery.zen.ping.unicast.hosts</strong>： 集群发现其他节点，或者其他节点通过此服务加入集群。</li><li><strong>discovery.zen.minimum_master_nodes</strong>： 构成集群的最少master节点数。一般设置为n/2+1个，防止“脑裂”现象。</li></ul><h4 id="创建服务"><a href="#创建服务" class="headerlink" title="创建服务"></a>创建服务</h4><pre><code>apiVersion: apps/v1beta1kind: StatefulSetmetadata:  name: es-instanceid  labels:    app: es-node-instanceidspec:  replicas: 1  selector:    matchLabels:      app: es-node-instanceid  #noted: serviceName is the real service name  serviceName: &quot;es-cluster-service&quot;  template:    metadata:      labels:        app: es-node-instanceid      annotations:        scheduler.alpha.kubernetes.io/critical-pod: &apos;&apos;    spec:      securityContext:        fsGroup: 1000      initContainers:      - name: fix-permissions        image: docker.io/busybox:latest        command: [&quot;sh&quot;, &quot;-c&quot;, &quot;chown -R 1000:1000 /usr/share/elasticsearch/data&quot;]        securityContext:          privileged: true        volumeMounts:        - name: data          mountPath: /usr/share/elasticsearch/data      - name: increase-vm-max-map        image: docker.io/busybox:latest        command: [&quot;sysctl&quot;, &quot;-w&quot;, &quot;vm.max_map_count=262144&quot;]        securityContext:          privileged: true      - name: increase-fd-ulimit        image: docker.io/busybox:latest        command: [&quot;sh&quot;, &quot;-c&quot;, &quot;ulimit -n 65536&quot;]        securityContext:          privileged: true      containers:      - name: elasticsearch        image: docker.elastic.co/elasticsearch/elasticsearch:6.8.7        imagePullPolicy: Always        env:        - name: &quot;cluster.name&quot;          value: &quot;elasticsearch-cluster&quot;        - name: &quot;ES_JAVA_OPTS&quot;          value: &quot;-Xms512m -Xmx512m&quot;        - name: &quot;discovery.zen.ping.unicast.hosts&quot;          value: &quot;es-cluster-discovery&quot;        - name: &quot;discovery.zen.minimum_master_nodes&quot;          value: &quot;2&quot;       # - name: &quot;bootstrap.memory_lock&quot;       #   value: &quot;true&quot;        ports:        - containerPort: 9200          protocol: TCP          name: discovery        - containerPort: 9300          protocol: TCP          name: transport        volumeMounts:            - mountPath: /usr/share/elasticsearch/data              name: data            - mountPath: /usr/share/elasticsearch/logs              name: data        #resources:         # limits:           # cpu: 25m           # memory: 3Gi      nodeSelector:        kubernetes.io/hostname: cent165      volumes:         - name: data           #emptyDir: {}           hostPath:              path: &quot;/ocdf_local_pv_vg0/es&quot;</code></pre><p><strong>注</strong>：笔者为了演示创建了两个节点，正式使用必须遵循规则防止“脑裂”现象。<br>创建结果如下：</p><pre><code># kubectl get pod -n local-pv -o wideNAME                      READY   STATUS    RESTARTS   AGE   IP                NODE      NOMINATED NODE   READINESS GATESes-instanceid-1-0         1/1     Running   0          22h   100.81.251.208    cent166   &lt;none&gt;           &lt;none&gt;es-instanceid-2-0         1/1     Running   0          22h   100.110.104.217   cent165   &lt;none&gt;           &lt;none&gt;</code></pre><p>查看集群健康状态：green表示健康</p><pre><code>#curl http://10.1.234.164:30709/_cluster/health?pretty{&quot;cluster_name&quot; : &quot;elasticsearch-cluster&quot;,&quot;status&quot; : &quot;green&quot;,&quot;timed_out&quot; : false,&quot;number_of_nodes&quot; : 2,&quot;number_of_data_nodes&quot; : 2,&quot;active_primary_shards&quot; : 5,&quot;active_shards&quot; : 10,&quot;relocating_shards&quot; : 0,&quot;initializing_shards&quot; : 0,&quot;unassigned_shards&quot; : 0,&quot;delayed_unassigned_shards&quot; : 0,&quot;number_of_pending_tasks&quot; : 0,&quot;number_of_in_flight_fetch&quot; : 0,&quot;task_max_waiting_in_queue_millis&quot; : 0,&quot;active_shards_percent_as_number&quot; : 100.0}</code></pre><p>查看集群nodes:</p><pre><code>#curl http://10.1.234.164:30709/_cat/nodes?vip              heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name100.110.104.217           60          94   2    0.33    0.13     0.07 mdi       *      1mSnPgt100.81.251.208            62          97   3    0.27    0.19     0.20 mdi       -      clNDNoX</code></pre><p>查看集群masters:</p><pre><code>#curl http://10.1.234.164:30709/_cat/master?vid                     host            ip              node1mSnPgtDS8O3_FsmX-PGLA 100.110.104.217 100.110.104.217 1mSnPgt</code></pre><h2 id="创建Kibana服务"><a href="#创建Kibana服务" class="headerlink" title="创建Kibana服务"></a>创建Kibana服务</h2><h3 id="创建Kibana-Service（NodePort模式）"><a href="#创建Kibana-Service（NodePort模式）" class="headerlink" title="创建Kibana  Service（NodePort模式）"></a>创建Kibana  Service（NodePort模式）</h3><pre><code>apiVersion: v1kind: Servicemetadata:name: kibanalabels:    app: kibanaspec:type: NodePortports:- port: 5601selector:    app: kibana</code></pre><p>创建结果如下：</p><pre><code># kubectl get service -n local-pv -o widekibana                 NodePort    10.107.131.227   &lt;none&gt;        5601:31920/TCP   6h49m   app=kibana</code></pre><h3 id="创建Kibana-服务"><a href="#创建Kibana-服务" class="headerlink" title="创建Kibana 服务"></a>创建Kibana 服务</h3><h4 id="参数说明：-1"><a href="#参数说明：-1" class="headerlink" title="参数说明："></a>参数说明：</h4><ul><li><strong>ELASTICSEARCH_URL</strong>: 连接es的url，如：”<a href="http://es-cluster-service:9200&quot;" rel="external nofollow noopener noreferrer" target="_blank">http://es-cluster-service:9200&quot;</a> 其中“es-cluster-service”是es集群的9200 service name。</li><li><strong>elasticsearch.hosts</strong>：es的host列表，一般也是设置成es 9200 service name。通过服务名字可以解析出对应节点的IP。</li></ul><h4 id="创建服务："><a href="#创建服务：" class="headerlink" title="创建服务："></a>创建服务：</h4><pre><code>apiVersion: apps/v1kind: Deploymentmetadata:  name: kibana  labels:    app: kibanaspec:  replicas: 1  selector:    matchLabels:      app: kibana  template:    metadata:      labels:        app: kibana    spec:      containers:      - name: kibana        image: docker.elastic.co/kibana/kibana:6.8.7        resources:          limits:            cpu: 1000m          requests:            cpu: 100m        env:          - name: &quot;ELASTICSEARCH_URL&quot;            value: &quot;http://es-cluster-service:9200&quot;          - name: &quot;elasticsearch.hosts&quot;            value: &quot;es-cluster-service&quot;          - name: &quot;elasticsearch.username&quot;            value: &quot;admin&quot;          - name: &quot;elasticsearch.password&quot;            value: &quot;admin&quot;        ports:        - containerPort: 5601</code></pre><p>创建结果如下：</p><pre><code># kubectl get pod -n local-pv -o widekibana-76969bdf57-xzxc9   1/1     Running   0          73m   100.81.251.214    cent166   &lt;none&gt;           &lt;none&gt;</code></pre><h4 id="浏览器访问"><a href="#浏览器访问" class="headerlink" title="浏览器访问"></a>浏览器访问</h4><p>浏览器地址中输入：<a href="http://10.1.234.164:31920" target="_blank" rel="external nofollow noopener noreferrer">http://10.1.234.164:31920</a> 如下图所示：</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/kibana1.jpg?raw=true"  alt></p><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/kibana2.jpg?raw=true"  alt></p><p>es集群状态：<br><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/kibana3.jpg?raw=true"  alt></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Kubernetes </tag>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Heketi (二)调用封装</title>
      <link href="/2020-03-18-Heket(%E4%BA%8C)%E8%B0%83%E7%94%A8%E5%B0%81%E8%A3%85/"/>
      <url>/2020-03-18-Heket(%E4%BA%8C)%E8%B0%83%E7%94%A8%E5%B0%81%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Heketi-调用封装"><a href="#Heketi-调用封装" class="headerlink" title="Heketi 调用封装"></a>Heketi 调用封装</h1><h3 id="包依赖"><a href="#包依赖" class="headerlink" title="包依赖"></a>包依赖</h3><pre><code>import (    &quot;fmt&quot;    &quot;errors&quot;    client&quot;github.com/heketi/heketi/client/api/go-client&quot;    api&quot;github.com/heketi/heketi/pkg/glusterfs/api&quot;)</code></pre><h3 id="Heketi属性"><a href="#Heketi属性" class="headerlink" title="Heketi属性"></a>Heketi属性</h3><pre><code>type Heketi struct{    Url string    User string    Key string    ClientObj *client.Client}</code></pre><h3 id="客户端实例化接口"><a href="#客户端实例化接口" class="headerlink" title="客户端实例化接口"></a>客户端实例化接口</h3><pre><code>func(self *Heketi)NewClient(){    // Create a client object    clientObj := client.NewClient(self.Url, self.User, self.Key)    self.ClientObj = clientObj}</code></pre><h3 id="创建一个集群接口"><a href="#创建一个集群接口" class="headerlink" title="创建一个集群接口"></a>创建一个集群接口</h3><pre><code>func(self *Heketi)CreateCluster(block bool,file bool)(string,error){    // create a cluster    clusterCreateReq := &amp;api.ClusterCreateRequest{}    clusterCreateReq.ClusterFlags.Block = true    clusterCreateReq.ClusterFlags.File = true    clusterInfoRep,err := self.ClientObj.ClusterCreate(clusterCreateReq)    return clusterInfoRep.Id,err}</code></pre><h3 id="集群ID列表返回"><a href="#集群ID列表返回" class="headerlink" title="集群ID列表返回"></a>集群ID列表返回</h3><pre><code>func(self *Heketi)ClusterList()([]string,error){    // Get  cluster list    clusterListRes,err := self.ClientObj.ClusterList()    if err != nil{        return nil,err    }    if len((*clusterListRes).Clusters) == 0{        fmt.Println(&quot;don&apos;t have a cluster&quot;)        return []string{},errors.New(&quot;don&apos;t have a cluster&quot;)    }    clusterList := (*clusterListRes).Clusters    return clusterList,nil}</code></pre><h3 id="集群信息获取"><a href="#集群信息获取" class="headerlink" title="集群信息获取"></a>集群信息获取</h3><pre><code>func(self *Heketi)ClusterInfo(clusterId string)([]string,[]string,[]string,error){    clusterInfoRes,err := self.ClientObj.ClusterInfo(clusterId)    return clusterInfoRes.Nodes,clusterInfoRes.Volumes ,clusterInfoRes.BlockVolumes ,err}</code></pre><h3 id="集群中添加一个节点"><a href="#集群中添加一个节点" class="headerlink" title="集群中添加一个节点"></a>集群中添加一个节点</h3><pre><code>func(self *Heketi)AddNode(clusterId string,zone int,hostnameManage []string,hostnamesStorage []string,Tags map[string]string)(*api.NodeInfoResponse,error){    // Create node    nodeReq := &amp;api.NodeAddRequest{}    nodeReq.ClusterId = clusterId    nodeReq.Hostnames.Manage = []string{&quot;cent&quot; + fmt.Sprintf(&quot;%v&quot;, zone)}    nodeReq.Hostnames.Storage = []string{&quot;storage&quot; + fmt.Sprintf(&quot;%v&quot;, zone)}    nodeReq.Zone = zone + 1    nodeReq.Tags = Tags    // Add node    node, err := self.ClientObj.NodeAdd(nodeReq)    return node ,err}</code></pre><h3 id="给节点添加一个存储设备"><a href="#给节点添加一个存储设备" class="headerlink" title="给节点添加一个存储设备"></a>给节点添加一个存储设备</h3><pre><code>func(self *Heketi)AddDevice(nodeId string, deviceName string)(bool,error){        // add device        deviceReq := &amp;api.DeviceAddRequest{}        deviceReq.Name = deviceName        deviceReq.NodeId = nodeId        err := self.ClientObj.DeviceAdd(deviceReq)        if err != nil{            return false,err        }        return true,nil}</code></pre><h3 id="在设备中创建一个卷"><a href="#在设备中创建一个卷" class="headerlink" title="在设备中创建一个卷"></a>在设备中创建一个卷</h3><pre><code>func(self *Heketi)VolumeCreate(size int,name string,replica int,clustersIdList []string,block bool)(string,error){    volumeCreateReq := &amp;api.VolumeCreateRequest{}     volumeCreateReq.Size = size    volumeCreateReq.Clusters = clustersIdList    volumeCreateReq.Name = name    volumeCreateReq.Block  = block    volumeCreateReq.Durability.Replicate.Replica = replica    volumeInfoRes := &amp;api.VolumeInfoResponse{}    volumeInfoRes,err := self.ClientObj.VolumeCreate(volumeCreateReq)    return volumeInfoRes.VolumeInfo.Id,err}</code></pre><h3 id="卷删除"><a href="#卷删除" class="headerlink" title="卷删除"></a>卷删除</h3><pre><code>func(self *Heketi)VolumeDelete(id string)(error){    return self.ClientObj.VolumeDelete(id)}</code></pre><h3 id="卷信息获取"><a href="#卷信息获取" class="headerlink" title="卷信息获取"></a>卷信息获取</h3><pre><code>func(self *Heketi)VolumeInfo(id string){    info,_ := self.ClientObj.VolumeInfo(id)    fmt.Println(info)}</code></pre><h3 id="获取集群信息细节"><a href="#获取集群信息细节" class="headerlink" title="获取集群信息细节"></a>获取集群信息细节</h3><pre><code>func(self *Heketi)GetClusterInfoDetail(clusterId string)(map[string]interface{}){    /*        {            &quot;ClusterId&quot;:&quot;&quot;,            &quot;ClusterInfo&quot;:[                {                    &quot;NodeName&quot;:&quot;&quot;,                    &quot;NodeId&quot;:&quot;&quot;,                    &quot;NodeState&quot;:&quot;&quot;,                    &quot;DevideInfo&quot;:[                    {                        &quot;DeviceId&quot;:&quot;&quot;,                        &quot;DeviceName&quot;:&quot;&quot;,                        &quot;DeviceState&quot;:&quot;&quot;,                        &quot;DeviceTotal&quot;:0,                        &quot;DeviceUsed&quot;:0,                        &quot;DeviceFree&quot;:0,                    }                ]                }            ]        }    */    clusterInfo,_ := self.ClientObj.ClusterInfo(clusterId)    clusterInfoDetailMap := map[string]interface{}{}    var nodeList  []interface{}    clusterInfoDetailMap[&quot;ClusterId&quot;] = clusterId    //select  cluster&apos;s node    for _,node:= range clusterInfo.Nodes {        nodeInfoRes ,_:= self.ClientObj.NodeInfo(node)         var newdDviceInfoList  []interface{}        newNodeInfo := map[string]interface{}{}        newNodeInfo[&quot;NodeState&quot;] = (*nodeInfoRes).State        newNodeInfo[&quot;NodeId&quot;] = (*nodeInfoRes).NodeInfo.Id        newNodeInfo[&quot;NodeName&quot;] = (*nodeInfoRes).NodeInfo.NodeAddRequest.Hostnames.Manage        devicesInfoResList := (*nodeInfoRes).DevicesInfo           for _,deviceInfoRes := range devicesInfoResList{            deviceInfo := map[string]interface{}{}            deviceInfo[&quot;DeviceId&quot;] = deviceInfoRes.DeviceInfo.Id            deviceInfo[&quot;DeviceName&quot;] = deviceInfoRes.DeviceInfo.Device.Name            deviceInfo[&quot;DeviceUsed&quot;] = deviceInfoRes.DeviceInfo.Storage.Used            deviceInfo[&quot;DeviceFree&quot;] = deviceInfoRes.DeviceInfo.Storage.Free            deviceInfo[&quot;DeviceTotal&quot;] = deviceInfoRes.DeviceInfo.Storage.Total             deviceInfo[&quot;DeviceState&quot;] = deviceInfoRes.State            newdDviceInfoList = append(newdDviceInfoList,deviceInfo)            newNodeInfo[&quot;DevideInfo&quot;] = newdDviceInfoList                                                    }        nodeList = append(nodeList,newNodeInfo)    }    clusterInfoDetailMap[&quot;ClusterInfo&quot;] = nodeList    return clusterInfoDetailMap}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Heketi </tag>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch（二）安装部署</title>
      <link href="/2020-03-18-Elasticsearch%20(%E4%BA%8C)%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
      <url>/2020-03-18-Elasticsearch%20(%E4%BA%8C)%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Elasticsearch-docker-安装部署"><a href="#Elasticsearch-docker-安装部署" class="headerlink" title="Elasticsearch  docker 安装部署"></a>Elasticsearch  docker 安装部署</h1><p><strong>Elasticsearch(ES)</strong> 的docker镜像运用 <a href="https://hub.docker.com/_/centos/" target="_blank" rel="external nofollow noopener noreferrer">Centos:7</a>作为基础镜像。发布过的相关Docker镜像包可以在<a href="https://www.docker.elastic.co" target="_blank" rel="external nofollow noopener noreferrer">www.docker.elastic.co</a>官网进行查。源码托管在<a href="https://github.com/elastic/elasticsearch/blob/7.6/distribution/docker" target="_blank" rel="external nofollow noopener noreferrer">Github</a>上。</p><h2 id="单节点安装"><a href="#单节点安装" class="headerlink" title="单节点安装"></a>单节点安装</h2><h3 id="拉取镜像包"><a href="#拉取镜像包" class="headerlink" title="拉取镜像包"></a>拉取镜像包</h3><pre><code>docker pull docker.elastic.co/elasticsearch/elasticsearch:7.6.1</code></pre><p>其他的版本镜像包可以去<a href="https://www.docker.elastic.co" target="_blank" rel="external nofollow noopener noreferrer">www.docker.elastic.co</a>进行下载。</p><h3 id="运行一个单节点集群的服务"><a href="#运行一个单节点集群的服务" class="headerlink" title="运行一个单节点集群的服务"></a>运行一个单节点集群的服务</h3><p>运行一个单节点集群服务用来开发或者测试。并且要指定单节点发现来绕过引导检查。详细引导检查请查看<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html" target="_blank" rel="external nofollow noopener noreferrer">引导检查</a></p><pre><code>docker run -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:7.6.1</code></pre><h2 id="多节点集群安装"><a href="#多节点集群安装" class="headerlink" title="多节点集群安装"></a>多节点集群安装</h2><h3 id="使用Docker-Compose-启动一个多节点集群"><a href="#使用Docker-Compose-启动一个多节点集群" class="headerlink" title="使用Docker Compose 启动一个多节点集群"></a>使用Docker Compose 启动一个多节点集群</h3><ul><li><p><strong>1 创建一个docker compose文件docker-compose.yml</strong></p><pre><code>version: &apos;2.2&apos;services:  es01:    image: docker.elastic.co/elasticsearch/elasticsearch:7.6.1    container_name: es01    environment:      - node.name=es01      - cluster.name=es-docker-cluster      - discovery.seed_hosts=es02,es03      - cluster.initial_master_nodes=es01,es02,es03      - bootstrap.memory_lock=true      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;    ulimits:      memlock:        soft: -1        hard: -1    volumes:      - data01:/usr/share/elasticsearch/data    ports:      - 9200:9200    networks:      - elastic  es02:    image: docker.elastic.co/elasticsearch/elasticsearch:7.6.1    container_name: es02    environment:      - node.name=es02      - cluster.name=es-docker-cluster      - discovery.seed_hosts=es01,es03      - cluster.initial_master_nodes=es01,es02,es03      - bootstrap.memory_lock=true      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;    ulimits:      memlock:        soft: -1        hard: -1    volumes:      - data02:/usr/share/elasticsearch/data    networks:      - elastic  es03:    image: docker.elastic.co/elasticsearch/elasticsearch:7.6.1    container_name: es03    environment:      - node.name=es03      - cluster.name=es-docker-cluster      - discovery.seed_hosts=es01,es02      - cluster.initial_master_nodes=es01,es02,es03      - bootstrap.memory_lock=true      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;    ulimits:      memlock:        soft: -1        hard: -1    volumes:      - data03:/usr/share/elasticsearch/data    networks:      - elasticvolumes:  data01:    driver: local  data02:    driver: local  data03:    driver: localnetworks:  elastic:    driver: bridge</code></pre></li></ul><p>此Docker Compose 例子文件将创建一个3个节点的Elasticsearch集群。节点es01 监听 localhost:9200 并且在Docker网络中节点es02 和es03要和es01通信。</p><p>请记录此配置文件导出的端口号：9200，并且要在所有网络接口上配置Linux的iptables端口开放信息，这样Elasticsearch服务就有权限公开访问了。如果您不想公开端口9200，而是使用反向代理，请在docker-compose.yml文件中将9200：9200替换为127.0.0.1:9200:9200。 然后只能从主机本身访问Elasticsearch。</p><pre><code>#开发9200端口iptables -A INPUT -p tcp --dport 22 -j ACCEPTservice iptables save</code></pre><p>卷data01,data02,和data01直接存储着节点数据，没有用持久化存储，此种配置在重启服务后数据可能丢失</p><ul><li><p><strong>2 确保为Docker Engine分配了至少4GiB的内存</strong></p><p>  如果docker compose 没有安装请查看docs.docker.com网站进行<a href="https://docs.docker.com/compose/install" target="_blank" rel="external nofollow noopener noreferrer">安装</a></p><pre><code>sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.25.4/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-compose </code></pre><p>  查看版本</p><pre><code># docker-compose --versiondocker-compose version 1.25.4, build 8d51620a</code></pre></li></ul><ul><li><p><strong>3 运行docker compose 来创建拉起集群</strong></p><pre><code>docker-compose up -d</code></pre><p>  <strong>报错：</strong><br>  iptables: No chain/target/match by that name<br>  <strong>原因：</strong><br>  docker服务启动时定义的自定义链<br>  DOCKER由于某种原因被清掉重启docker服务及可重新生成自定义链DOCKER<br>  <strong>解决方案：</strong></p><pre><code>iptables -t filter -Fiptables -t filter -Xsystemctl restart docker</code></pre><p>  <strong>docker 运行查看</strong></p><pre><code># docker ps|grep es086b91ba4732f        docker.elastic.co/elasticsearch/elasticsearch:7.6.1   &quot;/usr/local/bin/do...&quot;   5 minutes ago       Up 5 minutes        0.0.0.0:9200-&gt;9200/tcp, 9300/tcp   es01706171c7357b        docker.elastic.co/elasticsearch/elasticsearch:7.6.1   &quot;/usr/local/bin/do...&quot;   5 minutes ago       Up 5 minutes        9200/tcp, 9300/tcp                 es02941ebc831b93        docker.elastic.co/elasticsearch/elasticsearch:7.6.1   &quot;/usr/local/bin/do...&quot;   5 minutes ago       Up 5 minutes        9200/tcp, 9300/tcp                 es03</code></pre></li><li><p><strong>4 提交一个_cat/nodes 请求来查看节点是否被拉起来以及运行状态</strong></p><pre><code>curl -X GET &quot;localhost:9200/_cat/nodes?v&amp;pretty&quot;</code></pre><p>  <strong>查看节点状态结果：</strong></p><pre><code># curl -X GET &quot;localhost:9200/_cat/nodes?v&amp;pretty&quot;ip         heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name172.18.0.4           22          86   8    0.16    0.58     0.70 dilm      -      es03172.18.0.3           16          86   7    0.16    0.58     0.70 dilm      *      es01172.18.0.2           27          86   7    0.16    0.58     0.70 dilm      -      es02</code></pre></li><li><p><strong>5 停止集群</strong></p><pre><code>#数据将会保留docker-compose down#数据将被清除docker-compose down -v#重启集群docker-compose up -d</code></pre></li></ul><h2 id="产品中使用注意事项"><a href="#产品中使用注意事项" class="headerlink" title="产品中使用注意事项"></a>产品中使用注意事项</h2><ul><li><p><strong>1 设置 vm.max_map_count 至少为262144</strong></p><pre><code>grep vm.max_map_count /etc/sysctl.confvm.max_map_count=262144#如果没有设置运行如下命令sysctl -w vm.max_map_count=262144</code></pre></li><li><p><strong>2 配置文件必须被elasticsearch用户可读</strong></p><p>  默认情况下，Elasticsearch使用uid：gid 1000：0作为用户elasticsearch在容器内运行。</p><p>  如果您要绑定安装本地目录或文件，则elasticsearch用户必须可以读取它。 此外，该用户必须对数据和日志目录具有写权限。</p><p>  例如：准备一个本地目录通过mount来存储数据</p><pre><code>mkdir esdatadirchmod g+rwx esdatadirchgrp 0 esdatadir</code></pre><p>参考：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#_pulling_the_image" target="_blank" rel="external nofollow noopener noreferrer">官方网站</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Heketi (一)开发介绍</title>
      <link href="/2020-03-18-Heketi(%E4%B8%80)%E5%BC%80%E5%8F%91%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020-03-18-Heketi(%E4%B8%80)%E5%BC%80%E5%8F%91%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Heketi-开发介绍"><a href="#Heketi-开发介绍" class="headerlink" title="Heketi 开发介绍"></a>Heketi 开发介绍</h1><p>Heketi提供了RESTful管理接口，可用于管理GlusterFS卷的生命周期。 Heketi的目标是提供一种在多个存储群集中创建，列出和删除GlusterFS卷的简单方法。 Heketi将智能地管理群集中整个磁盘的分配，创建和删除。 在满足任何请求之前，Heketi首先需要了解集群的拓扑（topologies ）也就是需要配置topologies.json文件 。 此json文件将数据资源组织为以下内容：群集、节点、设备的归属、以及块的归属。</p><h1 id="开发"><a href="#开发" class="headerlink" title="开发"></a>开发</h1><p>要与Heketi服务进行通信，您将需要使用客户端库或直接与REST端点进行通信。 Heketi目前支持以下客户端库：Go，Python。</p><h1 id="Go-客户端库"><a href="#Go-客户端库" class="headerlink" title="Go 客户端库"></a>Go 客户端库</h1><h2 id="以下是一个使用Go客户端库的小例子仅供参考"><a href="#以下是一个使用Go客户端库的小例子仅供参考" class="headerlink" title="以下是一个使用Go客户端库的小例子仅供参考"></a>以下是一个使用Go客户端库的小例子仅供参考</h2><pre><code>package mainimport (    &quot;fmt&quot;    client&quot;github.com/heketi/heketi/client/api/go-client&quot;    // api&quot;github.com/heketi/heketi/pkg/glusterfs/api&quot;)func main() {    type Options struct{        Url string        User string        Key string    }    options := Options{Url:&quot;http://192.168.3.126:8080&quot;,User:&quot;admin&quot;,Key:&quot;My Secret&quot;}    // Create a client    clientObj := client.NewClient(options.Url, options.User, options.Key)    // Get a cluster id    clusterListRes,_ := clientObj.ClusterList()    if len((*clusterListRes).Clusters) == 0{        fmt.Println(&quot;don&apos;t have a cluster&quot;)        return    }    clusterList := (*clusterListRes).Clusters    clusterInfo,_ := clientObj.ClusterInfo(clusterList[0])    //Create node    // nodeReq := &amp;api.NodeAddRequest{}    // n := 0    // nodeReq.ClusterId = clusterInfo.Id    // nodeReq.Hostnames.Manage = []string{&quot;cent&quot; + fmt.Sprintf(&quot;%v&quot;, 1)}    // nodeReq.Hostnames.Storage = []string{&quot;storage&quot; + fmt.Sprintf(&quot;%v&quot;, 1)}    // nodeReq.Zone = n + 1    // // Add node    // node, err := clientObj.NodeAdd(nodeReq)    // fmt.Println(node,err)    for _,node:= range clusterInfo.Nodes {        nodeInfo ,_:= clientObj.NodeInfo(node)        fmt.Println(*nodeInfo)    }  }</code></pre><p>想要了解更多有段Heketi客户端API代码细节的可以参考如下链接：</p><ul><li><strong>Source code:</strong> <a href="https://github.com/heketi/heketi/tree/master/client/api/go-client" target="_blank" rel="external nofollow noopener noreferrer">https://github.com/heketi/heketi/tree/master/client/api/go-client</a></li><li><strong>Doc:</strong><a href="https://godoc.org/github.com/heketi/heketi/client/api/go-client" target="_blank" rel="external nofollow noopener noreferrer">https://godoc.org/github.com/heketi/heketi/client/api/go-client</a></li></ul><h1 id="快速搭建开发环境"><a href="#快速搭建开发环境" class="headerlink" title="快速搭建开发环境"></a>快速搭建开发环境</h1><p>在开发Heketi 客户端代码时，我们需要一个模拟Heketi Server的环境来做开发。在这种模式下，Heketi无需与任何存储节点进行通信，而是模拟通信，同时仍支持所有REST调用并保持状态，这种最简单的方式就是运行一个Heketi server的docker容器。 具体命令如下：</p><pre><code>docker run -d -p 8080:8080 heketi/heketicurl http://localhost:8080/helloHello from Heketi</code></pre><h1 id="认证模式"><a href="#认证模式" class="headerlink" title="认证模式"></a>认证模式</h1><p>Heketi使用基于IETF提议的JSON Web令牌（JWT）标准的无状态身份验证模型。 如规范所指定，JWT令牌具有一组声明，可以将这些声明添加到令牌中以确定其正确性。 Heketi要求使用以下标准声明：</p><ul><li><strong>iss：</strong> Issuer. Heketi支持两种issuers的方式 <ul><li>admin: 对所有的API都有权限</li><li>user: 仅仅对卷相关API有权限</li></ul></li><li><strong>iat:</strong> Issued-at-time</li><li><strong>exp:</strong> Time when the token should expire</li></ul><p>并且用户可以遵循Atlassian所述的模型进行定制：</p><ul><li><strong>qsh:</strong> URL Tampering prevention.</li></ul><p>Heketi支持使用HMAC SHA-256算法加密的令牌签名，该算法由规范指定为HS256。</p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Heketi </tag>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch（一）基础介绍</title>
      <link href="/2020-03-18-ElasticSearch%EF%BC%88%E4%B8%80%EF%BC%89%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020-03-18-ElasticSearch%EF%BC%88%E4%B8%80%EF%BC%89%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="ElasticSearch介绍"><a href="#ElasticSearch介绍" class="headerlink" title="ElasticSearch介绍"></a>ElasticSearch介绍</h2><p><strong>Elasticsearch（ES）</strong> 是一个基于Lucene构建的开源、分布式、RESTful接口的全文搜索引擎。Elasticsearch还是一个分布式文档数据库 ，可以在极短的时间内存储、搜索和分析大量的数据。通常作为具有复杂搜索场景情况下的核心发动机。</p><p><strong>具有以下特点：</strong></p><ul><li>分布式的实时文件存储，每个字段都被索引并可被搜索</li><li>分布式的实时分析搜索引擎</li><li>可以扩展到上百台服务器，处理PB级结构化或非结构化数据</li></ul><p>Elasticsearch（ES）集群架构图如下图所示：<br><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-e7dd5da0314b3901.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="kisspng-elasticsearch-computer-cluster-node-relativity-tec-relativity-5b3e5bb51abf47.6045839215308133651096.jpg"></p><p>Elasticsearch用于构建高可用和可扩展的系统。扩展的方式可以是购买更好的服务器(纵向扩展(vertical scale or scaling up))或者购买更多的服务(横向扩展(horizontal scale or scaling out))。Elasticsearch虽然能从更强大的硬件中获得更好的性能，但是纵向扩展有它的局限性。真正的扩展应该是横向的，它通过增加节点来均摊负载和增加可靠性。对于大多数数据库而言，横向扩展意味着你的程序将做非常大的改动才能利用这些新添加的设备。对比来说，Elasticsearch天生就是分布式的：它知道如何管理节点来提供高扩展和高可用。这意味着你的程序不需要关心这些。</p><h2 id="Elasticsearch-生活运用场景"><a href="#Elasticsearch-生活运用场景" class="headerlink" title="Elasticsearch 生活运用场景"></a>Elasticsearch 生活运用场景</h2><p>当你经营一家网上商店，你可以让你的客户搜索你卖的商品。在这种情况下，你可以使用ElasticSearch来存储你的整个产品目录和库存信息，为客户提供精准搜索，可以为客户推荐相关商品。</p><p>当你想收集日志或者交易数据的时候，需要分析和挖掘这些数据，寻找趋势，进行统计，总结，或发现异常。在这种情况下，你可以使用Logstash或者其他工具来进行收集数据，当这引起数据存储到ElasticsSearch中。你可以搜索和汇总这些数据，找到任何你感兴趣的信息。</p><p>生活中运用的手机APP用户发布信息的快速搜索以及存储，并且运营商可以根据存储的数据进行大数据分析，和个性推荐机制等场景。</p><p>如下图是推特的使用场景图：<br><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-02d015a9eceeb5dd.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="kisspng-diagram-elasticsearch-architecture-kibana-github-5b804d3aab7978.3267572115351350347024.jpg"></p><h2 id="Elasticsearch基本概念"><a href="#Elasticsearch基本概念" class="headerlink" title="Elasticsearch基本概念"></a>Elasticsearch基本概念</h2><p><strong>Near Realtime(NRT) 几乎实时：</strong><br>Elasticsearch是一个几乎实时的搜索平台。意思是，从索引一个文档到这个文档可被搜索只需要一点点的延迟，这个时间一般为毫秒级。</p><p><strong>Cluster 集群：</strong><br>群集是一个或多个节点（服务器）的集合， 这些节点共同保存整个数据，并在所有节点上提供联合索引和搜索功能。一个集群由一个唯一集群ID确定，并指定一个集群名（默认为“elasticsearch”）。该集群名非常重要，因为节点可以通过这个集群名加入群集，<strong>一个节点只能是群集的一部分</strong>。</p><p>确保在不同的环境中不要使用相同的群集名称，否则可能会导致连接错误的群集节点。例如，你可以使用logging-dev、logging-stage、logging-prod分别为开发、阶段产品、生产集群做记录。</p><p><strong>Node节点：</strong><br>节点是单个服务器实例，它是群集的一部分，可以存储数据，并参与群集的索引和搜索功能。就像一个集群，节点的名称默认为一个随机的通用唯一标识符（UUID），确定在启动时分配给该节点。如果不希望默认，可以定义任何节点名。这个名字对管理很重要，目的是要确定你的网络服务器对应于你的ElasticSearch群集节点。</p><p>我们可以通过群集名配置节点以连接特定的群集。默认情况下，每个节点设置加入名为“elasticSearch”的集群。这意味着如果你启动多个节点在网络上，假设他们能发现彼此都会自动形成和加入一个名为“elasticsearch”的集群。</p><p>在单个群集中，您可以拥有尽可能多的节点。此外，如果“elasticsearch”在同一个网络中，没有其他节点正在运行，从单个节点的默认情况下会形成一个新的单节点名为”elasticsearch”的集群。</p><p><strong>Index索引：</strong><br>索引是具有相似特性的文档集合。例如，可以为客户数据提供索引，为产品目录建立另一个索引，以及为订单数据建立另一个索引。索引由名称（<strong>必须全部为小写</strong>）标识，该名称用于在对其中的文档执行索引、搜索、更新和删除操作时引用索引。在单个群集中，您可以定义尽可能多的索引。</p><p><strong>Type类型：</strong><br>在索引中，可以定义一个或多个类型。类型是索引的逻辑类别/分区，其语义完全取决于您。一般来说，类型定义为具有公共字段集的文档。例如，假设你运行一个博客平台，并将所有数据存储在一个索引中。在这个索引中，您可以为用户数据定义一种类型，为博客数据定义另一种类型，以及为注释数据定义另一类型。</p><p><strong>Document文档：</strong><br>文档是可以被索引的信息的基本单位。例如，您可以为单个客户提供一个文档，单个产品提供另一个文档，以及单个订单提供另一个文档。本文件的表示形式为JSON（JavaScript Object Notation）格式，这是一种非常普遍的互联网数据交换格式。</p><p>在索引/类型中，您可以存储尽可能多的文档。请注意，尽管文档物理驻留在索引中，文档实际上必须索引或分配到索引中的类型。</p><p><strong>Shards &amp; Replicas分片与副本：</strong></p><p>索引可以存储大量的数据，这些数据可能超过单个节点的硬件限制。例如，十亿个文件占用磁盘空间1TB的单指标可能不适合对单个节点的磁盘或可能太慢服务仅从单个节点的搜索请求。</p><p>为了解决这一问题，Elasticsearch提供细分你的指标分成多个块称为分片的能力。当你创建一个索引，你可以简单地定义你想要的分片数量。每个分片本身是一个全功能的、独立的“指数”，可以托管在集群中的任何节点。</p><p>Shards分片的重要性主要体现在以下两个特征：</p><p>分片允许您水平拆分或缩放内容的大小<br>分片允许你分配和并行操作的碎片（可能在多个节点上）从而提高性能/吞吐量<br>这个机制中的碎片是分布式的以及其文件汇总到搜索请求是完全由ElasticSearch管理，对用户来说是透明的。</p><p>在同一个集群网络或云环境上，故障是任何时候都会出现的，拥有一个故障转移机制以防分片和结点因为某些原因离线或消失是非常有用的，并且被强烈推荐。为此，Elasticsearch允许你创建一个或多个拷贝，你的索引分片进入所谓的副本或称作复制品的分片，简称Replicas。</p><p>Replicas的重要性主要体现在以下两个特征：</p><p>副本为分片或节点失败提供了高可用性。为此，需要注意的是，一个副本的分片不会分配在同一个节点作为原始的或主分片，副本是从主分片那里复制过来的。<br>副本允许用户扩展你的搜索量或吞吐量，因为搜索可以在所有副本上并行执行。</p><p>此分片副本存储方式和GLUSTER FS 分布式条带卷存储方式类似。</p><p><strong>ElasticSearch和关系型数据库相关概念的对应关系：</strong></p><table><thead><tr><th>Elasticsearch</th><th>关系型数据库</th></tr></thead><tbody><tr><td>数据库(Database)</td><td>索引(Index)，支持全文检索</td></tr><tr><td>表(Table)</td><td>类型(Type)</td></tr><tr><td>数据行(Row)</td><td>文档(Document)，但不需要固定结构，不同文档可以具有不同字段集合</td></tr><tr><td>数据列(Column)</td><td>字段(Field)</td></tr><tr><td>模式(Schema)</td><td>映像(Mapping)</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes(一)之基础介绍</title>
      <link href="/2020-03-12-Kubernetes(%E4%B8%80)%E4%B9%8B%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020-03-12-Kubernetes(%E4%B8%80)%E4%B9%8B%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Kubernetes基础介绍"><a href="#Kubernetes基础介绍" class="headerlink" title="Kubernetes基础介绍"></a>Kubernetes基础介绍</h1><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><hr><p>Kubernetes是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。</p><p>Kubernetes一个核心的特点就是能够自主的管理容器来保证云平台中的容器按照用户的期望状态运行着（比如用户想让apache一直运行，用户不需要关心怎么去做，Kubernetes会自动去监控，然后去重启，新建，总之，让apache一直提供服务），管理员可以加载一个微型服务，让规划器来找到合适的位置，同时，Kubernetes也系统提升工具以及人性化方面，让用户能够方便的部署自己的应用（就像canary deployments）。</p><p>在Kubenetes中，所有的容器均在Pod中运行,一个Pod可以承载一个或者多个相关的容器，在后边的案例中，同一个Pod中的容器会部署在同一个物理机器上并且能够共享资源。一个Pod也可以包含O个或者多个磁盘卷组（volumes）,这些卷组将会以目录的形式提供给一个容器，或者被所有Pod中的容器共享，对于用户创建的每个Pod,系统会自动选择那个健康并且有足够容量的机器，然后创建类似容器的容器,当容器创建失败的时候，容器会被node agent自动的重启,这个node agent叫kubelet,但是，如果是Pod失败或者机器，它不会自动的转移并且启动，除非用户定义了 replication controller。</p><h3 id="Kubernetes主要由以下几个核心组件组成"><a href="#Kubernetes主要由以下几个核心组件组成" class="headerlink" title="Kubernetes主要由以下几个核心组件组成"></a>Kubernetes主要由以下几个核心组件组成</h3><ul><li><p><strong>Etcd</strong><br>保存了整个集群的状态,所有master的持续状态都存在etcd的一个实例中。这可以很好地存储配置数据。因为有watch(观察者)的支持，各部件协调中的改变可以很快被察觉。</p></li><li><p><strong>Api server</strong><br>提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制.它提供Kubernetes API （PS:官方 英文）的服务。这个服务试图通过把所有或者大部分的业务逻辑放到不两只的部件中从而使其具有CRUD特性。它主要处理REST操作，在etcd中验证更新这些对象（并最终存储）。</p></li><li><p><strong>Controller Manager</strong><br>负责维护集群的状态，比如故障检测、自动扩展、滚动更新等.</p></li><li><p><strong>Scheduler</strong><br>负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上.</p></li><li><p><strong>Kubelet</strong><br>负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理.</p></li><li><p><strong>Container Runtime</strong><br>负责镜像管理以及Pod和容器的真正运行（CRI.）</p></li><li><p><strong>Kube-Proxy</strong><br>负责为Service提供cluster内部的服务发现和负载均衡.</p></li></ul><h3 id="Kubernetes-集群架构图"><a href="#Kubernetes-集群架构图" class="headerlink" title="Kubernetes 集群架构图"></a>Kubernetes 集群架构图</h3><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-eeb29f3f177b008d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="Untitled Diagram (1).png"></p><h3 id="Kubernetes的特点"><a href="#Kubernetes的特点" class="headerlink" title="Kubernetes的特点"></a>Kubernetes的特点</h3><ul><li>1、可移植：支持公有云，私有云，混合云，多重云（multi-cloud）</li><li>2、可扩展：模块化, 插件化, 可挂载, 可组合</li><li>3、自动化：自动部署，自动重启，自动复制，自动伸缩/扩展</li></ul><h3 id="Kubernetes的应用范围"><a href="#Kubernetes的应用范围" class="headerlink" title="Kubernetes的应用范围"></a>Kubernetes的应用范围</h3><ul><li>多个进程（作为容器运行）协同工作。（Pod）</li><li>存储系统挂载</li><li>Distributing secrets</li><li>应用健康检测</li><li>应用实例的复制</li><li>Pod自动伸缩/扩展</li><li>Naming and discovering</li><li>负载均衡</li><li>滚动更新</li><li>资源监控</li><li>日志访问</li><li>调试应用程序</li><li>提供认证和授权</li></ul><p><strong>博客著作权归本作者所有，任何形式的转载都请联系作者获得授权并注明出处。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Kubernetes 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes(二)之安装部署</title>
      <link href="/2020-03-12-Kubernetes(%E4%BA%8C)%E4%B9%8B%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
      <url>/2020-03-12-Kubernetes(%E4%BA%8C)%E4%B9%8B%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Kubernetes-安装部署"><a href="#Kubernetes-安装部署" class="headerlink" title="Kubernetes 安装部署"></a>Kubernetes 安装部署</h1><h2 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1.环境准备"></a>1.环境准备</h2><h3 id="1-1-部署机器准备"><a href="#1-1-部署机器准备" class="headerlink" title="1.1 部署机器准备"></a>1.1 部署机器准备</h3><table><thead><tr><th>机器IP</th><th>主机名</th><th>角色</th><th>系统版本</th><th>备注</th></tr></thead><tbody><tr><td>192.168.3.120</td><td>kube-master</td><td>master</td><td>CentOS  7.4.1708</td><td>内存2G</td></tr><tr><td>192.168.3.122</td><td>kube-node01</td><td>node</td><td>CentOS   7.4.1708</td><td>内存2G</td></tr><tr><td>192.168.3.123</td><td>kube-node02</td><td>node</td><td>CentOS   7.4.1708</td><td>内存2G</td></tr></tbody></table><h3 id="1-2-基础配置安装-每台机器都需执行"><a href="#1-2-基础配置安装-每台机器都需执行" class="headerlink" title="1.2 基础配置安装(每台机器都需执行)"></a>1.2 基础配置安装(每台机器都需执行)</h3><h4 id="1-2-1-配置节点信息"><a href="#1-2-1-配置节点信息" class="headerlink" title="1.2.1 配置节点信息"></a>1.2.1 配置节点信息</h4><ul><li><p><strong>修改对应节点主机hostname</strong></p><pre><code>hostnamectl set-hostname kube-master</code></pre></li><li><p><strong>配置DNS</strong></p><pre><code>cat &lt;&lt;EOF &gt;&gt;/etc/hosts192.168.3.120 kube-master192.168.3.123 kube-node01192.168.3.122 kube-node02EOF</code></pre></li></ul><h4 id="1-2-2-配置国内yum源"><a href="#1-2-2-配置国内yum源" class="headerlink" title="1.2.2 配置国内yum源"></a>1.2.2 配置国内yum源</h4><pre><code>mkdir /etc/yum.repos.d/bak &amp;&amp; mv /etc/yum.repos.d/*.repo /etc/yum.repos.d/bakwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repoyum makecacheyum -y update</code></pre><h4 id="1-2-3-关闭防火墙、selinux和swap"><a href="#1-2-3-关闭防火墙、selinux和swap" class="headerlink" title="1.2.3 关闭防火墙、selinux和swap"></a>1.2.3 关闭防火墙、selinux和swap</h4><ul><li><p><strong>1 关闭防火墙</strong></p><pre><code>systemctl stop firewalld &amp; systemctl disable firewalld</code></pre></li><li><p><strong>2 关闭selinux</strong></p><pre><code>setenforce 0sed -i &apos;s/^SELINUX=enforcing$/SELINUX=disabled/&apos; /etc/selinux/config</code></pre></li><li><p><strong>3 关闭swap</strong></p><pre><code>swapoff -ayes | cp /etc/fstab /etc/fstab_bakcat /etc/fstab_bak |grep -v swap &gt; /etc/fstabecho vm.swappiness=0 &gt;&gt;/etc/sysctl.confsysctl -p</code></pre></li><li><p><strong>4 设置路由</strong></p><pre><code>yum install -y bridge-utils.x86_64cat &lt;&lt; EOF &gt;  /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOFsysctl --system  # 重新加载所有配置文件</code></pre></li></ul><h4 id="1-2-4-安装docker"><a href="#1-2-4-安装docker" class="headerlink" title="1.2.4 安装docker"></a>1.2.4 安装docker</h4><ul><li><p><strong>配置docker源</strong></p><pre><code>yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum makecache</code></pre></li><li><p><strong>安装对应版本docker</strong></p><pre><code>本次安装笔者选用:V18.09.9yum -y install docker-ce-18.09.9</code></pre></li><li><p><strong>安装版本查看如图所示</strong></p><p>  <img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-ef16886398457ffd.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="docker_version.jpg"></p></li><li><p><strong>启动docker服务并设置服务开机自启动</strong></p><pre><code>systemctl start docker &amp; systemctl enable docker</code></pre></li><li><p><strong>修改docker cgroup驱动，与k8s一致</strong></p><pre><code># 修改docker cgroup驱动：native.cgroupdriver=systemdcat &gt; /etc/docker/daemon.json &lt;&lt;EOF{&quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],&quot;log-driver&quot;: &quot;json-file&quot;,&quot;log-opts&quot;: {    &quot;max-size&quot;: &quot;100m&quot;},&quot;storage-driver&quot;: &quot;overlay2&quot;,&quot;storage-opts&quot;: [    &quot;overlay2.override_kernel_check=true&quot;]}EOF# 重启使配置生效systemctl restart docker  </code></pre><h4 id="1-2-4-k8s组件"><a href="#1-2-4-k8s组件" class="headerlink" title="1.2.4 k8s组件"></a>1.2.4 k8s组件</h4></li><li><p><strong>配置k8s yum源</strong></p><pre><code>cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg    http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF#更新yumyum makecache</code></pre></li><li><p><strong>master节点安装kubelet kubeadm kubectl</strong></p><pre><code>#指定版本安装V1-.17.3yum install -y kubelet-1.17.3 kubeadm-1.17.3 kubectl-1.17.3 --disableexcludes=kubernetes</code></pre></li><li><p><strong>安装结果如图所示</strong><br><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-27ee25ccef4b200a.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="k8sversion.jpg"></p></li><li><p><strong>设置开机自启动kubelet</strong></p><pre><code>systemctl enable --now kubelet </code></pre></li></ul><h2 id="2-部署集群"><a href="#2-部署集群" class="headerlink" title="2.部署集群"></a>2.部署集群</h2><h3 id="2-1-master节点安装"><a href="#2-1-master节点安装" class="headerlink" title="2.1 master节点安装"></a>2.1 master节点安装</h3><h4 id="2-1-1-master节点k8s集群初始化"><a href="#2-1-1-master节点k8s集群初始化" class="headerlink" title="2.1.1 master节点k8s集群初始化"></a>2.1.1 master节点k8s集群初始化</h4><ul><li><p><strong>安装相应版本的k8s:V1.17.3</strong></p><pre><code>kubeadm init --kubernetes-version=1.17.3 --apiserver-advertise-address=192.168.3.120 --image-repository registry.aliyuncs.com/google_containers --service-cidr=192.1.0.0/16 --pod-network-cidr=192.244.0.0/16</code></pre></li><li><p><strong>安装结果如图所示：</strong><br><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-fcc89e9d2054dd6d.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="1584073519(1).jpg"></p></li><li><p><strong>记录安装终端末尾显示的内容，此内容需要在其它节点加入k8s集群时执行。</strong></p><pre><code>kubeadm join 192.168.3.120:6443 --token 76d8po.jgo5pniao8pomjwc \    --discovery-token-ca-cert-hash sha256:69f401a7aabcc841b5dd857a66b753a6df4133f280bd7560903f2433144a99ec</code></pre></li><li><p><strong>配置kubectl工具</strong></p><pre><code>#此文件用来连接集群mkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/configchown $(id -u):$(id -g) $HOME/.kube/config</code></pre></li><li><p><strong>设置master节点为工作节点，可调度</strong></p><pre><code>kubectl taint nodes --all node-role.kubernetes.io/master-</code></pre></li><li><p><strong>master节点部署flannel网络</strong></p><pre><code>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</code></pre></li><li><p><strong>查看节点状态</strong></p></li></ul><h4 id="2-1-2-node节点加入"><a href="#2-1-2-node节点加入" class="headerlink" title="2.1.2 node节点加入"></a>2.1.2 node节点加入</h4><ul><li><p><strong>执行加入集群命令</strong></p><pre><code>kubeadm join 192.168.3.120:6443 --token 76d8po.jgo5pniao8pomjwc \    --discovery-token-ca-cert-hash sha256:69f401a7aabcc841b5dd857a66b753a6df4133f280bd7560903f2433144a99ec</code></pre></li><li><p><strong>执行结果如图所示</strong><br><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-6931e2d38cc70c98.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="node_join.jpg"></p><h2 id="3-集群状态查看"><a href="#3-集群状态查看" class="headerlink" title="3.集群状态查看"></a>3.集群状态查看</h2><h3 id="3-1-集群节点状态如图所示"><a href="#3-1-集群节点状态如图所示" class="headerlink" title="3.1 集群节点状态如图所示"></a>3.1 集群节点状态如图所示</h3></li></ul><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-ab25997231ce2d94.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="1584081461(1).jpg"></p><p>注：状态为Ready表示节点健康，并且正常加入。</p><p><strong>博客著作权归本作者所有，任何形式的转载都请联系作者获得授权并注明出处。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Kubernetes 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes(三)之组件介绍</title>
      <link href="/2020-03-13-Kubernetes(%E4%B8%89)%E4%B9%8B%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020-03-13-Kubernetes(%E4%B8%89)%E4%B9%8B%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Kubernetes各个组件介绍"><a href="#Kubernetes各个组件介绍" class="headerlink" title="Kubernetes各个组件介绍"></a>Kubernetes各个组件介绍</h1><h2 id="Kubernetes-集群组件交互架构"><a href="#Kubernetes-集群组件交互架构" class="headerlink" title="Kubernetes 集群组件交互架构"></a>Kubernetes 集群组件交互架构</h2><p>如下图所示为Kubernetes集群中各个组件交互流程以及整体集群架构<br><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-fb8a24a90c9faeaa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="kubernetes-control-plane.png"></p><h2 id="组件功能介绍"><a href="#组件功能介绍" class="headerlink" title="组件功能介绍"></a>组件功能介绍</h2><h3 id="kube-master-控制节点"><a href="#kube-master-控制节点" class="headerlink" title="kube-master[控制节点]:"></a>kube-master[控制节点]:</h3><p>如图所示为master节点的工作流：<br><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-79a056a93b8b6f6e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="master.png"><br>Master定义了Kubernetes 集群Master/API Server的主要声明，包括Pod Registry、Controller Registry、Service Registry、Endpoint Registry、Minion Registry、Binding Registry、RESTStorage以及Client, 是client(Kubecfg)调用Kubernetes API，管理Kubernetes主要构件Pods、Services、Minions、容器的入口。Master由API Server、Scheduler以及Registry等组成。从下图可知Master的工作流主要分以下步骤：</p><ul><li><strong>Kubecfg</strong> 将特定的请求，比如创建Pod，发送给Kubernetes Client。</li><li><strong>Kubernetes Client</strong> 将请求发送给API server。</li><li><strong>API Server</strong>根据请求的类型，比如创建Pod时storage类型是pods，然后依此选择何种REST Storage API对请求作出处理。</li><li><strong>REST Storage API</strong> 对的请求作相应的处理。将处理的结果存入高可用键值存储系统Etcd中。在API Server响应Kubecfg的请求后。</li><li><strong>Scheduler</strong> 会根据Kubernetes Client获取集群中运行Pod及Minion信息。依据从Kubernetes Client获取的信息，Scheduler将未分发的Pod分发到可用的Minion节点上。</li></ul><h3 id="API-Server-资源操作入口-："><a href="#API-Server-资源操作入口-：" class="headerlink" title="API Server[资源操作入口]："></a>API Server[资源操作入口]：</h3><ol><li><p>提供了资源对象的唯一操作入口，其他所有组件都必须通过它提供的API来操作资源数据，只有API Server与存储通信，其他模块通过API Server访问集群状态。<br>第一，是为了保证集群状态访问的安全。<br>第二，是为了隔离集群状态访问的方式和后端存储实现的方式：API Server是状态访问的方式，不会因为后端存储技术etcd的改变而改变。</p></li><li><p>作为kubernetes系统的入口，封装了核心对象的增删改查操作，以RESTful接口方式提供给外部客户和内部组件调用。对相关的资源数据“全量查询”+“变化监听”，实时完成相关的业务功能。</p></li></ol><h3 id="Controller-Manager-内部管理控制中心-："><a href="#Controller-Manager-内部管理控制中心-：" class="headerlink" title="Controller Manager[内部管理控制中心]："></a>Controller Manager[内部管理控制中心]：</h3><ol><li>实现集群故障检测和恢复的自动化工作，负责执行各种控制器，主要有：</li></ol><ul><li><strong>endpoint-controller：</strong> 定期关联service和pod(关联信息由endpoint对象维护)，保证service到pod的映射总是最新的。</li><li><strong>replication-controller：</strong> 定期关联replicationController和pod，保证replicationController定义的复制数量与实际运行pod的数量总是一致的。</li></ul><h3 id="Scheduler-集群分发调度器-："><a href="#Scheduler-集群分发调度器-：" class="headerlink" title="Scheduler[集群分发调度器]："></a>Scheduler[集群分发调度器]：</h3><ol><li>Scheduler收集和分析当前Kubernetes集群中所有Minion/Node节点的资源(内存、CPU)负载情况，然后依此分发新建的Pod到Kubernetes集群中可用的节点。</li><li>实时监测Kubernetes集群中未分发和已分发的所有运行的Pod。</li><li>监测Minion/Node节点信息，由于会频繁查找Minion/Node节点，Scheduler会缓存一份最新的信息在本地。</li><li>将已分发Pod到指定的Minion/Node节点，把Pod相关的信息Binding写回API Server。</li></ol><h3 id="Kubelet-节点上的Pod管家-："><a href="#Kubelet-节点上的Pod管家-：" class="headerlink" title="Kubelet[节点上的Pod管家]："></a>Kubelet[节点上的Pod管家]：</h3><ol><li>负责Node节点上pod的创建、修改、监控、删除等全生命周期的管理，<br>以及定时上报本Node的状态信息给API Server。</li><li>kubelet是Master API Server和Minion/Node之间的桥梁，接收Master API Server分配给它的commands和work，通过kube-apiserver间接与Etcd集群交互，读取配置信息。<br>具体的工作如下：</li></ol><ul><li><p>1) 设置容器的环境变量、给容器绑定Volume、给容器绑定Port、根据指定的Pod运行一个单一容器、给指定的Pod创建network 容器。</p></li><li><p>2) 同步Pod的状态、从cAdvisor获取container info、 pod info、 root info、 machine info。</p></li><li><p>3) 在容器中运行命令、杀死容器、删除Pod的所有容器</p></li></ul><h3 id="Proxy-负载均衡、路由转发-："><a href="#Proxy-负载均衡、路由转发-：" class="headerlink" title="Proxy[负载均衡、路由转发]："></a>Proxy[负载均衡、路由转发]：</h3><ol><li>Proxy是为了解决外部网络能够访问跨机器集群中容器提供的应用服务而设计的，运行在每个Minion/Node上。Proxy提供TCP/UDP sockets的proxy，每创建一种Service，Proxy主要从etcd获取Services和Endpoints的配置信息（也可以从file获取），然后根据配置信息在Minion/Node上启动一个Proxy的进程并监听相应的服务端口，当外部请求发生时，Proxy会根据Load Balancer将请求分发到后端正确的容器处理。</li><li>Proxy不但解决了同一主宿机相同服务端口冲突的问题，还提供了Service转发服务端口对外提供服务的能力，Proxy后端使用了随机、轮循负载均衡算法。</li></ol><h3 id="kubectl-集群管理命令行工具集-："><a href="#kubectl-集群管理命令行工具集-：" class="headerlink" title="kubectl[集群管理命令行工具集]："></a>kubectl[集群管理命令行工具集]：</h3><ol><li>通过客户端的kubectl命令集操作，API Server响应对应的命令结果，从而达到对kubernetes集群的管理。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Kubernetes 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes(四)之资源对象POD和JOB</title>
      <link href="/2020-03-13-Kubernetes(%E5%9B%9B)%E4%B9%8B%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1POD%E5%92%8CJOB/"/>
      <url>/2020-03-13-Kubernetes(%E5%9B%9B)%E4%B9%8B%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1POD%E5%92%8CJOB/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Kubernetes-POD和JOB"><a href="#Kubernetes-POD和JOB" class="headerlink" title="Kubernetes POD和JOB"></a>Kubernetes POD和JOB</h1><h2 id="pod"><a href="#pod" class="headerlink" title="pod"></a>pod</h2><p>Pod是K8S的最小操作单元，一个Pod可以由一个或多个容器组成；<br>整个K8S系统都是围绕着Pod展开的，比如如何部署运行Pod、如何保证Pod的数量、如何访问Pod等。</p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><p>Pod是能够被创建、调度和管理的最小单元；每个Pod都有一个独立的IP；<br>一个Pod由一个或多个容器构成，并共享命名空间和共享存储等；Pod所有容器在同一个Node上；</p><h4 id="容器生命周期管理"><a href="#容器生命周期管理" class="headerlink" title="容器生命周期管理"></a>容器生命周期管理</h4><p>对资源使用进行限制，resources(requests、limits)</p><p>对容器进行探测：livenessProbe</p><p>集群内的Pod之间都可以任意访问，这一般是通过一个二层网络来实现的。</p><h3 id="Pod与容器"><a href="#Pod与容器" class="headerlink" title="Pod与容器"></a>Pod与容器</h3><p>在Docker中，容器是最小的处理单元，增删改查的对象是容器，容器是一种虚拟化技术，容器之间是隔离的，隔离是基于Linux Namespace实现的。</p><p>而在K8S中，Pod包含一个或者多个相关的容器，Pod可以认为是容器的一种延伸扩展，一个Pod也是一个隔离体，而Pod内部包含的一组容器又是共享的（包括PID、Network、IPC、UTS）。除此之外，Pod中的容器可以访问共同的数据卷来实现文件系统的共享。</p><h3 id="资源请求与限制"><a href="#资源请求与限制" class="headerlink" title="资源请求与限制"></a>资源请求与限制</h3><p>创建Pod时，可以指定计算资源（目前支持的资源类型有CPU和内存），即指定每个容器的资源请求（Request）和资源限制（Limit），资源请求是容器所需的最小资源需求，资源限制则是容器不能超过的资源上限。关系是： 0&lt;=request&lt;=limit&lt;=infinity</p><p>Pod的资源请求就是Pod中所有容器资源请求之和。K8S在调度Pod时，会根据Node中的资源总量（通过cAdvisor接口获得），以及该Node上已使用的计算资源，来判断该Node是否满足需求。</p><p>资源请求能够保证Pod有足够的资源来运行，而资源限制则是防止某个Pod无限制地使用资源，导致其他Pod崩溃。特别是在公有云场景，往往会有恶意软件通过抢占内存来攻击平台。</p><p>具体配置资源限制如下所示:</p><pre><code>resources:limits:    memory: {{ .ContainerMemory }}Gi    cpu: {{ .ContainerCPU }}</code></pre><h3 id="一pod多容器"><a href="#一pod多容器" class="headerlink" title="一pod多容器"></a>一pod多容器</h3><p>Pod主要是在容器化环境中建立一个面向应用的“逻辑主机”模型，它可以包含一个或多个相互间紧密联系的容器。当其中任一容器异常时，该Pod也随之异常。</p><p>一pod多容器，让多个同应用的单一容器整合到一个类虚拟机中，使其所有容器共用一个vm的资源，提高耦合度，从而方便副本的复制，提高整体的可用性。</p><h4 id="一pod多容器的优势："><a href="#一pod多容器的优势：" class="headerlink" title="一pod多容器的优势："></a>一pod多容器的优势：</h4><p>同个Pod下的容器之间能更方便的共享数据和通信，使用相同的网络命名空间、IP地址和端口区间，相互之间能通过localhost来发现和通信。</p><p>在同个Pod内运行的容器共享存储空间（如果设置），存储卷内的数据不会在容器重启后丢失，同时能被同Pod下别的容器读取。</p><p>相比原生的容器接口，Pod通过提供更高层次的抽象，简化了应用的部署和管理，不同容器提供不同服务。Pod就像一个管理横向部署的单元，主机托管、资源共享、协调复制和依赖管理都可以自动处理。</p><h2 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h2><p>在有些场景下，是想要运行一些容器执行某种特定的任务，任务一旦执行完成，容器也就没有存在的必要了。在这种场景下，创建pod就显得不那么合适。于是就是了Job，Job指的就是那些一次性任务。通过Job运行一个容器，当其任务执行完以后，就自动退出，集群也不再重新将其唤醒。</p><p>从程序的运行形态上来区分，可以将Pod分为两类：长时运行服务（jboss、mysql等）和一次性任务（数据计算、测试）。RC创建的Pod都是长时运行的服务，Job多用于执行一次性任务、批处理工作等，执行完成后便会停止（status.phase变为Succeeded）。</p><h3 id="yaml配置参数说明"><a href="#yaml配置参数说明" class="headerlink" title="yaml配置参数说明"></a>yaml配置参数说明</h3><h4 id="重启策略"><a href="#重启策略" class="headerlink" title="重启策略"></a>重启策略</h4><p>支持两种重启策略：</p><ul><li><p><strong>OnFailure</strong>:在出现故障时其内部重启容器，而不是创建。</p></li><li><p><strong>Never</strong>:会在出现故障时创建新的，且故障job不会消失。</p></li></ul><h5 id="设置超时"><a href="#设置超时" class="headerlink" title="设置超时"></a>设置超时</h5><p>job执行超时时间可以通过spec.activeDeadlineSeconds来设置，超过指定时间未完成的job会以DeadlineExceeded原因停止</p><h4 id="并行"><a href="#并行" class="headerlink" title="并行"></a>并行</h4><p>.spec.completions：这个job运行pod的总次数</p><p>.spec.parallelism：并发数，每次同时运行多少个pod</p><p>当completions少于parallelism，parallelism的值为completions</p><p>可以使用kubectl scale命令来增加或者减少completions的值</p><h4 id="pod-selector"><a href="#pod-selector" class="headerlink" title="pod selector"></a>pod selector</h4><p>job同样可以指定selector来关联pod。需要注意的是job目前可以使用两个API组来操作，batch/v1和extensions/v1beta1。当用户需要自定义selector时，使用两种API组时定义的参数有所差异。</p><p>使用batch/v1时，用户需要将jod的spec.manualSelector设置为true，才可以定制selector。默认为false。</p><p>使用extensions/v1beta1时，用户不需要额外的操作。因为extensions/v1beta1的spec.autoSelector默认为false，该项与batch/v1的spec.manualSelector含义正好相反。换句话说，使用extensions/v1beta1时，用户不想定制selector时，需要手动将spec.autoSelector设置为true。</p><p>例子</p><pre><code>apiVersion: batch/v1kind: Jobmetadata:labels:app: jobproject: lykopsversion: v1name: lykops-jobnamespace: defaultspec:completions: 50parallelism: 5template:metadata:    labels:    app: job    job-name: lykops-job    project: lykops    version: v1    name: lykops-jobspec:    containers:    - command: [&apos;sleep&apos;,&apos;60&apos;]    image: web:apache    name: lykops-job    restartPolicy: Never</code></pre><h2 id="POD和JOB的区别"><a href="#POD和JOB的区别" class="headerlink" title="POD和JOB的区别"></a>POD和JOB的区别</h2><p>job执行完后，不会自动启动一个新的pod，pod也不会被自动删除。<br>使用kubectl get pod无法显示执行完的job的pod，详细查看已运行过的job的pod需要添加参数—all-show或者-a，kubectl get pods -a。</p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Kubernetes 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes(七)之容器运行时(CRI)介绍</title>
      <link href="/2019-11-14-Kubernetes(%E4%B8%83)%E4%B9%8B%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6(CRI)%E4%BB%8B%E7%BB%8D/"/>
      <url>/2019-11-14-Kubernetes(%E4%B8%83)%E4%B9%8B%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6(CRI)%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="容器运行时简介-CRI"><a href="#容器运行时简介-CRI" class="headerlink" title="容器运行时简介(CRI)"></a>容器运行时简介(CRI)</h3><p>容器运行时接口（Container Runtime Interface，简称 CRI）是 Kubernetes v1.5 引入的容器运行时接口，它将 Kubelet 与容器运行时解耦，将原来完全面向 Pod 级别的内部接口拆分成面向 Sandbox 和 Container 的 gRPC 接口，并将镜像管理和容器管理分离到不同的服务。且到笔者目前的时间段CRI是Alpha版本。</p><h3 id="容器运行时总流程-CRI"><a href="#容器运行时总流程-CRI" class="headerlink" title="容器运行时总流程(CRI)"></a>容器运行时总流程(CRI)</h3><p>Kubelet与容器运行时通信（或者是CRI插件填充了容器运行时）时，Kubelet就像是客户端，而CRI插件就像对应的服务器。它们之间可以通过Unix 套接字或者gRPC框架进行通信。</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-401ca5f0fa105800.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="image.png"></p><p>protocol buffers API包含了两个gRPC服务：ImageService和RuntimeService。ImageService提供了从镜像仓库拉取、查看、和移除镜像的RPC。RuntimeSerivce包含了Pods和容器生命周期管理的RPC，以及跟容器交互的调用(exec/attach/port-forward)。一个单块的容器运行时能够管理镜像和容器（例如：Docker和Rkt），并且通过同一个套接字同时提供这两种服务。这个套接字可以在Kubelet里通过标识–container-runtime-endpoint和–image-service-endpoint进行设置。<br>采用CRI后kubelet 架构图如下图所示：<br><img src="/img/loading.gif" class="lazyload" data-src="https://upload-images.jianshu.io/upload_images/17904159-3e069487e4c290a1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"  alt="image.png"></p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://yq.aliyun.com/articles/679819" target="_blank" rel="external nofollow noopener noreferrer">https://yq.aliyun.com/articles/679819</a></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> Kubernetes 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《一句顶一万句》</title>
      <link href="/2019-10-12-%E4%B8%80%E5%8F%A5%E9%A1%B6%E4%B8%80%E4%B8%87%E5%8F%A5/"/>
      <url>/2019-10-12-%E4%B8%80%E5%8F%A5%E9%A1%B6%E4%B8%80%E4%B8%87%E5%8F%A5/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="《一句顶一万句》读后感"><a href="#《一句顶一万句》读后感" class="headerlink" title="《一句顶一万句》读后感"></a>《一句顶一万句》读后感</h2><pre><code>一句顶一万句，一句胜千言</code></pre><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/book1.jpg?raw=true"  alt></p><h3 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h3><p>最近由于出差来回路上的碎片时间挺多，就想着利用这些碎片时间来读几本书。一开始看到本书的书名以为是教人如何交谈或者演讲之类的教学书，<br>看完了才知道其实不仅仅教人如何说话，更是把“说得上话”作为一种生活，孜孜以求。说得上的，内心便不感孤独，说不上的，三两句之后杀人放火，人与人之间的关系，又皆有说话开始，或近或远、或亲或疏，或延续或断绝…… </p><h3 id="简介："><a href="#简介：" class="headerlink" title="简介："></a>简介：</h3><p><strong>《一句顶一万句》这本书出自刘震云先生</strong>，这本书真的写出了中国式的百年孤独，切近当时的生活，反应当时社会现状，写出了大部分中国人内心的寂寞和渴望回归中国乡土，平民百姓，是我熟悉的阶层和熟悉的文化。朴实无华的语言说尽了大多数人的一生，读来有趣得很。很多人穷其一生都在找一个说得着的人，有的人找到了，有的人没找到。找到的有些人又发现原先说得着的人现在又说不着了，又或者这个说得着不是那个说得着。说得着的人或因为一句话一件事又说不着了，本说不着的人又因为这件事说得着了。没找到的人便不喜欢说话，不喜欢说话还分心里有话和心里没话。</p><h3 id="概述："><a href="#概述：" class="headerlink" title="概述："></a>概述：</h3><h4 id="本书的概括主要由两大部分组成即："><a href="#本书的概括主要由两大部分组成即：" class="headerlink" title="本书的概括主要由两大部分组成即："></a>本书的概括主要由两大部分组成即：</h4><ul><li><ol><li><strong>出延津记(上部分)</strong></li></ol></li><li><ol start="2"><li><strong>回延津记(下部分)</strong></li></ol></li></ul><p><strong>小说的前半部写的是过去:</strong> 孤独无助的杨百顺也是杨摩西也是吴摩西失去唯一能够“说的上话”的养女，为了寻找，走出延津县城；<br><strong>小说的后半部写的是现在;</strong> 也就是吴摩西养女巧玲的儿子——牛建国，同样为了摆脱孤独寻找“说的上话”的朋友，走向延津县城。一出一走，延宕百年。</p><p>小说中所有的情节关系和人物结构，所有的社群组织和家庭和谐，乃至于亲情爱情，都和人与人能不能对上话，对的话能不能触及心灵、提供温暖、化解冲突、激发情欲有关。话，一旦成了人与人之间唯一交流的东西，寻找和孤独便伴随一生。心灵的疲惫与生命的颓废，便如影随形地产生了。小说的叙事风格类似明清的野稗日记，语句洗练，情节简洁，叙事直接。本书的每一个字每一句话，都构成言说的艺术，都能拧出作家的汗水。更为重要的是，作家唯有用此语言，才有对应和表现作品的内涵。在与神对话的西方文化中，因为神的无处不在而愉悦自在。人与人之间虽说来往不多，但并不孤独；而与人对话的中国文化和浮生百姓，却因为极端注重现实和儒家传统，加上其社群、地位和利益的不同，人心难测和诚信缺失，能够说贴心话、温暖灵魂的朋友并不多，反倒生活在千年的孤独当中。</p><h2 id="感悟："><a href="#感悟：" class="headerlink" title="感悟："></a>感悟：</h2><p>《一句顶一万句》是一本非常优秀的小说。很符合过去的中国平民农村老百姓的生活。日子天天鸡零狗碎地过，天天东家长西家短，看似絮絮叨叨地车轱辘话，人的一辈子也就这么过去了。能跟你说的上话，我们就是朋友；说不上话了，我们就掰了。作者不停的引用《圣经》和《论语》中的话大概就是为了告诉我们：没有信仰的人大都孤独，因为他们一生都在寻找。没有信仰的人的精神寄托也是人，人不是一个固定的东西，人是会变的，所以他们一生都在寻找。书中把人与人间的关系，分成“说得上话”和“说不上话”两种。简单的分类法，却非常有效。无论家人，朋友还是夫妻，一旦说上话了，人就亲了。反过来，一旦说不上，就没有亲味儿了。想想也是，记得有人说康熙虽宫粉黛三千，最爱的人却是容妃。他到容妃那里，最爱说的话就是：“朕想和你说说话。”然后把一些杂事倾诉一番。到后来，他不得已废了容妃，再想找人说话，已经是人去楼空，虽为千古大帝，连一个说话的人也没有。</p><p>“话，一旦成为人与人唯一沟通的东西，寻找和孤独便伴随一生。”生活中必定有这样的经历，有的人与之交谈说话通畅舒心，不论长久不见或经常相见，总能聊得来，即使沉默许久也不必刻意找话题，无话也不觉冷场;也有的人，即使日日见面或千里相聚，总是三五句话便收了场，觉着冷场还要找个话题说说，便就是“尬聊”了。吴摩西为了寻找能够“说得上话”的养女巧玲，走出延津，天南海北寻找不息，最终把自己的名字找没了还没歇息;牛爱国为了寻找吴摩西临死前留个母亲曹青娥(也就是巧玲)的一句话，也是天南海北一顿走，遇到那句“日子过的是以后，不是以前”后想明白了，寻找能跟他“说得上话”的章楚红和寻找吴摩西临终前留下的那句话一样重要，便也要继续找下去了。书中的情节和人物关系，社会群组和家庭关系，乃至意念想法，都和人与人能不能“说得上话”，说的话能不能触及心灵、提供温暖、化解矛盾有关，可谓“良言一句三冬暖，恶语伤人六月寒”，怪不得老人们常常教育孩子要好好说话，可见这个说话真是极其重要的，话说对了一句顶一万句，话说不对一万句也是白搭，又可谓“酒逢知己千杯少，话不投机半句多”。</p><p>书中描写的人物都为着能够说上话，或忠诚或背叛，或亲近或疏远，或者不远万里去寻找着，义无反顾地追逐“一句顶一万句”的身影，也指引着现实中的人们不断去寻找精神上的依托和慰藉。</p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift3.11 nvidia gpu任务调度</title>
      <link href="/2019-10-09-OpenShift3.11%E4%B9%8Bnvidia-gpu/"/>
      <url>/2019-10-09-OpenShift3.11%E4%B9%8Bnvidia-gpu/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Openshift3-11-如何调度GPU任务POD"><a href="#Openshift3-11-如何调度GPU任务POD" class="headerlink" title="Openshift3.11 如何调度GPU任务POD"></a>Openshift3.11 如何调度GPU任务POD</h1><p><strong>参考</strong>：<a href="https://blog.openshift.com/how-to-use-gpus-with-deviceplugin-in-openshift-3-10/" target="_blank" rel="external nofollow noopener noreferrer">https://blog.openshift.com/how-to-use-gpus-with-deviceplugin-in-openshift-3-10/</a></p><p><strong>基础环境安装</strong>：NVIDIA驱动、nvidia-docker安装与测试详见参考链接。<br>本文主要提供经过实践验证过的创建SCC服务的nvidia-deviceplugin-scc.yaml 文件和 创建NVIDIA Device Plugin daemonset  的nvidia-deviceplugin.yaml文件以及测试调用GPU POD test-gpu.yaml 文件。</p><ul><li><p><strong>1.创建SCC服务 “oc create -f nvidia-deviceplugin-scc.yaml”</strong></p><pre><code>allowHostDirVolumePlugin: trueallowHostIPC: trueallowHostNetwork: trueallowHostPID: trueallowHostPorts: trueallowPrivilegedContainer: trueallowedCapabilities:- &apos;*&apos;allowedFlexVolumes: nullapiVersion: v1defaultAddCapabilities:- &apos;*&apos;fsGroup:type: RunAsAnygroups:- system:cluster-admins- system:nodes- system:masterskind: SecurityContextConstraintsmetadata:annotations:kubernetes.io/description: anyuid provides all features of the restricted SCC    but allows users to run with any UID and any GID.creationTimestamp: nullname: nvidia-devicepluginpriority: 10readOnlyRootFilesystem: falserequiredDropCapabilities:runAsUser:type: RunAsAnyseLinuxContext:type: RunAsAnyseccompProfiles:- &apos;*&apos;supplementalGroups:type: RunAsAnyusers:- system:serviceaccount:nvidia:nvidia-devicepluginvolumes:- &apos;*&apos;:</code></pre></li><li><p><strong>2.创建 NVIDIA Device Plugin daemonset  “oc create -f nvidia-deviceplugin.yaml”</strong></p></li></ul><pre><code>apiVersion: extensions/v1beta1kind: DaemonSetmetadata:name: nvidia-device-plugin-daemonsetnamespace: nvidiaspec:template:    metadata:    # Mark this pod as a critical add-on; when enabled, the critical add-on scheduler    # reserves resources for critical add-on pods so that they can be rescheduled after    # a failure.  This annotation works in tandem with the toleration below.    annotations:        scheduler.alpha.kubernetes.io/critical-pod: &quot;&quot;    labels:        name: nvidia-device-plugin-ds    spec:    affinity:        nodeAffinity:        requiredDuringSchedulingIgnoredDuringExecution:            nodeSelectorTerms:            - matchExpressions:            - key: openshift.com/gpu-accelerator                operator: Exists    tolerations:    # Allow this pod to be rescheduled while the node is in &quot;critical add-ons only&quot; mode.    # This, along with the annotation above marks this pod as a critical add-on.    - key: CriticalAddonsOnly        operator: Exists    - key: nvidia.com/gpu        operator: Exists        effect: NoSchedule    serviceAccount: nvidia-deviceplugin    serivceAccountName: nvidia-deviceplugin    hostNetwork: true    hostPID: true    containers:    - image: nvidia/k8s-device-plugin:1.11        name: nvidia-device-plugin-ctr        securityContext:        allowPrivilegeEscalation: false        capabilities:            drop: [&quot;ALL&quot;]        seLinuxOptions:            type: nvidia_container_t        volumeMounts:        - name: device-plugin            mountPath: /var/lib/kubelet/device-plugins    volumes:        - name: device-plugin        hostPath:            path: /var/lib/kubelet/device-plugins</code></pre><ul><li><strong>3.测试调用GPU “测试调用GPU POD test-gpu.yaml”</strong></li></ul><pre><code>apiVersion: v1kind: Podmetadata:name: cuda3namespace: nvidiaspec:restartPolicy: OnFailurecontainers:    - name: cuda3    image: &quot;docker.io/nvidia/cuda:9.0-base&quot;    args: [&quot;nvidia-smi&quot;]    resources:        limits:        nvidia.com/gpu: 3 # requesting 3 GPU</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 大数据 </tag>
            
            <tag> Docker </tag>
            
            <tag> Openshift </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gluster Fs(一)基础知识介绍</title>
      <link href="/2019-08-23-Gluster%20FS%20(%E4%B8%80)%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D/"/>
      <url>/2019-08-23-Gluster%20FS%20(%E4%B8%80)%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="基础知识铺垫-什么是分布式文件系统？"><a href="#基础知识铺垫-什么是分布式文件系统？" class="headerlink" title="基础知识铺垫(什么是分布式文件系统？)"></a>基础知识铺垫(什么是分布式文件系统？)</h2><p>分布式文件系统（Distributed File System）是指文件系统管理的物理存储资源并不直接与本地节点相连，而是分布于计算网络中的一个或者多个节点的计算机上。目前意义上的分布式文件系统大多都是由多个节点计算机构成，结构上是典型的客户机/服务器模式。流行的模式是当客户机需要存储数据时，服务器指引其将数据分散的存储到多个存储节点上，以提供更快的速度，更大的容量及更好的冗余特性。</p><pre><code>目前流行的分布式文件系统有许多，如MooseFS、OpenAFS、GoogleFS等。</code></pre><h2 id="GlusterFS-简介"><a href="#GlusterFS-简介" class="headerlink" title="GlusterFS 简介"></a>GlusterFS 简介</h2><p>GlusterFS系统是一个可扩展的网络文件系统，相比其他分布式文件系统，GlusterFS具有高扩展性、高可用性、高性能、可横向扩展等特点，并且其没有元数据服务器的设计，让整个服务没有单点故障的隐患。</p><h3 id="关键词介绍"><a href="#关键词介绍" class="headerlink" title="关键词介绍"></a>关键词介绍</h3><ul><li><strong>Brick:</strong> GFS中的存储单元，通过是一个受信存储池中的服务器的一个导出目录。可以通过主机名和目录名来标识，如’HOME:PATH’</li><li><strong>Client:</strong> 挂载了GFS卷的设备</li><li><strong>Extended Attributes:</strong> xattr是一个文件系统的特性，其支持用户或程序关联文件/目录和元数据。</li><li><strong>FUSE:</strong> Filesystem Userspace是一个可加载的内核模块，其支持非特权用户创建自己的文件系统而不需要修改内核代码。通过在用户空间运行文件系统的代码通过FUSE代码与内核进行桥接。</li><li><strong>Geo-Replication：</strong> 跨地理位置的副本</li><li><strong>GFID:</strong> GFS卷中的每个文件或目录都有一个唯一的128位的数据相关联，其用于模拟inode</li><li><strong>Namespace:</strong> 每个Gluster卷都导出单个ns作为POSIX的挂载点</li><li><strong>Node:</strong> 一个拥有若干brick的设备</li><li><strong>RDMA:</strong> 远程直接内存访问，支持不通过双方的OS进行直接内存访问。</li><li><strong>RRDNS:</strong> round robin DNS是一种通过DNS轮转返回不同的设备以进行负载均衡的方法</li><li><strong>Self-heal:</strong> 用于后台运行检测复本卷中文件和目录的不一致性并解决这些不一致。</li><li><strong>Split-brain:</strong> 脑裂</li><li><strong>Volfile:</strong> glusterfs进程的配置文件，通常位于/var/lib/glusterd/vols/volname</li><li><strong>Volume:</strong> 一组bricks的逻辑集合</li></ul><h3 id="无元数据设计"><a href="#无元数据设计" class="headerlink" title="无元数据设计"></a>无元数据设计</h3><p>元数据是用来描述一个文件或给定区块在分布式文件系统中所在的位置，简而言之就是某个文件或某个区块存储的位置。传统分布式文件系统大都会设置元数据服务器或者功能相近的管理服务器，主要作用就是用来管理文件与数据区块之间的存储位置关系。相较其他分布式文件系统而言，GlusterFS并没有集中或者分布式的元数据的概念，取而代之的是弹性哈希算法。集群中的任何服务器和客户端都可以利用哈希算法、路径及文件名进行计算，就可以对数据进行定位，并执行读写访问操作。</p><p>这种设计带来的好处是极大的提高了扩展性，同时也提高了系统的性能和可靠性；另一显著的特点是如果给定确定的文件名，查找文件位置会非常快。但是如果要列出文件或者目录，性能会大幅下降，因为列出文件或者目录时，需要查询所在节点并对各节点中的信息进行聚合。此时有元数据服务的分布式文件系统的查询效率反而会提高许多。</p><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>主要应用在集群系统中，具有很好的可扩展性。软件的结构设计良好，易于扩展和配置，通过各个模块的灵活搭配以得到针对性的解决方案。可解决以下问题：网络存储，联合存储(融合多个节点上的存储空间)，冗余备份，大文件的负载均衡(分块)。由于缺乏一些关键特性，可靠性也未经过长时间考验，还不适合应用于需要提供 24 小时不间断服务的产品环境。目前适合应用于大数据量的离线应用。<br>　　由于它良好的软件设计，以及由专门的公司负责开发，进展非常迅速，几个月或者一年后将会有很大的改进，非常值得期待。<br>GlusterFS通过Infiniband RDMA 或者Tcp/Ip 方式将许多廉价的x86 主机，通过网络互联成一个并行的网络文件系统</p><h3 id="Gluster-Fs-集群模式卷的应用介绍"><a href="#Gluster-Fs-集群模式卷的应用介绍" class="headerlink" title="Gluster Fs 集群模式卷的应用介绍"></a>Gluster Fs 集群模式卷的应用介绍</h3><h4 id="1-分布式卷（Distributed-Volume）"><a href="#1-分布式卷（Distributed-Volume）" class="headerlink" title="1. 分布式卷（Distributed Volume）"></a>1. 分布式卷（Distributed Volume）</h4><p>又称其为哈希卷，近似于RAID0，文件没有分片，文件根据hash算法写入各个节点的硬盘上，优点是容量大，缺点是没数据冗余即可靠性无法保障。</p><p><strong>创建分布式卷指令如下：</strong></p><pre><code>gluster volume create test-distributed-volume server1:/exp1 server2:/exp2 server3:/exp3 server4:/exp4</code></pre><h4 id="2-复制卷（Replicated-Volume）"><a href="#2-复制卷（Replicated-Volume）" class="headerlink" title="2. 复制卷（Replicated Volume）"></a>2. 复制卷（Replicated Volume）</h4><p>复制卷设定复制的份数，决定集群的大小，通常与分布式卷或者条带卷组合使用，解决前两种存储卷的冗余缺陷。缺点是磁盘利用率低。</p><p>复本卷在创建时可指定复本的数量，通常为2或者3，复本在存储时会在卷的不同brick上，因此有几个复本就必须提供至少多个brick，当其中一台服务器岩机后，可以从另一台服务器读取数据，因此复制卷提高了数据可靠性的同时，还提供了数据冗余的功能。</p><p><strong>创建分布式卷指令如下：</strong></p><pre><code>gluster volume create test-replicated-volume replica 2 transport tcp server1:/exp1 server2:/exp2</code></pre><h4 id="3-分布式复制卷（Distributed-Replicated-Volume）"><a href="#3-分布式复制卷（Distributed-Replicated-Volume）" class="headerlink" title="3. 分布式复制卷（Distributed Replicated Volume）"></a>3. 分布式复制卷（Distributed Replicated Volume）</h4><p>分布式复制GlusterFS卷结合了分布式和复制Gluster卷的特点。</p><p><strong>创建分布式卷指令如下：</strong></p><pre><code>gluster volume create test-distributed-replicated-volume  replica 2 transport tcp server1:/exp1 server2:/exp2 server3:/exp3 server4:/exp4</code></pre><h4 id="3-条带卷（Striped-Volume）"><a href="#3-条带卷（Striped-Volume）" class="headerlink" title="3. 条带卷（Striped Volume）"></a>3. 条带卷（Striped Volume）</h4><p>文件是分片均匀写在各个节点的硬盘上的，优点是分布式读写，性能整体较好。缺点是没冗余，分片随机读写可能会导致硬盘IOPS饱和。</p><p><strong>创建分布式卷指令如下：</strong></p><pre><code>gluster volume create test-striped-volume stripe 2 transport tcp server1:/exp1 server2:/exp2</code></pre><h4 id="4-分布式条带卷（Distributed-Striped-Volume）"><a href="#4-分布式条带卷（Distributed-Striped-Volume）" class="headerlink" title="4. 分布式条带卷（Distributed Striped Volume）"></a>4. 分布式条带卷（Distributed Striped Volume）</h4><p>当单个文件的体型十分巨大，客户端数量更多时，条带卷已经无法满足需求，此时将分布式与条带化结合起来是一个比较好的选择。其性能与服务器数量有关。</p><p><strong>创建分布式卷指令如下：</strong></p><pre><code>gluster volume create test-distributed-striped-volume stripe 4 transport tcp server1:/exp1 server2:/exp2 server3:/exp3 server4:/exp4 server5:/exp5 server6:/exp6 server7:/exp7 server8:/exp8</code></pre><p><strong>博客著作权归本作者所有，任何形式的转载都请联系作者获得授权并注明出处。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift3.11集群安装</title>
      <link href="/2019-08-19-Openshift3.11%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/"/>
      <url>/2019-08-19-Openshift3.11%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h3><pre><code>CentOS Linux release 7.6.1810 (Core) </code></pre><h3 id="集群信息"><a href="#集群信息" class="headerlink" title="集群信息"></a>集群信息</h3><table><thead><tr><th>主机</th><th>IP</th><th>内存</th><th>硬盘大小</th><th>备注</th></tr></thead><tbody><tr><td>host-192-168-1-12</td><td>192.168.1.12</td><td>31G</td><td>40G+500G</td><td>MASTER</td></tr><tr><td>host-192-168-1-13</td><td>192.168.1.13</td><td>31G</td><td>40G+500G</td><td>INFRA</td></tr><tr><td>host-192-168-1-14</td><td>192.168.1.14</td><td>31G</td><td>40G+500G</td><td>COMPUTER</td></tr></tbody></table><h3 id="离线安装包准备"><a href="#离线安装包准备" class="headerlink" title="离线安装包准备"></a>离线安装包准备</h3><h4 id="离线docker镜像准备"><a href="#离线docker镜像准备" class="headerlink" title="离线docker镜像准备"></a>离线docker镜像准备</h4><pre><code>yum install docker -ysystemctl start docker; systemctl enable dockerdocker pull docker.io/openshift/origin-node:v3.11docker pull docker.io/openshift/origin-control-plane:v3.11docker pull docker.io/openshift/origin-deployer:v3.11.0docker pull docker.io/openshift/origin-haproxy-router:v3.11docker pull docker.io/openshift/origin-pod:v3.11.0docker pull docker.io/openshift/origin-web-console:v3.11docker pull docker.io/openshift/origin-docker-registry:v3.11docker pull docker.io/openshift/origin-metrics-server:v3.11docker pull docker.io/openshift/origin-console:v3.11docker pull docker.io/openshift/origin-metrics-heapster:v3.11docker pull docker.io/openshift/origin-metrics-hawkular-metrics:v3.11docker pull docker.io/openshift/origin-metrics-schema-installer:v3.11docker pull docker.io/openshift/origin-metrics-cassandra:v3.11docker pull docker.io/cockpit/kubernetes:latestdocker pull quay.io/coreos/cluster-monitoring-operator:v0.1.1docker pull quay.io/coreos/prometheus-config-reloader:v0.23.2docker pull quay.io/coreos/prometheus-operator:v0.23.2docker pull docker.io/openshift/prometheus-alertmanager:v0.15.2docker pull docker.io/openshift/prometheus-node-exporter:v0.16.0docker pull docker.io/openshift/prometheus:v2.3.2docker pull docker.io/grafana/grafana:5.2.1docker pull quay.io/coreos/kube-rbac-proxy:v0.3.1docker pull quay.io/coreos/etcd:v3.2.22docker pull quay.io/coreos/kube-state-metrics:v1.3.1docker pull docker.io/openshift/oauth-proxy:v1.1.0docker pull quay.io/coreos/configmap-reload:v0.0.1</code></pre><h4 id="离线rpm包准备"><a href="#离线rpm包准备" class="headerlink" title="离线rpm包准备"></a>离线rpm包准备</h4><pre><code>origin-3.11.0-1.el7.git.0.62803d0.x86_64.rpm origin-hyperkube-3.11.0-1.el7.git.0.62803d0.x86_64.rpmorigin-clients-3.11.0-1.el7.git.0.62803d0.x86_64.rpmorigin-node-3.11.0-1.el7.git.0.62803d0.x86_64.rpm</code></pre><p><strong>执行如下命名：</strong></p><pre><code>yum install -y origin-node-3.11.0  origin-hyperkube-3.11.0 origin-clients-3.11.0 conntrack-tools# master安装yum install -y origin-3.11.0</code></pre><h3 id="基础依赖包安装"><a href="#基础依赖包安装" class="headerlink" title="基础依赖包安装"></a>基础依赖包安装</h3><pre><code>yum install wget git net-tools bind-utils yum-utils iptables-services bridge-utils bash-completion kexec-tools sos psacct vim python-setuptools unzip tree docker –yyum install atomic -yyum install -y centos-release-openshift-origin311 ceph-common container-selinux docker epel extras python-docker</code></pre><h3 id="配置网络安全"><a href="#配置网络安全" class="headerlink" title="配置网络安全"></a>配置网络安全</h3><h4 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h4><pre><code>sudo systemctl stop firewalld.service; sudo systemctl disable firewalld.service</code></pre><h3 id="配置iptables"><a href="#配置iptables" class="headerlink" title="配置iptables"></a>配置iptables</h3><pre><code>cp /etc/sysconfig/iptables /etc/sysconfig/iptables.bak.$(date &quot;+%Y%m%d%H%M%S&quot;);sed -i &apos;/.*--dport 22 -j ACCEPT.*/a\-A INPUT -p tcp -m state --state NEW -m tcp --dport 53 -j ACCEPT&apos; /etc/sysconfig/iptables;sed -i &apos;/.*--dport 22 -j ACCEPT.*/a\-A INPUT -p udp -m state --state NEW -m udp --dport 53 -j ACCEPT&apos; /etc/sysconfig/iptables;sed -i &apos;/.*--dport 22 -j ACCEPT.*/a\-A INPUT -p tcp -m state --state NEW -m tcp --dport 5000 -j ACCEPT&apos; /etc/sysconfig/iptables;sed -i &apos;/.*--dport 22 -j ACCEPT.*/a\-A INPUT -p tcp -m state --state NEW -m tcp --dport 81 -j ACCEPT&apos; /etc/sysconfig/iptables;#在master节点允许 8443 for node joinsed -i &apos;/.*--dport 22 -j ACCEPT.*/a\-A INPUT -p tcp -m state --state NEW -m tcp --dport 8443 -j ACCEPT &apos; /etc/sysconfig/iptables;sed -i &apos;/.*--dport 22 -j ACCEPT.*/a\-A INPUT -p tcp -m state --state NEW -m tcp --dport 8443 -j ACCEPT &apos; /etc/sysconfig/iptables;systemctl restart iptables;systemctl enable iptables</code></pre><h3 id="先在一个节点上DNS配置"><a href="#先在一个节点上DNS配置" class="headerlink" title="先在一个节点上DNS配置"></a>先在一个节点上DNS配置</h3><p>编辑/etc/hosts文件加入以下内容：</p><pre><code>192.168.1.12 openshift1192.168.1.13 openshift2192.168.1.14 openshift3</code></pre><h3 id="主机hostname配置"><a href="#主机hostname配置" class="headerlink" title="主机hostname配置"></a>主机hostname配置</h3><p><strong>注意：</strong> 此时DNS 配置需要与主机名保持一致</p><pre><code>hostnamectl set-hostname openshift1/openshift2/openshift3hostnamectl --prettyhostnamectl --statichostnamectl --transientcat /etc/hostname</code></pre><p>分别在节点上执行以上命令</p><h3 id="设置时区、配置chrony时钟同步"><a href="#设置时区、配置chrony时钟同步" class="headerlink" title="设置时区、配置chrony时钟同步"></a>设置时区、配置chrony时钟同步</h3><p><strong>Openshift默认使用ntp来进行时间同步。如果使用chrony来做时间同步，步骤如下：</strong></p><ul><li><p><strong>(1)设置时区</strong></p><pre><code>查看时区: timedatectl设置时区: timedatectl set-timezone Asia/Shanghai</code></pre></li><li><p><strong>(2)开通chrony server的123端口的访问策略（iptables）</strong></p><pre><code>sudo iptables -I INPUT -p udp --dport 123 -j ACCEPTsudo vi /etc/sysconfig/iptables，增加: -I INPUT -p udp --dport 123 -j ACCEPT重启iptables。</code></pre></li><li><p><strong>(3)每台主机开启网络时间同步：</strong></p><pre><code>查看时间同步状态：timedatectl status开启时间同步状态：sudo timedatectl set-ntp true</code></pre><pre><code># timedatectl status Local time: Mon 2019-08-19 11:20:52 CST Universal time: Mon 2019-08-19 03:20:52 UTC RTC time: Mon 2019-08-19 03:40:59 Time zone: Asia/Shanghai (CST, +0800)NTP enabled: yesNTP synchronized: yesRTC in local TZ: noDST active: n/a</code></pre></li><li><p><strong>(4)配置chrony服务端与客户端</strong><br>可以在集群内选择一台作为chrony服务器，其他节点从该server同步时间。<br>chrony一般情况下会已安装，rpm -aq|grep chrony</p><p>  <strong>Chrony Server端配置：</strong><br>  sudo vi /etc/chrony.conf<br>  server 10.1.234.164 iburst  #指定本机IP或者上游的时间服务器<br>  allow 10.1.0.0/16</p><p>  <strong>Chrony客户端配置：</strong> vi /etc/chrony.conf<br>  server 10.1.234.164 iburst  #指定上游的时间服务器</p><p>  启动chrony：<br>  ansible -i dfhosts.cfg all -b -m shell -a “sudo systemctl start chronyd”<br>  ansible -i dfhosts.cfg all -b -m shell -a “sudo systemctl enable chronyd”<br>  ansible -i dfhosts.cfg all -b -m shell -a “chronyc sources -v” #查看chrony server源（同步的server的状态显示为^*）</p></li></ul><pre><code>210 Number of sources = 5.-- Source mode  &apos;^&apos; = server, &apos;=&apos; = peer, &apos;#&apos; = local clock./ .- Source state &apos;*&apos; = current synced, &apos;+&apos; = combined , &apos;-&apos; = not combined,| /   &apos;?&apos; = unreachable, &apos;x&apos; = time may be in error, &apos;~&apos; = time too variable.||                                                 .- xxxx [ yyyy ] +/- zzzz||      Reachability register (octal) -.           |  xxxx = adjusted offset,||      Log2(Polling interval) --.      |          |  yyyy = measured offset,||                                \     |          |  zzzz = estimated error.||                                 |    |           \MS Name/IP address         Stratum Poll Reach LastRx Last sample===============================================================================^* openshift1                    3   7   377    97    +70us[ +154us] +/-   90ms^? undefined.hostname.local&gt;     0  10     0     -     +0ns[   +0ns] +/-    0ns^? 139.199.214.202               0  10     0     -     +0ns[   +0ns] +/-    0ns^? ntp7.flashdance.cx            0  10     0     -     +0ns[   +0ns] +/-    0ns^? amy.chl.la                    0  10     0     -     +0ns[   +0ns] +/-    0ns</code></pre><h3 id="节点间ansible-免密登录配置"><a href="#节点间ansible-免密登录配置" class="headerlink" title="节点间ansible 免密登录配置"></a>节点间ansible 免密登录配置</h3><pre><code>ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa):/root/.ssh/id_rsa already exists.Overwrite (y/n)? yEnter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:UqtSrQUgOe0WeA9rfqDSMn5U3J4LzQQ2Ks+hWUbDKMA root@ldapThe key&apos;s randomart image is:+---[RSA 2048]----+|+ ++.            ||.E+===           ||. .+=== .        || . =*o.* .       || .O=o.B S        ||+oo+.o.X         ||.+. ..+ .        || . . . .         ||  .              |+----[SHA256]-----+ssh-copy-id -i ~/.ssh/id_rsa.pub openshift1/openshift2/openshift3;</code></pre><h3 id="安装-openshift-ansible"><a href="#安装-openshift-ansible" class="headerlink" title="安装 openshift ansible"></a>安装 openshift ansible</h3><pre><code>yum install -y ansible-2.6.14-1.el7yum install -y openshift-ansible</code></pre><h4 id="配置ansible-文件"><a href="#配置ansible-文件" class="headerlink" title="配置ansible 文件"></a>配置ansible 文件</h4><pre><code>[root@openshift1 ~]# cat /etc/ansible/hosts# Create an OSEv3 group that contains the masters, nodes, and etcd groups[OSEv3:children]mastersnodesetcd# Set variables common for all OSEv3 hosts[OSEv3:vars]# SSH user, this user should allow ssh based auth without requiring a passwordansible_ssh_user=root#openshift_deployment_type=openshift-enterpriseopenshift_deployment_type=originopenshift_release=&quot;3.11&quot;openshift_image_tag=v3.11openshift_pkg_version=-3.11.0openshift_use_openshift_sdn=true# If ansible_ssh_user is not root, ansible_become must be set to true#ansible_become=true#containerized=false# default selectors for router and registry services# openshift_router_selector=&apos;node-role.kubernetes.io/infra=true&apos;# openshift_registry_selector=&apos;node-role.kubernetes.io/infra=true&apos;# uncomment the following to enable htpasswd authentication; defaults to DenyAllPasswordIdentityProvideropenshift_master_identity_providers=[{&apos;name&apos;: &apos;htpasswd_auth&apos;, &apos;login&apos;: &apos;true&apos;, &apos;challenge&apos;: &apos;true&apos;, &apos;kind&apos;: &apos;HTPasswdPasswordIdentityProvider&apos;}]#openshift_master_default_subdomain=ai.comopenshift_disable_check=memory_availability,disk_availability,docker_image_availabilityos_sdn_network_plugin_name=&apos;redhat/openshift-ovs-networkpolicy&apos;openshift_master_cluster_method=nativeopenshift_master_cluster_hostname=openshift1openshift_master_cluster_public_hostname=openshift1# falseansible_service_broker_install=falseopenshift_enable_service_catalog=falsetemplate_service_broker_install=falseopenshift_logging_install_logging=falseenable_excluders=false# registry passwd#oreg_url=10.1.236.77:5000/openshift3/ose-${component}:${version}#oreg_url=10.1.236.77:5000/openshift/origin-${component}:${version}#openshift_examples_modify_imagestreams=true# docker config#openshift_docker_additional_registries=10.1.236.77:5000#openshift_docker_insecure_registries=10.1.236.77:5000#openshift_docker_blocked_registriesopenshift_docker_options=&quot;--log-driver json-file --log-opt max-size=1M --log-opt max-file=3&quot;# openshift_cluster_monitoring_operator_install=false# openshift_metrics_install_metrics=true# openshift_enable_unsupported_configurations=True#openshift_logging_es_nodeselector=&apos;node-role.kubernetes.io/infra: &quot;true&quot;&apos;#openshift_logging_kibana_nodeselector=&apos;node-role.kubernetes.io/infra: &quot;true&quot;&apos;# host group for masters[masters]openshift1# host group for etcd[etcd]openshift1# host group for nodes, includes region info[nodes]openshift1 openshift_node_group_name=&apos;node-config-master&apos;openshift2 openshift_node_group_name=&apos;node-config-compute&apos;openshift3 openshift_node_group_name=&apos;node-config-compute&apos;openshift2  openshift_node_group_name=&apos;node-config-infra&apos;</code></pre><h4 id="DNS-配置下发"><a href="#DNS-配置下发" class="headerlink" title="DNS 配置下发"></a>DNS 配置下发</h4><pre><code>ansible all -m copy -a &quot;src=/etc/hosts dest=/etc/hosts &quot;</code></pre><h3 id="启动docker"><a href="#启动docker" class="headerlink" title="启动docker"></a>启动docker</h3><pre><code>ansible all -a &apos;systemctl start docker&apos;;ansible all -a &apos;systemctl enable docker&apos;</code></pre><h3 id="执行安装检查"><a href="#执行安装检查" class="headerlink" title="执行安装检查"></a>执行安装检查</h3><pre><code>ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/prerequisites.yml</code></pre><h3 id="执行安装"><a href="#执行安装" class="headerlink" title="执行安装"></a>执行安装</h3><pre><code>ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/deploy_cluster.yml -vvv</code></pre><h3 id="安装完成"><a href="#安装完成" class="headerlink" title="安装完成"></a>安装完成</h3><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/openshift1.jpg?raw=true"  alt></p><h4 id="创建用户名和密码"><a href="#创建用户名和密码" class="headerlink" title="创建用户名和密码"></a>创建用户名和密码</h4><pre><code>htpasswd -cb /etc/origin/master/htpasswd admin abc123oc adm policy add-cluster-role-to-user cluster-admin admin</code></pre><p>进入openshift WEB主页面：<a href="https://openshift1:8443" target="_blank" rel="external nofollow noopener noreferrer">https://openshift1:8443</a></p><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/openshift2.jpg?raw=true"  alt></p><p><strong>username:admin</strong></p><p><strong>password: abc123</strong></p><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/openshift3.jpg?raw=true"  alt></p><p><strong>博客著作权归本作者所有，任何形式的转载都请联系作者获得授权并注明出处。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 大数据 </tag>
            
            <tag> Docker </tag>
            
            <tag> Openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SSO基础概念介绍</title>
      <link href="/2019-08-01-SSO/"/>
      <url>/2019-08-01-SSO/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="SSO-Single-Sign-On"><a href="#SSO-Single-Sign-On" class="headerlink" title="SSO (Single Sign On)"></a>SSO (Single Sign On)</h1><p><strong>单点登录(SingleSignOn，SSO)</strong>，就是通过用户的一次性鉴别登录。当用户在身份认证服务器上登录一次以后，即可获得访问单点登录系统中其他联邦系统和应用软件的权限，同时这种实现是不需要管理员对用户的登录状态或其他信息进行修改的，这意味着在多个应用系统中，用户只需一次登录就可以访问所有相互信任的应用系统。这种方式减少了由登录产生的时间消耗，辅助了用户管理，是目前比较流行的。</p><h2 id="SSO应用场景"><a href="#SSO应用场景" class="headerlink" title="SSO应用场景"></a>SSO应用场景</h2><p>对于大型系统来说使用单点登录可以减少用户很多的麻烦。就拿百度来说吧，百度下面有很多的子系统——百度经验、百度知道、百度文库等等，如果我们使用这些系统的时候，每一个系统都需要我们输入用户名和密码登录一次的话，我相信用户体验肯定会直线下降。当然，对于个人博客这类系统来说根本就用不上单点登录了。</p><p>假如，我们的系统很庞大，但是就是这一个系统，并没有什么子系统。这时我们也不需要单点登录。我们需要的是搭建集群环境，这里虽说只有一个系统，但是很多台节点负载均衡的话就涉及到session共享的问题了。Session共享问题较之于SSO来说将比较容易解决了。</p><h2 id="单点登录和非单点登录系统示意图"><a href="#单点登录和非单点登录系统示意图" class="headerlink" title="单点登录和非单点登录系统示意图"></a>单点登录和非单点登录系统示意图</h2><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/sso1.jpg?raw=true"  alt></p><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/sso2.jpg?raw=true"  alt></p><h1 id="未完待续……"><a href="#未完待续……" class="headerlink" title="未完待续……"></a>未完待续……</h1><p><strong>博客著作权归本作者所有，任何形式的转载都请联系作者获得授权并注明出处。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 大数据 </tag>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LDAP(二)之安装部署</title>
      <link href="/2019-07-30-LDAP(%E4%BA%8C)/"/>
      <url>/2019-07-30-LDAP(%E4%BA%8C)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Docker安装LDAP"><a href="#Docker安装LDAP" class="headerlink" title="Docker安装LDAP"></a>Docker安装LDAP</h1><pre><code>安装LDAP分Server端和Client端两部分的安装部署Server端参考地址： https://github.com/osixia/docker-openldapClient端参考地址： https://github.com/osixia/docker-phpLDAPadmin</code></pre><hr><h2 id="Server端OpenLDAP安装"><a href="#Server端OpenLDAP安装" class="headerlink" title="Server端OpenLDAP安装"></a>Server端OpenLDAP安装</h2><p><strong>拉取镜像</strong></p><pre><code>docker pull osixia/openldap:1.2.4</code></pre><p><strong>运行镜像</strong></p><pre><code>docker run -p 389:389 -p 636:636 --name my-openldap-container --detach osixia/openldap:1.2.4</code></pre><p>本命令是ldap会默认创建一个admin用户，默认密码也是admin.<br>也通过环境变量设置 LDAP 服务器的参数：</p><pre><code>LDAP_ORGANISATION: Organisation name. Defaults to Example Inc.LDAP_DOMAIN: Ldap domain. Defaults to example.orgLDAP_BASE_DN: Ldap base DN. If empty automatically set from LDAP_DOMAIN value. Defaults to (empty)LDAP_ADMIN_PASSWORD Ldap Admin password. Defaults to adminLDAP_CONFIG_PASSWORD Ldap Config password. Defaults to configLDAP_READONLY_USER Add a read only user. Defaults to falseLDAP_READONLY_USER_USERNAME Read only user username. Defaults to readonlyLDAP_READONLY_USER_PASSWORD Read only user password. Defaults to readonlyLDAP_RFC2307BIS_SCHEMA Use rfc2307bis schema instead of nis schema. Defaults to false</code></pre><p>例子：</p><pre><code>docker run --env LDAP_ORGANISATION=&quot;My Company&quot; --env LDAP_DOMAIN=&quot;my-company.com&quot; \--env LDAP_ADMIN_PASSWORD=&quot;JonSn0w&quot; --detach osixia/openldap:1.2.4</code></pre><p><strong>LDAP查询命令</strong></p><p> 通过<strong>ldapsearch</strong>，<strong>ldapadd</strong>，<strong>ldapdelete</strong>，<strong>ldapmodify</strong>等参数查询、新增、删除、修改内容信息。如下所示命令是对ldap进行一次查询</p><pre><code>docker exec my-openldap-container ldapsearch -x -H ldap://localhost -b dc=example,dc=org -D &quot;cn=admin,dc=example,dc=org&quot; -w admin</code></pre><p>正常输出结果如下所示：</p><pre><code># extended LDIF## LDAPv3# base &lt;dc=example,dc=org&gt; with scope subtree# filter: (objectclass=*)# requesting: ALL## example.orgdn: dc=example,dc=orgobjectClass: topobjectClass: dcObjectobjectClass: organizationo: Example Inc.dc: example# admin, example.orgdn: cn=admin,dc=example,dc=orgobjectClass: simpleSecurityObjectobjectClass: organizationalRolecn: admindescription: LDAP administratoruserPassword:: e1NTSEF9Q3BkSlF6UUtzUjlOa29waktxWmdrNHBsdVZSMExWUE4=# search resultsearch: 2result: 0 Success# numResponses: 3# numEntries: 2</code></pre><p><strong>数据文件和配置文件外置安装方式介绍</strong></p><ul><li><p>在主机上进行分区，笔者分了2G的逻辑分区出来:</p><pre><code>命令使用 fdisk /dev/sda2...省略分区步骤最后格式化分区mkfs.ext4 /dev/XXXX</code></pre></li><li><p>挂载分区：</p><pre><code>1. 创建目录如下：/data/ldap/database//data/ldap/config/slapd.d/data/ldap/conffileldapdata目录保存数据slapd.d目录保存配置conffileldap目录用来与容器交换文件2.执行挂载mount /dev/XXXX /data</code></pre></li><li><p>运行镜像：</p><pre><code>docker run -p 389:389 -p 636:636 \--name my-openldap-container \--volume /data/ldap/database:/var/lib/ldap \--volume /data/ldap/config/slapd.d:/etc/ldap/slapd.d \--volume /data/ldap/conffileldap/:/home/ldap/conffile \--detach osixia/openldap:1.2.4</code></pre></li><li><p>问题：</p><p>  容器中没有执行权限 //挂载外部数据卷时,无法启动容器, 报 chown: cannot read directory ‘/var/lib/mysql/‘: Permission denied<br>  该原因为centOs7默认开启selinux安全模块,需要临时关闭该安全模块,或者添加目录到白名单</p><p>  <strong>解决方案：</strong></p><p>  将要挂载的目录添加到白名单： 示例：chcon -Rt svirt_sandbox_file_t   /data/mysql/db/</p></li></ul><h2 id="Client端PHPLdapAdmin安装"><a href="#Client端PHPLdapAdmin安装" class="headerlink" title="Client端PHPLdapAdmin安装"></a>Client端PHPLdapAdmin安装</h2><p><strong>拉取镜像</strong></p><pre><code>docker pull osixia/phpldapadmin:0.8.0</code></pre><p><strong>运行镜像</strong></p><pre><code>docker run -p 8888:443 \        --env PHPLDAPADMIN_LDAP_HOSTS=192.168.2.138 \        --detach osixia/phpldapadmin:0.8.0</code></pre><p><strong>客户端界面</strong></p><p>安装成功后输入<a href="https://ip:8888" target="_blank" rel="external nofollow noopener noreferrer">https://ip:8888</a> 进入页面如下图所示：</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/ldap3.jpg?raw=true"  alt></p><p><strong>登录成功后界面</strong></p><p>LogingDN(默认):</p><pre><code>cn=admin,dc=example,dc=org</code></pre><p>Password(默认):</p><pre><code>admin</code></pre><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/ldap4.jpg?raw=true"  alt></p><p><strong>问题</strong></p><p>可能会出现连接LDAP服务端失败或者用户名密码错误。</p><p><strong>解决方案</strong></p><p>由于LDAP Server访问是389端口号，需要将389端口加入到防火墙白名单里面。执行如下命名：</p><pre><code>cp /etc/sysconfig/iptables /etc/sysconfig/iptables.bak.$(date &quot;+%Y%m%d%H%M%S&quot;);sed -i &apos;/.*--dport 22 -j ACCEPT.*/a\-A INPUT -p tcp -m state --state NEW -m tcp --dport 389 -j ACCEPT&apos; /etc/sysconfig/iptables;systemctl restart iptables;systemctl enable iptables</code></pre><p><strong>博客著作权归本作者所有，任何形式的转载都请联系作者获得授权并注明出处。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 大数据 </tag>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LDAP(一)之概念原理介绍</title>
      <link href="/2019-07-29-LDAP(%E4%B8%80)/"/>
      <url>/2019-07-29-LDAP(%E4%B8%80)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-基础知识铺垫"><a href="#1-基础知识铺垫" class="headerlink" title="1. 基础知识铺垫"></a>1. 基础知识铺垫</h1><h2 id="1-1-什么是目录？"><a href="#1-1-什么是目录？" class="headerlink" title="1.1 什么是目录？"></a>1.1 什么是目录？</h2><ul><li><strong>(1)</strong> 目录是一类为了浏览和搜索数据二十几的特殊的数据库，例如：最知名的的微软公司的活动目录（active directory）就是目录数据库的一种。目录服务时按照梳妆形式存储信息的，目录包含基于属性的描述性信息，并且支持高级的过滤功能。</li><li><strong>(2)</strong> 一般来说，目录不支持大多数事务性数据库所支持的高吞吐两盒复杂的更新操作。目录进行更新操作，可以说是要么全部，要么都不的原子操作，目录服务适合的业务应用在于提供大量的查询和搜索操作。</li><li><strong>(3)</strong> 为了保证目录数据的可用性和卡可靠性，她们在确保提供快速的查询和搜索操作的同事，还提供了主从服务器同步目录数据信息的能力，这相当于传统的Mysql数据库的主从同步一样，可以最大限度的确保基于目录业务的持续可用性。</li><li><strong>(4)</strong> 广义的目录服务概念，可以有多重不同的方式来提供目录服务，不同的目录所允许存储的信息是不同的，在信息如何被引用，查询，更新以及防止未经守群的访问等问题上，不同的目录所允许存储的信息是不同的，在信息如何被引用，查询，更新以及防止未经授权的访问等问题上，不同的目录的处理方式也有诸多的不同。一些目录服务时为本地的，只提供受限的服务，（比如，单机上的finger服务）。另一些服务时大范围的（global），提供广阔得多的服务（比如面向整个因特网）。大范围的服务通常是分布式的，这也就意味着数据是分布在多台机器上的，这些计数器一起来提供目录服务。典型的大范围服务定义一个统一的名称空间（namespace）来给出一个相同的数据试图（data view），而不管你相对于数据所在的位置。DNS是一个典型的大范围分布式目录服务的例子</li></ul><h2 id="1-2-什么是X-500？"><a href="#1-2-什么是X-500？" class="headerlink" title="1.2. 什么是X.500？"></a>1.2. 什么是X.500？</h2><ul><li>X.500由ITU-T和ISO定义，它实际上不是一个协议，而是有一个协议族组成，包括了从X.501到X.525等一系列非常完整的目录服务协议。</li></ul><h1 id="2-LADP介绍"><a href="#2-LADP介绍" class="headerlink" title="2. LADP介绍"></a>2. LADP介绍</h1><p>##2.1  什么是LDAP？</p><ul><li><strong>(1)</strong> <strong>LDAP</strong>是Lightweight Directory Access Protocol (轻量级目录访问协议)的缩写。正如它的名字所表明的那样，它是一个轻量级的目录访问协议，特质基于X.500的目录访问协议的简化版本。LADP运行在TCP/IP或者其他的面向连接的传输服务至上。LADP完整的技术规范由RFC2251 “The Lightweight Directory Access Protocol（V3）”和其他几个在RFC3377中定义的文档组成。</li><li><strong>(2)</strong> 目录是一个为查询、浏览和搜索而优化的数据库，它成树状结构组织数据，类似文件目录一样。</li><li><strong>(3)</strong> 目录数据库和关系数据库不同，它有优异的读性能，但写性能差，并且没有事务处理、回滚等复杂功能，不适于存储修改频繁的数据。所以目录天生是用来查询的，就好象它的名字一样。</li></ul><h2 id="2-2-LADP目录服务的特点"><a href="#2-2-LADP目录服务的特点" class="headerlink" title="2.2 LADP目录服务的特点"></a>2.2 LADP目录服务的特点</h2><h3 id="2-2-1-LDAP目录服务具有下列特点"><a href="#2-2-1-LDAP目录服务具有下列特点" class="headerlink" title="2.2.1 LDAP目录服务具有下列特点"></a>2.2.1 LDAP目录服务具有下列特点</h3><ul><li>LDAP是一个跨平台的，标准的协议，近几年来得到了业界广泛的认可；</li><li>LADP的结构用树形结构来表示，而不是用表格。因此不用SQL语句维护了；</li><li>LADP提供了静态数据的快速查询方式，但在写数据方面并不擅长；</li><li>LADP服务可以使用基于“推或”拉”的复制信息技术，用简单的活基于安全证书的安全认证，复制部分或全部数据，既保证了数据的安全性，又提高了数据的访问效率；</li><li>LDAP是一个安全的协议，LDAP v3支持SASL（Simple Authentication and Securityh Layer）,SSL（Secure Socket Layer）和TLS（Transport Layer Security），使用认证来确保事物的安全，另外，LDAP提供了不同层次的访问控制，以限制不同用户的访问权限；</li><li>LADP支持一类数据存储，LADP存储的数据可由是文本资料，二进制图片等；</li><li>Client/Server模型：Server用于存储树，Client提供操作目录信息数的工具，这些工具可以将数据库的内容以文本格式（LDAP数据交换格式，LDIF）呈现在我们的面前；</li><li>LDAP是一种开放Internet标准，LADP协议时跨平台的Internt协议，它是基于X.500标准的，与X.500不同，LADY支持TCP/IP（即可以分不知部署）</li></ul><h2 id="3-LDAP是怎样工作的？"><a href="#3-LDAP是怎样工作的？" class="headerlink" title="3. LDAP是怎样工作的？"></a>3. LDAP是怎样工作的？</h2><p>LDAP目录服务器是基于客户/服务器模式的。一个或者多个LDAP服务器包含着组成整个目录信息树（DIT）的数据。客户连接到服务器并且并发一个请求（request）。然后服务器要么以一个回答（answer）予以回应，要么给出一个指针，客户可以通过此指针获取到所需的数据（通常，该指针是指向另一个LDAP服务器）。无论客户连到哪个LDAP服务器，它看到的都是同一个目录视图（view）。这是LDAP这类全局目录服务的一个重要特征。</p><h2 id="4-LADP目录信息模型"><a href="#4-LADP目录信息模型" class="headerlink" title="4. LADP目录信息模型"></a>4. LADP目录信息模型</h2><h3 id="4-1-什么样的信息可以存储在目录当中？"><a href="#4-1-什么样的信息可以存储在目录当中？" class="headerlink" title="4.1 什么样的信息可以存储在目录当中？"></a>4.1 什么样的信息可以存储在目录当中？</h3><p>条目和属性的关系：</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/LDAP1.jpg?raw=true"  alt></p><p>LDAP的信息模型是基于条目的（entry）。一个条目就是一些具有全局唯一的标识名（Distinguished Name,简写做DN）的属性的集合。DN用于无二义性的纸袋一个唯一的条目。条目的每一个属性都有一个类型（type），一个或者多个值（value）。类型往往是特定字符串的简写，比如用“cn”指代“common name”，或是”mail”指代电子邮件地址。值（value）的语法依赖于类型（type）。比如，类型为cn的属性可能包含值”候剑豪”。类型为mail的属性可能包含值“<a href="mailto:frederick_hou@163.com" rel="external nofollow noopener noreferrer" target="_blank">frederick_hou@163.com</a>”。类型为jpeg Photo的属性可能包含二进制格式的JPEG图像。</p><h3 id="4-2-信息在目录中是如何组织的？"><a href="#4-2-信息在目录中是如何组织的？" class="headerlink" title="4.2 信息在目录中是如何组织的？"></a>4.2 信息在目录中是如何组织的？</h3><p>在LDAP中，条目是按树状的层次结构组织的。传统上，这个机构旺旺是代理界限或组织界限的反应。代表国家的条目位与整个目录树的顶层。之下的条目则代表各个州以及国家性的组织。在下面的条目则代表着组织单位，个人，打印机，文件，或者你所能想到的其他的东西。目录是也可以按照因特网域名组织结构，因为它允许按照DNS对目录服务进行定时，这种命名方式正变得越来越受欢迎。下图是按照域名进行组织的一个LADP目录树，相比传统的命名方式更加让用户易于接受。另外，LDAP允许你通过使用一种叫做objectClass的特殊属性来控制哪些属性是条目所必须的，哪些属性是条目可选的。objectClass属性的值是由条目所必须遵守的方案（schema）来定义的。</p><h3 id="4-3-信息是如何被引用的？"><a href="#4-3-信息是如何被引用的？" class="headerlink" title="4.3 信息是如何被引用的？"></a>4.3 信息是如何被引用的？</h3><p>一个条目是通过它的标识名来引用的。而标识名（Relative DistinguishedName 或者RDN）是由标识名和它的父条目名连在一起构成的。</p><h3 id="4-4-信息是如何被访问的？"><a href="#4-4-信息是如何被访问的？" class="headerlink" title="4.4 信息是如何被访问的？"></a>4.4 信息是如何被访问的？</h3><p>LDAP定义了一个查询和更新目录的操作，支持的操作包括从目录中添加和删除条目，更改一游的条目，更改已有的的名字。然而，大多数情况下LDAP是用于搜索目录中的信息的。通过指定搜索过滤器，LDAP可以在目录的相关部分搜索想相符的条目。满足过滤条件的每一个条目都能收到请求消息。</p><h3 id="4-5-怎样保护信息不受未经授权的访问？"><a href="#4-5-怎样保护信息不受未经授权的访问？" class="headerlink" title="4.5 怎样保护信息不受未经授权的访问？"></a>4.5 怎样保护信息不受未经授权的访问？</h3><p>一些目录服务不提供保护，允许信息对任何人可见。LDAP提供了一套机制来对客户进行身份确认，或者让客户证明他拥有连接到服务器的身份，这无疑为对服务器进行全方位的访问控制铺平了道理，从而确保了服务器上所包含信息的安全。LDAP也支持privacy和integrity的安全服务。</p><p><strong>博客著作权归本作者所有，任何形式的转载都请联系作者获得授权并注明出处。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 大数据 </tag>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker仓库介绍以及私有仓库搭建</title>
      <link href="/2019-07-26-Docker/"/>
      <url>/2019-07-26-Docker/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="【Docker】之基于Harbor搭建私有镜像仓库"><a href="#【Docker】之基于Harbor搭建私有镜像仓库" class="headerlink" title="【Docker】之基于Harbor搭建私有镜像仓库"></a>【Docker】之基于Harbor搭建私有镜像仓库</h1><hr><h2 id="1-Docker仓库介绍"><a href="#1-Docker仓库介绍" class="headerlink" title="1. Docker仓库介绍"></a>1. Docker仓库介绍</h2><p><strong>仓库</strong> 是集中存放镜像的地方。每个服务器上可以有多个仓库。<br>仓库又分为公有仓库（DockerHub、dockerpool）和私有仓库。<br><strong>DockerHub</strong>：docker官方维护的一个公共仓库<a href="https://hub.docker.com，其中包括了15000多个的镜像，大部分都可以通过dockerhub直接下载镜像。也可通过docker" target="_blank" rel="external nofollow noopener noreferrer">https://hub.docker.com，其中包括了15000多个的镜像，大部分都可以通过dockerhub直接下载镜像。也可通过docker</a> search和docker pull命令来下载。<br><strong>DockerPool</strong>：国内专业的docker技术社区，<a href="http://www.dockerpool.com也提供官方镜像的下载。" target="_blank" rel="external nofollow noopener noreferrer">http://www.dockerpool.com也提供官方镜像的下载。</a></p><h2 id="2-Harbor介绍-私有仓库服务器"><a href="#2-Harbor介绍-私有仓库服务器" class="headerlink" title="2. Harbor介绍(私有仓库服务器)"></a>2. Harbor介绍(私有仓库服务器)</h2><p><strong>Harbor</strong>，是一个英文单词，意思是港湾，港湾是干什么的呢，就是停放货物的，而货物呢，是装在集装箱中的，说到集装箱，就不得不提到Docker容器，因为docker容器的技术正是借鉴了集装箱的原理。所以，Harbor正是一个用于存储Docker镜像的企业级Registry服务。它是由VMware公司开发的企业级Registry项目Harbor，其的目标是帮助用户迅速搭建一个企业级的Docker registry 服务。它以Docker公司开源的registry 为基础，提供了管理UI, 基于角色的访问控制(RoleBased Access Control)，AD/LDAP集成、以及审计日志(Auditlogging) 等企业用户需求的功能，同时还原生支持中文，对广大中国用户是一个好消息。</p><h3 id="2-1-Harbor核心组件解释"><a href="#2-1-Harbor核心组件解释" class="headerlink" title="2.1 Harbor核心组件解释"></a>2.1 Harbor核心组件解释</h3><ul><li><strong>Proxy</strong>：他是一个nginx的前端代理，代理Harbor的registry,UI, token等服务。</li><li><strong>db</strong>：负责储存用户权限、审计日志、Dockerimage分组信息等数据。</li><li><strong>UI</strong>：提供图形化界面，帮助用户管理registry上的镜像, 并对用户进行授权。</li><li><strong>jobsevice</strong>：jobsevice是负责镜像复制工作的，他和registry通信，从一个registry pull镜像然后push到另一个registry，并记录job_log。</li><li><strong>Adminserver</strong>：是系统的配置管理中心附带检查存储用量，ui和jobserver启动时候回需要加载adminserver的配置。</li><li><strong>Registry</strong>：镜像仓库，负责存储镜像文件。</li><li><strong>Log</strong>：为了帮助监控Harbor运行，负责收集其他组件的log，供日后进行分析。</li></ul><h3 id="3-主机搭建环境"><a href="#3-主机搭建环境" class="headerlink" title="3. 主机搭建环境"></a>3. 主机搭建环境</h3><pre><code>LSB Version:    :core-4.1-amd64:core-4.1-noarchDistributor ID: CentOSDescription:    CentOS Linux release 7.4.1708 (Core)Release:        7.4.1708Codename:       Core</code></pre><h3 id="4-搭建步骤"><a href="#4-搭建步骤" class="headerlink" title="4. 搭建步骤"></a>4. 搭建步骤</h3><h4 id="4-1-下载harbor离线包"><a href="#4-1-下载harbor离线包" class="headerlink" title="4.1 下载harbor离线包"></a>4.1 下载harbor离线包</h4><p>先下载docker安装包并且下载 harbor对应1.17.0+以上版本的docker-compose</p><pre><code>curl -L https://github.com/docker/compose/releases/download/1.17.1/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-compose</code></pre><p>首先我们需要在github上搜索harbor下载地址。下载地址：<a href="https://github.com/goharbor/harbor/releases" target="_blank" rel="external nofollow noopener noreferrer">https://github.com/goharbor/harbor/releases</a><br>笔者选择的V1.7.0版本进行安装</p><pre><code>wget https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-offline-installer-v1.7.1.tgztar zxvf harbor-offline-installer-v1.7.1.tgz</code></pre><p>解压tar包后目录结构</p><pre><code>common                          docker-compose.clair.yml   docker-compose.yml  harbor.v1.7.1.tar.gz  LICENSE              preparedocker-compose.chartmuseum.yml  docker-compose.notary.yml  harbor.cfg          install.sh            open_source_license</code></pre><p>笔者修改的harbor.cfg文件内容如下，具体hostname和passwd根据自己的具体情况更改。</p><pre><code>hostname = harbor.comharbor_admin_password = 12345</code></pre><p>接下来进行harbor安装具体安装信息如下：</p><pre><code>./install.sh [Step 0]: checking installation environment ...Note: docker version: 1.13.1Note: docker-compose version: 1.17.1[Step 1]: loading Harbor images ...ae18db924eef: Loading layer [==================================================&gt;] 32.92 MB/32.92 MB1c06074dba9c: Loading layer [==================================================&gt;] 8.955 MB/8.955 MB7a719a639e34: Loading layer [==================================================&gt;] 3.072 kB/3.072 kB49f7bca05da9: Loading layer [==================================================&gt;]  2.56 kB/2.56 kBe86d69bef97e: Loading layer [==================================================&gt;]  2.56 kB/2.56 kB81e122d773f5: Loading layer [==================================================&gt;] 2.048 kB/2.048 kB5fe5adb8cf31: Loading layer [==================================================&gt;]  22.8 MB/22.8 MBd760045419e4: Loading layer [==================================================&gt;]  22.8 MB/22.8 MBLoaded image: goharbor/registry-photon:v2.6.2-v1.7.1c0f668a21621: Loading layer [==================================================&gt;] 133.2 MB/133.2 MBf8cb0bf39ff2: Loading layer [==================================================&gt;]   684 MB/684 MB444ac38a117b: Loading layer [==================================================&gt;]  7.68 kB/7.68 kB2e16f24ac8bc: Loading layer [==================================================&gt;]   212 kB/212 kBLoaded image: goharbor/harbor-migrator:v1.7.1fa2dcaba747a: Loading layer [==================================================&gt;] 8.955 MB/8.955 MBeeaaf4c760eb: Loading layer [==================================================&gt;]  15.6 MB/15.6 MB98ffd6175b61: Loading layer [==================================================&gt;] 18.94 kB/18.94 kBfc1db6c4f652: Loading layer [==================================================&gt;]  15.6 MB/15.6 MBLoaded image: goharbor/harbor-adminserver:v1.7.18d55a6a034d6: Loading layer [==================================================&gt;] 8.955 MB/8.955 MB01ef68a17913: Loading layer [==================================================&gt;] 27.24 MB/27.24 MBf9258cfa4b48: Loading layer [==================================================&gt;] 5.632 kB/5.632 kBdcf5c61ede76: Loading layer [==================================================&gt;] 27.24 MB/27.24 MBLoaded image: goharbor/harbor-core:v1.7.11f65d10893c9: Loading layer [==================================================&gt;] 50.39 MB/50.39 MB358f40be2091: Loading layer [==================================================&gt;] 3.584 kB/3.584 kBc7f3ef058d0b: Loading layer [==================================================&gt;] 3.072 kB/3.072 kB154caf7c7173: Loading layer [==================================================&gt;] 4.096 kB/4.096 kB42c7764aa777: Loading layer [==================================================&gt;] 3.584 kB/3.584 kB023f3a96f324: Loading layer [==================================================&gt;] 10.24 kB/10.24 kBLoaded image: goharbor/harbor-log:v1.7.1a1b528067504: Loading layer [==================================================&gt;] 8.955 MB/8.955 MB2d3d34f3ba5b: Loading layer [==================================================&gt;] 21.51 MB/21.51 MBa5da70777097: Loading layer [==================================================&gt;] 21.51 MB/21.51 MBLoaded image: goharbor/harbor-jobservice:v1.7.1ab31dfc84e9d: Loading layer [==================================================&gt;] 8.954 MB/8.954 MBb130423af762: Loading layer [==================================================&gt;] 13.43 MB/13.43 MB357c059d0598: Loading layer [==================================================&gt;]  17.3 MB/17.3 MBfabc6edfac55: Loading layer [==================================================&gt;] 11.26 kB/11.26 kBcfaa3b5d445a: Loading layer [==================================================&gt;] 3.072 kB/3.072 kB12c73a4b2c7a: Loading layer [==================================================&gt;] 30.72 MB/30.72 MBLoaded image: goharbor/notary-server-photon:v0.6.1-v1.7.150a6467bd619: Loading layer [==================================================&gt;]   113 MB/113 MB6ae61fc91943: Loading layer [==================================================&gt;] 11.46 MB/11.46 MB5c840c272f78: Loading layer [==================================================&gt;] 2.048 kB/2.048 kB077d16ebcba8: Loading layer [==================================================&gt;] 48.13 kB/48.13 kBb822f5ff7858: Loading layer [==================================================&gt;] 3.072 kB/3.072 kB4548140152fd: Loading layer [==================================================&gt;] 11.51 MB/11.51 MBLoaded image: goharbor/clair-photon:v2.0.7-v1.7.1232024be30e3: Loading layer [==================================================&gt;]  3.39 MB/3.39 MBa73624ae3fad: Loading layer [==================================================&gt;] 4.721 MB/4.721 MB96b8c5c532c3: Loading layer [==================================================&gt;] 3.584 kB/3.584 kBLoaded image: goharbor/harbor-portal:v1.7.1e2fd12afe6e8: Loading layer [==================================================&gt;] 63.31 MB/63.31 MBe973513bcb58: Loading layer [==================================================&gt;] 40.74 MB/40.74 MB4f45af643b2b: Loading layer [==================================================&gt;] 6.656 kB/6.656 kB54a84094f024: Loading layer [==================================================&gt;] 2.048 kB/2.048 kB2d78cf8a687b: Loading layer [==================================================&gt;]  7.68 kB/7.68 kBe96067b83a72: Loading layer [==================================================&gt;]  2.56 kB/2.56 kB38a7d304147f: Loading layer [==================================================&gt;]  2.56 kB/2.56 kBa36c0cb6a35a: Loading layer [==================================================&gt;]  2.56 kB/2.56 kBLoaded image: goharbor/harbor-db:v1.7.1b0c31ad64c85: Loading layer [==================================================&gt;] 65.01 MB/65.01 MB22fbab41769e: Loading layer [==================================================&gt;] 3.072 kB/3.072 kB7f28bf5373b2: Loading layer [==================================================&gt;]  59.9 kB/59.9 kBabb9969cff2a: Loading layer [==================================================&gt;] 61.95 kB/61.95 kBLoaded image: goharbor/redis-photon:v1.7.1933cd9a15fc5: Loading layer [==================================================&gt;]  3.39 MB/3.39 MBLoaded image: goharbor/nginx-photon:v1.7.16ee16a137af2: Loading layer [==================================================&gt;] 8.955 MB/8.955 MB954443cb7d20: Loading layer [==================================================&gt;]  22.8 MB/22.8 MB302a998137db: Loading layer [==================================================&gt;] 3.072 kB/3.072 kBe342723aef9b: Loading layer [==================================================&gt;] 7.465 MB/7.465 MB4eeb61ed730b: Loading layer [==================================================&gt;] 30.26 MB/30.26 MBLoaded image: goharbor/harbor-registryctl:v1.7.15b40d957fafd: Loading layer [==================================================&gt;] 12.11 MB/12.11 MB63489681dd6c: Loading layer [==================================================&gt;]  17.3 MB/17.3 MB696209dcd336: Loading layer [==================================================&gt;] 11.26 kB/11.26 kB8dc53997aa1f: Loading layer [==================================================&gt;] 3.072 kB/3.072 kBcb6d560a9958: Loading layer [==================================================&gt;] 29.41 MB/29.41 MBLoaded image: goharbor/notary-signer-photon:v0.6.1-v1.7.1dc1e16790c89: Loading layer [==================================================&gt;]  8.96 MB/8.96 MB046c7e7a0100: Loading layer [==================================================&gt;] 35.08 MB/35.08 MB8c8428e3d6c6: Loading layer [==================================================&gt;] 2.048 kB/2.048 kBebb477ee35a2: Loading layer [==================================================&gt;] 3.072 kB/3.072 kB19636f39e29d: Loading layer [==================================================&gt;] 35.08 MB/35.08 MBLoaded image: goharbor/chartmuseum-photon:v0.7.1-v1.7.1[Step 2]: preparing environment ...Generated and saved secret to file: /data/secretkeyGenerated configuration file: ./common/config/nginx/nginx.confGenerated configuration file: ./common/config/adminserver/envGenerated configuration file: ./common/config/core/envGenerated configuration file: ./common/config/registry/config.ymlGenerated configuration file: ./common/config/db/envGenerated configuration file: ./common/config/jobservice/envGenerated configuration file: ./common/config/jobservice/config.ymlGenerated configuration file: ./common/config/log/logrotate.confGenerated configuration file: ./common/config/registryctl/envGenerated configuration file: ./common/config/core/app.confGenerated certificate, key file: ./common/config/core/private_key.pem, cert file: ./common/config/registry/root.crtThe configuration files are ready, please use docker-compose to start the service.[Step 3]: checking existing instance of Harbor ...[Step 4]: starting Harbor ...Creating network &quot;harbor_harbor&quot; with the default driverCreating harbor-log ... Creating harbor-log ... doneCreating harbor-db ... Creating redis ... Creating harbor-dbCreating registry ... Creating redisCreating registryctl ... Creating harbor-adminserver ... Creating registryCreating harbor-adminserverCreating harbor-adminserver ... doneCreating registryctl ... doneCreating harbor-core ... doneCreating harbor-portal ... Creating harbor-jobservice ... Creating harbor-portalCreating harbor-portal ... doneCreating nginx ... Creating nginx ... done✔ ----Harbor has been installed and started successfully.----Now you should be able to visit the admin portal at http://harbor.com. For more details, please visit https://github.com/goharbor/harbor .</code></pre><h1 id="未完待续……"><a href="#未完待续……" class="headerlink" title="未完待续……"></a>未完待续……</h1><p><strong>博客著作权归本作者所有，任何形式的转载都请联系作者获得授权并注明出处。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 大数据 </tag>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>让数据驱动增长</title>
      <link href="/2019-05-31-%E8%AE%A9%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E5%A2%9E%E9%95%BF/"/>
      <url>/2019-05-31-%E8%AE%A9%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E5%A2%9E%E9%95%BF/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">一本好书会帮我们指明前进道路的方向，激发我们的好奇，</span><br><span class="line">让我们开始思考。但是前进的路还是要我们自己走。</span><br></pre></td></tr></table></figure><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/hacker.jpg?raw=true"  alt></p><h1 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h1><p>前段时间由于同事们一直在讨论《增长黑客》这本书，在当前大数据时代背景下，数据驱动业务增长是产品被用户所接受的直接反馈。作为 一名开发人员不仅只眼观于业务实现和技术研究，同时也应该有产品设计和商业思维。</p><h1 id="书籍介绍"><a href="#书籍介绍" class="headerlink" title="书籍介绍"></a>书籍介绍</h1><p>该书的作者是肖恩·埃利斯&amp;摩根·布朗(Sean Ellis&amp;Morgan Brown)，主要讲的就是需求验证后，如何获客、激活、留存、变现和推广的方法。随着互联网红利的减少，用户时间的碎片化以及资本投资的理性化趋势，企业单位的运营成本也在不断的呈指数型增长。这本书告诉我们的就是如何利用数据在有限的资源内获得最大限度的用户增长。</p><h1 id="书籍重点摘要"><a href="#书籍重点摘要" class="headerlink" title="书籍重点摘要"></a>书籍重点摘要</h1><ul><li><h2 id="增长前提"><a href="#增长前提" class="headerlink" title="增长前提"></a>增长前提</h2></li></ul><p>好产品是用户增长的根本。即在做用户增长之前，先确定产品是否为“不可或缺”受目标用户之喜爱。否则过早地追求增长会使大量的人力财力物力浪费在错误的事情上，推广一个不受欢迎的产品，不但不会使早期客户转换为忠实粉丝，反而会令他们失望，甚至变成愤怒的批判者传播负面性的口碑。<br>产品早期先从一小部分用户群直接/间接获取反馈，以最小化可行性产品验证需求，将反馈快速迭代，融合到新产品中。</p><ul><li><h2 id="认知数据"><a href="#认知数据" class="headerlink" title="认知数据"></a>认知数据</h2></li></ul><p>用户增长的一切工作都是建立在数据分析的指导之上，需要具有数据思维，没有数据就没有比较，没有比较就没有进步。通过数据定量和定性的分析，提出假设、设计方案、分析数据、验证或者是推翻假设，最终抽丝剥茧，逐渐接近真相。<br>不断的去认知挖掘数据的价值；掌握数据驱动的体系和方法；运用数据指导各个业务部门的运营；利用分析工具代替人力。</p><ul><li><h2 id="专注目标"><a href="#专注目标" class="headerlink" title="专注目标"></a>专注目标</h2></li></ul><p>用户增长的工作必须时刻围绕增长展开，确定增长愿景或目标，每个目标需要制定明确的投资策略和验收指标。但有时通往目标的道路处于一团迷雾之中，并没有现成的套路和方法可以直接借鉴，需经历不断地测试、改进、学习、再测试，要求相当强的毅力和抗压能力快速执行。</p><ul><li><h2 id="关注细节"><a href="#关注细节" class="headerlink" title="关注细节"></a>关注细节</h2></li></ul><p>对产品任何一处细微的改动都有可能影响到用户增长。通常 A/B测试 是检验产品细节最有效的方式之一。</p><ul><li><h2 id="善于创新"><a href="#善于创新" class="headerlink" title="善于创新"></a>善于创新</h2></li></ul><p>用户增长本身就是一门艺术，我们不但要通过缜密的分析衡量自己的想法是否可行，也要天马行空提出解决问题的方案构想(通常指头脑风暴)。</p><ul><li><h2 id="全方面探索"><a href="#全方面探索" class="headerlink" title="全方面探索"></a>全方面探索</h2></li></ul><p>用户增长既要了解自己的产品用户活跃渠道，建立环环相扣的转化漏洞；还要目光长远审时度势时刻掌握海内外最新产品和市场动向，横向掌握产品的数据，纵向挖掘上下游生态链接情况。<br>一句话：既要低头走路，又要抬头望天</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这本书有大量的具体执行案例非常值得我们反复阅读，对各种情况都提出了增长建议。AB测试，病毒式传播等等都是实现产品增长的经典手段。</p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++ 虚函数表、虚函数讲解</title>
      <link href="/2019-05-06-C++%E8%99%9A%E8%A1%A8%E3%80%81%E8%99%9A%E5%87%BD%E6%95%B0%E3%80%81%E8%99%9A%E6%8C%87%E9%92%88%E8%AE%B2%E8%A7%A3/"/>
      <url>/2019-05-06-C++%E8%99%9A%E8%A1%A8%E3%80%81%E8%99%9A%E5%87%BD%E6%95%B0%E3%80%81%E8%99%9A%E6%8C%87%E9%92%88%E8%AE%B2%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>近期有不少同学私信我询问关于C++ 虚表和虚函数的相关问题，于是就打算写一篇关于C++虚函数和虚表的原理文章有助于大家更好的去理解和学习。</p><hr><h1 id="虚函数"><a href="#虚函数" class="headerlink" title="虚函数"></a>虚函数</h1><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>虚函数是一种在基类中用virtual关键字声明的函数，并在一个或多个派生类中再定义的函数。虚函数的特点是，只要定义一个基类的指针，就可以指向派生类的对象。</p><p><strong>[注：无虚函数时，遵循以下规则：C++规定，定义为基类的指针，也能作指向派生类的指针使用，并可以用这个指向派生类对象的指针访问继承来的基类成员；但不能用它访问派生类的成员。]</strong></p><ul><li><p>使用虚函数实现运行时的多态性的关键在于：必须通过基类指针访问这些函数。</p></li><li><p>一旦一个函数定义为虚函数，无论它传下去多少层，一直保持为虚函数。</p></li><li><p>把虚函数的再定义称为过载（overriding）而不叫重载（overloading）。</p></li><li><p>纯虚函数：是定义在基类中的一种只给出函数原型，而没有任何与该基类有关的定义的函数。纯虚函数使得任何派生类都必须定义自己的函数版本。否则编译报错。纯虚函数定义的一般形式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">virtual type func_name(args)&#x3D;0;</span><br></pre></td></tr></table></figure></li><li><p>含有纯虚函数的基类称为抽象基类。抽象基类又一个重要特性：抽象类不能建立对象。但是抽象基类可以有指向自己的指针，以支持运行时的多态性。</p></li></ul><p><strong>虚函数示例代码</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">#include&quot;test.h&quot;</span><br><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Base&#123;</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line"></span><br><span class="line">    void printf()</span><br><span class="line">    &#123;</span><br><span class="line">        cout &lt;&lt; &quot;Base printf()&quot; &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    virtual void func()</span><br><span class="line">    &#123;</span><br><span class="line">        cout &lt;&lt; &quot;Base func()&quot; &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class Derived:public Base&#123;</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line"></span><br><span class="line">    void printf()</span><br><span class="line">    &#123;</span><br><span class="line">        cout &lt;&lt; &quot;Derived printf()&quot; &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    virtual void func()</span><br><span class="line">    &#123;</span><br><span class="line">        cout &lt;&lt; &quot;Derived func()&quot; &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>示例讲解</strong></p><p>在以上示例代码中，我们声明了一个父类 Base，和它的一个派生类 Derive，其中 printf() 实例方法是非虚函数，而func()方法被声明为了虚函数。并且在子类中我们重新实现了printf() 和 func()方法。下面我们分别构造出一个 Derive 实例和Base 实例，分别用示例对象访问各func()和printf()方法。然后构造新的Derived实例，并分别将其地址赋给 Base 指针和 Derived 指针，然后分别输出访问func()和printf()方法的结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    Base baseObj &#x3D; Base();</span><br><span class="line">    baseObj.func();</span><br><span class="line">    baseObj.printf();</span><br><span class="line">    Derived derivedObj &#x3D; Derived();</span><br><span class="line">    derivedObj.func();</span><br><span class="line">    derivedObj.printf();</span><br><span class="line"></span><br><span class="line">    Derived* pDerivedObj &#x3D; new Derived();</span><br><span class="line">    Base* pBaseObj &#x3D; pDerivedObj;</span><br><span class="line">    pDerivedObj-&gt;func();</span><br><span class="line">    pBaseObj-&gt;func();</span><br><span class="line">    pDerivedObj-&gt;printf();</span><br><span class="line">    pBaseObj-&gt;printf();</span><br><span class="line">    delete pDerivedObj;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>运行结果</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Terminal output result:</span><br><span class="line"></span><br><span class="line">Base func()</span><br><span class="line">Base printf()</span><br><span class="line">Derived func()</span><br><span class="line">Derived printf()</span><br><span class="line"></span><br><span class="line">Derived func()</span><br><span class="line">Derived func()</span><br><span class="line">Derived printf()</span><br><span class="line">Base printf()</span><br></pre></td></tr></table></figure><p><strong>结果描述</strong></p><p>Base和Derived实例分别访问func()和printf()方法。运行结果为各自对应的func()和printf()方法输出。<br>pDerivedObj 和 pBaseObj指针分别指向了Derived实例的地址，对于 pDerivedObj 指针的操作表现出来它本身的方法输出，然而当我们把相同对象的地址赋给 pBaseObj 指针时，可以发现它的非虚函数printf()竟然表现出了父类的行为，并没有被重写的样子。那到底是什么原因造成了这样的结果呢？我们继续往下看虚函数表的介绍。</p><h1 id="虚函数表以及内存布局"><a href="#虚函数表以及内存布局" class="headerlink" title="虚函数表以及内存布局"></a>虚函数表以及内存布局</h1><p>虚函数（Virtual Function）是通过一张虚函数表（Virtual Table）来实现的。简称为V-Table。在这个表中，主是要一个类的虚函数的地址表，这张表解决了继承、覆盖的问题，保证其容真实反应实际的函数。这样，在有虚函数的类的实例中这个表被分配在了这个实例的内存中，所以，当我们用父类的指针来操作一个子类的时候，这张虚函数表就显得由为重要了，它就像一个地图一样，指明了实际所应该调用的函数。</p><p>这里我们着重看一下这张虚函数表。C++的编译器应该是保证虚函数表的指针存在于对象实例中最前面的位置（这是为了保证取到虚函数表的有最高的性能——如果有多层继承或是多重继承的情况下）。 这意味着我们通过对象实例的地址得到这张虚函数表，然后就可以遍历其中函数指针，并调用相应的函数。</p><p><strong>示例代码(一下示例代码编译环境是X86并且采用4byte对齐)</strong></p><p><strong>非虚函数类</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class Base1</span><br><span class="line">&#123;</span><br><span class="line">int a;</span><br><span class="line">char c;</span><br><span class="line">public:</span><br><span class="line">void CommonFunction() &#123;&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>内存布局情况</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">  class Base1size(8):</span><br><span class="line">  +---</span><br><span class="line">   0| a</span><br><span class="line">   4| c</span><br><span class="line">    | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">  +---</span><br><span class="line">+---</span><br></pre></td></tr></table></figure><p>博主未来为了让同学们注意一下在类内存布局中常见的字节对齐问题，就专门在Base1类中添加了char c变量。可以很清晰的看出在内存中a和c成员变量依据声明的顺序进行排列（类内偏移为0开始）并且有3字节用于对齐，成员函数不占内存空间。</p><p><strong>单继承派生类不含非虚函数</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class DerivedClass : public Base1</span><br><span class="line">&#123;</span><br><span class="line">int c;</span><br><span class="line">public:</span><br><span class="line">void DerivedCommonFunction() &#123;&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>内存布局情况</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class DerivedClasssize(12):</span><br><span class="line">+---</span><br><span class="line"> 0| +--- (base class Base1)</span><br><span class="line"> 0| | a</span><br><span class="line"> 4| | c</span><br><span class="line">  | | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">| +---</span><br><span class="line"> 8| c</span><br><span class="line">+---</span><br></pre></td></tr></table></figure><p>可以看到子类DerivedClass继承了父类Base1的成员变量，在内存排布上，先是排布了父类的成员变量，接着排布子类的成员变量，同样，成员函数不占字节。</p><p><strong>存在虚函数类</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">class Base1</span><br><span class="line">&#123;</span><br><span class="line">int a;</span><br><span class="line">char c;</span><br><span class="line">public:</span><br><span class="line">void CommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction() &#123;&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>内存分布情况</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">class Base1size(12):</span><br><span class="line">+---</span><br><span class="line"> 0| &#123;vfptr&#125;</span><br><span class="line"> 4| a</span><br><span class="line"> 8| c</span><br><span class="line">  | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">+---</span><br><span class="line"></span><br><span class="line">Base1::$vftable@:</span><br><span class="line">| &amp;Base1_meta</span><br><span class="line">|  0</span><br><span class="line"> 0| &amp;Base1::VirtualFunction</span><br></pre></td></tr></table></figure><p>这个内存结构图分成了两个部分，上面是内存分布，下面是虚表，我们逐个看一下。从上图可以看出虚表指针放在了内存的开始处（0地址偏移），然后再是成员变量；下面生成了虚表，紧跟在&amp;Base1_meta后面的0表示，这张虚表对应的虚指针在内存中的分布，下面列出了虚函数，左侧的0是这个虚函数的序号，因为博主只写了一个虚函数，所以只有一项，如果有多个虚函数，会有序号为1，为2的虚函数列出来。</p><p>通过上面这个例子有同学就问了<strong>虚表指针以及虚表是什么时候创建的呢？</strong> 构造函数创建的时候即类对象实例化的时候就创建的。那么<strong>如何利用虚表指针与虚表来实现多态的呢？</strong> 当创建一个含有虚函数的父类的对象时，编译器在对象构造时将虚表指针指向父类的虚函数；同样，当创建子类的对象时，编译器在构造函数里将虚表指针（子类只有一个虚表指针，它来自父类）指向子类的虚表（这个虚表里面的虚函数入口地址是子类的）从而可以实现多态。</p><p><strong>单继承派生类中也有虚函数并且存在覆盖继承</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class DerivedClass : public Base1</span><br><span class="line">&#123;</span><br><span class="line">int d;</span><br><span class="line">public:</span><br><span class="line">void DerivedCommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction() &#123;&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>内存分布情况</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class DerivedClasssize(16):</span><br><span class="line">+---</span><br><span class="line"> 0| +--- (base class Base1)</span><br><span class="line"> 0| | &#123;vfptr&#125;</span><br><span class="line"> 4| | a</span><br><span class="line"> 8| | c</span><br><span class="line">  | | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">| +---</span><br><span class="line">12| d</span><br><span class="line">+---</span><br><span class="line"></span><br><span class="line">DerivedClass::$vftable@:</span><br><span class="line">| &amp;DerivedClass_meta</span><br><span class="line">|  0</span><br><span class="line"> 0| &amp;DerivedClass::VirtualFunction</span><br></pre></td></tr></table></figure><p>上半部是内存分布，可以看到，虚表指针被继承了，且仍位于内存排布的起始处，下面是父类的成员变量a和c，最后是子类的成员变量d，注意虚表指针只有一个，子类并没有再生成虚表指针了；下半部的虚表情况与父类是一样的由于子类将父类的虚函数方法重写了即产生的虚表序号只有一个。</p><p><strong>单继承派生类中也有虚函数并且不存在覆盖继承</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">class Base1</span><br><span class="line">&#123;</span><br><span class="line">int a;</span><br><span class="line">char c;</span><br><span class="line">public:</span><br><span class="line">void CommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction() &#123;&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class DerivedClass : public Base1</span><br><span class="line">&#123;</span><br><span class="line">int d;</span><br><span class="line">public:</span><br><span class="line">void DerivedCommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction1() &#123;&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>内存布局情况</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">class DerivedClasssize(16):</span><br><span class="line">+---</span><br><span class="line"> 0| +--- (base class Base1)</span><br><span class="line"> 0| | &#123;vfptr&#125;</span><br><span class="line"> 4| | a</span><br><span class="line"> 8| | c</span><br><span class="line">  | | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">| +---</span><br><span class="line">12| d</span><br><span class="line">+---</span><br><span class="line"></span><br><span class="line">DerivedClass::$vftable@:</span><br><span class="line">| &amp;DerivedClass_meta</span><br><span class="line">|  0</span><br><span class="line"> 0| &amp;Base1::VirtualFunction</span><br><span class="line"> 1| &amp;DerivedClass::VirtualFunction1</span><br></pre></td></tr></table></figure><p>此种情况内存分布中上半部分也只有一个虚表指针变量内存分布依次排列，但是下方虚表的内容变化了，虚表的0号是父类的VirtualFunction，而1号放的是子类的VirtualFunction2。也就是说，如果定义了DerivedClass的对象，那么在构造时，虚表指针就会指向这个虚表，以后如果调用的是VirtualFunction，那么会从父类中寻找对应的虚函数，如果调用的是VirtualFunction1，那么会从子类中寻找对应的虚函数。</p><p><strong>单继承派生类中即存在覆盖虚函数也存在非覆盖虚函数继承</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class Base1</span><br><span class="line">&#123;</span><br><span class="line">int a;</span><br><span class="line">char c;</span><br><span class="line">public:</span><br><span class="line">void CommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction() &#123;&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class DerivedClass : public Base1</span><br><span class="line">&#123;</span><br><span class="line">int c;</span><br><span class="line">public:</span><br><span class="line">void DerivedCommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction1() &#123;&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>内存布局情况</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">class DerivedClasssize(16):</span><br><span class="line">+---</span><br><span class="line"> 0| +--- (base class Base1)</span><br><span class="line"> 0| | &#123;vfptr&#125;</span><br><span class="line"> 4| | a</span><br><span class="line"> 8| | c</span><br><span class="line">  | | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">| +---</span><br><span class="line">12| c</span><br><span class="line">+---</span><br><span class="line"></span><br><span class="line">DerivedClass::$vftable@:</span><br><span class="line">| &amp;DerivedClass_meta</span><br><span class="line">|  0</span><br><span class="line"> 0| &amp;DerivedClass::VirtualFunction</span><br><span class="line"> 1| &amp;DerivedClass::VirtualFunction1</span><br></pre></td></tr></table></figure><p>根据上面的内存布局情况，我们既重写了父类的虚函数，也有新添的虚函数，最终虚函数表0号和1号都是子类对应的虚函数地址。</p><p><strong>多继承派生类中存在覆盖虚函数继承</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">class Base1</span><br><span class="line">&#123;</span><br><span class="line">int a;</span><br><span class="line">char c;</span><br><span class="line">public:</span><br><span class="line">void CommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction() &#123;&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class DerivedClass1 : public Base1</span><br><span class="line">&#123;</span><br><span class="line">int b;</span><br><span class="line">public:</span><br><span class="line">void DerivedCommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction() &#123;&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class DerivedClass2 : public Base1</span><br><span class="line">&#123;</span><br><span class="line">int d;</span><br><span class="line">public:</span><br><span class="line">void DerivedCommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction() &#123;&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class DerivedDerivedClass : public DerivedClass1, public DerivedClass2</span><br><span class="line">&#123;</span><br><span class="line">int e;</span><br><span class="line">public:</span><br><span class="line">void DerivedDerivedCommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction() &#123;&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>内存布局</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">class Base1size(12):</span><br><span class="line">+---</span><br><span class="line">0| &#123;vfptr&#125;</span><br><span class="line">4| a</span><br><span class="line">8| c</span><br><span class="line">    | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">+---</span><br><span class="line"></span><br><span class="line">Base1::$vftable@:</span><br><span class="line">| &amp;Base1_meta</span><br><span class="line">|  0</span><br><span class="line">0| &amp;Base1::VirtualFunction</span><br><span class="line"></span><br><span class="line">class DerivedClass1size(16):</span><br><span class="line">  +---</span><br><span class="line">   0| +--- (base class Base1)</span><br><span class="line">   0| | &#123;vfptr&#125;</span><br><span class="line">   4| | a</span><br><span class="line">   8| | c</span><br><span class="line">    | | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">  | +---</span><br><span class="line">  12| b</span><br><span class="line">  +---</span><br><span class="line"></span><br><span class="line">  DerivedClass1::$vftable@:</span><br><span class="line">  | &amp;DerivedClass1_meta</span><br><span class="line">  |  0</span><br><span class="line">   0| &amp;DerivedClass1::VirtualFunction</span><br><span class="line"></span><br><span class="line">  DerivedClass1::VirtualFunction this adjustor: 0</span><br><span class="line"></span><br><span class="line">  class DerivedClass2size(16):</span><br><span class="line">  +---</span><br><span class="line">   0| +--- (base class Base1)</span><br><span class="line">   0| | &#123;vfptr&#125;</span><br><span class="line">   4| | a</span><br><span class="line">   8| | c</span><br><span class="line">    | | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">  | +---</span><br><span class="line">  12| d</span><br><span class="line">  +---</span><br><span class="line"></span><br><span class="line">  DerivedClass2::$vftable@:</span><br><span class="line">  | &amp;DerivedClass2_meta</span><br><span class="line">  |  0</span><br><span class="line">   0| &amp;DerivedClass2::VirtualFunction</span><br><span class="line"></span><br><span class="line">  DerivedClass2::VirtualFunction this adjustor: 0</span><br><span class="line"></span><br><span class="line">  class DerivedDerivedClasssize(36):</span><br><span class="line">  +---</span><br><span class="line">   0| +--- (base class DerivedClass1)</span><br><span class="line">   0| | +--- (base class Base1)</span><br><span class="line">   0| | | &#123;vfptr&#125;</span><br><span class="line">   4| | | a</span><br><span class="line">   8| | | c</span><br><span class="line">    | | | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">  | | +---</span><br><span class="line">  12| | b</span><br><span class="line">  | +---</span><br><span class="line">  16| +--- (base class DerivedClass2)</span><br><span class="line">  16| | +--- (base class Base1)</span><br><span class="line">  16| | | &#123;vfptr&#125;</span><br><span class="line">  20| | | a</span><br><span class="line">  24| | | c</span><br><span class="line">    | | | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">  | | +---</span><br><span class="line">  28| | d</span><br><span class="line">  | +---</span><br><span class="line">  32| e</span><br><span class="line">  +---</span><br><span class="line"></span><br><span class="line">  DerivedDerivedClass::$vftable@DerivedClass1@:</span><br><span class="line">  | &amp;DerivedDerivedClass_meta</span><br><span class="line">  |  0</span><br><span class="line">   0| &amp;DerivedDerivedClass::VirtualFunction</span><br><span class="line"></span><br><span class="line">  DerivedDerivedClass::$vftable@DerivedClass2@:</span><br><span class="line">  | -16</span><br><span class="line">   0| &amp;thunk: this-&#x3D;16; goto DerivedDerivedClass::VirtualFunction</span><br></pre></td></tr></table></figure><p>根据上面的内存分布情况，此多继承覆盖情况，我分别把每个类的内存分布都打了出来，下面我们重点看看这个类DerivedDerivedClass，由外向内看，它并列地排布着继承而来的两个父类DerivedClass1与DerivedClass2，还有自身的成员变量e。DerivedClass1包含了它的成员变量b，以及Base1，Base1有一个0地址偏移的虚表指针，然后是成员变量a和c；DerivedClass2的内存排布类似于DerivedClass1，注意到DerivedClass2里面竟然也有一份Base1。<br>我们再来看看虚表继承情况，我们看到了有两份虚表了，分别针对DerivedClass1与DerivedClass2，在&amp;DerivedDericedClass_meta下方的数字是首地址偏移量0也是DerivedClass1中的{vfptr}虚函数指针在DerivedDerivedClass的内存偏移，靠下面的虚表的那个-16表示指向这个虚表的虚指针的内存偏移，这正是DerivedClass2中的{vfptr}在DerivedDerivedClass的内存偏移。</p><p><strong>DerivedDerivedClass()的虚表的VirtualFunction()指针</strong><br><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/c++%E8%99%9A%E5%87%BD%E6%95%B01.png?raw=true"  alt></p><p><strong>多继承派生类中不存在覆盖虚函数继承</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">class Base1</span><br><span class="line">&#123;</span><br><span class="line">int a;</span><br><span class="line">char c;</span><br><span class="line">public:</span><br><span class="line">void CommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction() &#123;&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class DerivedClass1 : public Base1</span><br><span class="line">&#123;</span><br><span class="line">int b;</span><br><span class="line">public:</span><br><span class="line">void DerivedCommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction1() &#123;&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class DerivedClass2 : public Base1</span><br><span class="line">&#123;</span><br><span class="line">int d;</span><br><span class="line">public:</span><br><span class="line">void DerivedCommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction2() &#123;&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class DerivedDerivedClass : public DerivedClass1, public DerivedClass2</span><br><span class="line">&#123;</span><br><span class="line">int e;</span><br><span class="line">public:</span><br><span class="line">void DerivedDerivedCommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction3() &#123;&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>内存布局情况</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">  class Base1size(12):</span><br><span class="line">  +---</span><br><span class="line">  0| &#123;vfptr&#125;</span><br><span class="line">  4| a</span><br><span class="line">  8| c</span><br><span class="line">      | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">  +---</span><br><span class="line"></span><br><span class="line">  Base1::$vftable@:</span><br><span class="line">  | &amp;Base1_meta</span><br><span class="line">  |  0</span><br><span class="line">  0| &amp;Base1::VirtualFunction</span><br><span class="line"></span><br><span class="line">class DerivedClass1size(16):</span><br><span class="line">+---</span><br><span class="line"> 0| +--- (base class Base1)</span><br><span class="line"> 0| | &#123;vfptr&#125;</span><br><span class="line"> 4| | a</span><br><span class="line"> 8| | c</span><br><span class="line">  | | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">| +---</span><br><span class="line">12| b</span><br><span class="line">+---</span><br><span class="line"></span><br><span class="line">DerivedClass1::$vftable@:</span><br><span class="line">| &amp;DerivedClass1_meta</span><br><span class="line">|  0</span><br><span class="line"> 0| &amp;Base1::VirtualFunction</span><br><span class="line"> 1| &amp;DerivedClass1::VirtualFunction1</span><br><span class="line"></span><br><span class="line">DerivedClass1::VirtualFunction1 this adjustor: 0</span><br><span class="line"></span><br><span class="line">class DerivedClass2size(16):</span><br><span class="line">+---</span><br><span class="line"> 0| +--- (base class Base1)</span><br><span class="line"> 0| | &#123;vfptr&#125;</span><br><span class="line"> 4| | a</span><br><span class="line"> 8| | c</span><br><span class="line">  | | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">| +---</span><br><span class="line">12| d</span><br><span class="line">+---</span><br><span class="line"></span><br><span class="line">DerivedClass2::$vftable@:</span><br><span class="line">| &amp;DerivedClass2_meta</span><br><span class="line">|  0</span><br><span class="line"> 0| &amp;Base1::VirtualFunction</span><br><span class="line"> 1| &amp;DerivedClass2::VirtualFunction2</span><br><span class="line"></span><br><span class="line">DerivedClass2::VirtualFunction2 this adjustor: 0</span><br><span class="line"></span><br><span class="line">class DerivedDerivedClasssize(36):</span><br><span class="line">+---</span><br><span class="line"> 0| +--- (base class DerivedClass1)</span><br><span class="line"> 0| | +--- (base class Base1)</span><br><span class="line"> 0| | | &#123;vfptr&#125;</span><br><span class="line"> 4| | | a</span><br><span class="line"> 8| | | c</span><br><span class="line">  | | | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">| | +---</span><br><span class="line">12| | b</span><br><span class="line">| +---</span><br><span class="line">16| +--- (base class DerivedClass2)</span><br><span class="line">16| | +--- (base class Base1)</span><br><span class="line">16| | | &#123;vfptr&#125;</span><br><span class="line">20| | | a</span><br><span class="line">24| | | c</span><br><span class="line">  | | | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">| | +---</span><br><span class="line">28| | d</span><br><span class="line">| +---</span><br><span class="line">32| e</span><br><span class="line">+---</span><br><span class="line"></span><br><span class="line">DerivedDerivedClass::$vftable@DerivedClass1@:</span><br><span class="line">| &amp;DerivedDerivedClass_meta</span><br><span class="line">|  0</span><br><span class="line"> 0| &amp;Base1::VirtualFunction</span><br><span class="line"> 1| &amp;DerivedClass1::VirtualFunction1</span><br><span class="line"> 2| &amp;DerivedDerivedClass::VirtualFunction3</span><br><span class="line"></span><br><span class="line">DerivedDerivedClass::$vftable@DerivedClass2@:</span><br><span class="line">| -16</span><br><span class="line"> 0| &amp;Base1::VirtualFunction</span><br><span class="line"> 1| &amp;DerivedClass2::VirtualFunction2</span><br></pre></td></tr></table></figure><p>此种情况的内存分布和覆盖多继承一样，唯一注意的就是在多继承中成员虚函数地址会保存到第一个继承父类的虚函数表。</p><p><strong>多继承之虚继承派生类中存在覆盖虚函数继承</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">class Base1</span><br><span class="line">&#123;</span><br><span class="line">int a;</span><br><span class="line">char c;</span><br><span class="line">public:</span><br><span class="line">void CommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction() &#123;&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class DerivedClass1 : virtual public Base1</span><br><span class="line">&#123;</span><br><span class="line">int b;</span><br><span class="line">public:</span><br><span class="line">void DerivedCommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction1() &#123;&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class DerivedClass2 : virtual public Base1</span><br><span class="line">&#123;</span><br><span class="line">int d;</span><br><span class="line">public:</span><br><span class="line">void DerivedCommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction2() &#123;&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class DerivedDerivedClass : public DerivedClass1, public DerivedClass2</span><br><span class="line">&#123;</span><br><span class="line">int e;</span><br><span class="line">public:</span><br><span class="line">void DerivedDerivedCommonFunction() &#123;&#125;;</span><br><span class="line">void virtual VirtualFunction3() &#123;&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>内存分布情况</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line">  class Base1size(12):</span><br><span class="line">  +---</span><br><span class="line">  0| &#123;vfptr&#125;</span><br><span class="line">  4| a</span><br><span class="line">  8| c</span><br><span class="line">      | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">  +---</span><br><span class="line"></span><br><span class="line">  Base1::$vftable@:</span><br><span class="line">  | &amp;Base1_meta</span><br><span class="line">  |  0</span><br><span class="line">  0| &amp;Base1::VirtualFunction</span><br><span class="line"></span><br><span class="line">class DerivedClass1size(24):</span><br><span class="line">+---</span><br><span class="line"> 0| &#123;vfptr&#125;</span><br><span class="line"> 4| &#123;vbptr&#125;</span><br><span class="line"> 8| b</span><br><span class="line">+---</span><br><span class="line">+--- (virtual base Base1)</span><br><span class="line">12| &#123;vfptr&#125;</span><br><span class="line">16| a</span><br><span class="line">20| c</span><br><span class="line">  | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">+---</span><br><span class="line"></span><br><span class="line">DerivedClass1::$vftable@DerivedClass1@:</span><br><span class="line">| &amp;DerivedClass1_meta</span><br><span class="line">|  0</span><br><span class="line"> 0| &amp;DerivedClass1::VirtualFunction1</span><br><span class="line"></span><br><span class="line">DerivedClass1::$vbtable@:</span><br><span class="line"> 0| -4</span><br><span class="line"> 1| 8 (DerivedClass1d(DerivedClass1+4)Base1)</span><br><span class="line"></span><br><span class="line">DerivedClass1::$vftable@Base1@:</span><br><span class="line">| -12</span><br><span class="line"> 0| &amp;Base1::VirtualFunction</span><br><span class="line"></span><br><span class="line">DerivedClass1::VirtualFunction1 this adjustor: 0</span><br><span class="line">vbi:   class  offset o.vbptr  o.vbte fVtorDisp</span><br><span class="line">           Base1      12       4       4 0</span><br><span class="line"></span><br><span class="line">class DerivedClass2size(24):</span><br><span class="line">+---</span><br><span class="line"> 0| &#123;vfptr&#125;</span><br><span class="line"> 4| &#123;vbptr&#125;</span><br><span class="line"> 8| d</span><br><span class="line">+---</span><br><span class="line">+--- (virtual base Base1)</span><br><span class="line">12| &#123;vfptr&#125;</span><br><span class="line">16| a</span><br><span class="line">20| c</span><br><span class="line">  | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">+---</span><br><span class="line"></span><br><span class="line">DerivedClass2::$vftable@DerivedClass2@:</span><br><span class="line">| &amp;DerivedClass2_meta</span><br><span class="line">|  0</span><br><span class="line"> 0| &amp;DerivedClass2::VirtualFunction2</span><br><span class="line"></span><br><span class="line">DerivedClass2::$vbtable@:</span><br><span class="line"> 0| -4</span><br><span class="line"> 1| 8 (DerivedClass2d(DerivedClass2+4)Base1)</span><br><span class="line"></span><br><span class="line">DerivedClass2::$vftable@Base1@:</span><br><span class="line">| -12</span><br><span class="line"> 0| &amp;Base1::VirtualFunction</span><br><span class="line"></span><br><span class="line">DerivedClass2::VirtualFunction2 this adjustor: 0</span><br><span class="line">vbi:   class  offset o.vbptr  o.vbte fVtorDisp</span><br><span class="line">           Base1      12       4       4 0</span><br><span class="line"></span><br><span class="line">class DerivedDerivedClasssize(40):</span><br><span class="line">+---</span><br><span class="line"> 0| +--- (base class DerivedClass1)</span><br><span class="line"> 0| | &#123;vfptr&#125;</span><br><span class="line"> 4| | &#123;vbptr&#125;</span><br><span class="line"> 8| | b</span><br><span class="line">| +---</span><br><span class="line">12| +--- (base class DerivedClass2)</span><br><span class="line">12| | &#123;vfptr&#125;</span><br><span class="line">16| | &#123;vbptr&#125;</span><br><span class="line">20| | d</span><br><span class="line">| +---</span><br><span class="line">24| e</span><br><span class="line">+---</span><br><span class="line">+--- (virtual base Base1)</span><br><span class="line">28| &#123;vfptr&#125;</span><br><span class="line">32| a</span><br><span class="line">36| c</span><br><span class="line">  | &lt;alignment member&gt; (size&#x3D;3)</span><br><span class="line">+---</span><br><span class="line"></span><br><span class="line">DerivedDerivedClass::$vftable@DerivedClass1@:</span><br><span class="line">| &amp;DerivedDerivedClass_meta</span><br><span class="line">|  0</span><br><span class="line"> 0| &amp;DerivedClass1::VirtualFunction1</span><br><span class="line"> 1| &amp;DerivedDerivedClass::VirtualFunction3</span><br><span class="line"></span><br><span class="line">DerivedDerivedClass::$vftable@DerivedClass2@:</span><br><span class="line">| -12</span><br><span class="line"> 0| &amp;DerivedClass2::VirtualFunction2</span><br><span class="line"></span><br><span class="line">DerivedDerivedClass::$vbtable@DerivedClass1@:</span><br><span class="line"> 0| -4</span><br><span class="line"> 1| 24 (DerivedDerivedClassd(DerivedClass1+4)Base1)</span><br><span class="line"></span><br><span class="line">DerivedDerivedClass::$vbtable@DerivedClass2@:</span><br><span class="line"> 0| -4</span><br><span class="line"> 1| 12 (DerivedDerivedClassd(DerivedClass2+4)Base1)</span><br><span class="line"></span><br><span class="line">DerivedDerivedClass::$vftable@Base1@:</span><br><span class="line">| -28</span><br><span class="line"> 0| &amp;Base1::VirtualFunction</span><br></pre></td></tr></table></figure><p>上面虚继承的内存分布不做过多的叙述，下来总结一下：<br>虚继承的作用是减少了对基类的重复(在一般多继承中会造成二义性编译时出错，虚继承可以消除二义性)，但是代价是增加了虚表指针的负担（更多的虚表指针）。根据以上示例当基类有虚函数时：</p><ul><li><p>1 每个类都有虚指针和虚表；</p></li><li><p>2 如果不是虚继承，那么子类将父类的虚指针继承下来，并指向自身的虚表（发生在对象构造时）。有多少个虚函数，虚表里面的项就会有多少。多重继承时，可能存在多个的基类虚表与虚指针；</p></li><li><p>3 如果是虚继承，那么子类会有两份虚指针，一份指向自己的虚表，另一份指向虚基表，多重继承时虚基表与虚基表指针有且只有一份。</p></li></ul><p><strong>博客著作权归本作者所有，任何形式的转载都请联系作者获得授权并注明出处。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
          <category> C++ 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一条SQL语句在MySQL中如何执行的呢？</title>
      <link href="/2019-05-10-SQL%E5%9C%A8MySQL%E4%B8%AD%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F/"/>
      <url>/2019-05-10-SQL%E5%9C%A8MySQL%E4%B8%AD%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="MySQL架构分析以及各模块功能介绍"><a href="#MySQL架构分析以及各模块功能介绍" class="headerlink" title="MySQL架构分析以及各模块功能介绍"></a>MySQL架构分析以及各模块功能介绍</h2><p>如图是MySQL的一个简要架构图：</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/mysql_framework.png?raw=true"  alt></p><p><strong>SERVER:</strong> 如上图所示，SERVER层主要包括连接器、查询缓存、分析器、优化器、执行器等。例如存储过程、触发器、函数等功能都在这一层实现。日志模块Binlog模块也在SERVER层中实现。</p><p><strong>Storage engine:</strong> 主要负责数据的存储和读取，采用可替代的Plugin式架构，支持InnoDB、My-ISAM、Memory等多个存储引擎。</p><p><strong>Connector:</strong> 主要负责用户登录数据库，进行用户身份的认证，包括账户密码、权限等校验操作，如果校验通过，连接器会在权限表中查询该用户的所有执行权限，后续只要此连接不断开，即使管理员修改了该用户的权限，也不受影响。</p><p><strong>Query cache:</strong> 当用户在建立连接后，执行查询语句的时候，回先查询缓存，当MySQL在开始校验SQL是否已经执行过，会以key-value的形式缓存在内存中，key是查询语句，value是结果集。如果缓存key被找到，就会直接返回给客户端，如果没有找到就会执行后续的操作，当完成一次操作后也会把结果以key-value形式缓存起来(真正执行缓存查询时会先校验该用户的执行权限)。</p><p>相信读者看到这就会有了一个问号，对于数据实时更新和存储的场景，这种缓存机制显然是不可取的，在MySQL8.0版本以后该功能被直接删除掉了。</p><p><strong>Analyzer:</strong> 分析器是用来分析SQL语句，主要具体分析有以下几步：<br>第一步 词法分析：我们都知道SQL语句有很多.分为四大类DDL、DML、DQL、DCL。每条语句都是由多个字符串组成，要进行词法分析首先要提取关键字，比如‘select’,然后依次提出查询的表，提出字段名，提出查询条件等等。当此法的分析关机条件提取完成之后，会进入下一步。<br>第二步 语法分析：语法分析是根据MYSQL语法标准判断输入SQL语法是否正确。当语法分析合法之后，就进入下一步执行，但是如何执行会是最优的方式呢？此时就需要优化器。</p><p><strong>Optimizer:</strong> 优化器作用是找出最优的执行方案，例如在多索引条件下如何选择索引，多表查询的时候关联顺序的选择等等。</p><p><strong>Actuator:</strong> 在优化器选择了最终的执行方案后会交给执行器开始执行，在执行SQL方案之前会校验用户的执行权限，如果该用户没有改表的操作权限或者相应执行权限，就会直接返回错误信息。如果用户权限校验通过，执行器就会调用存储引擎的接口，并且相应返回接口执行的结果。</p><h2 id="未完待续-……"><a href="#未完待续-……" class="headerlink" title="未完待续 ……"></a>未完待续 ……</h2><p><strong>博客著作权归本作者所有，任何形式的转载都请联系作者获得授权并注明出处。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ详解</title>
      <link href="/2019-04-29-Rabbitmq%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019-04-29-Rabbitmq%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="RabbitMQ-介绍"><a href="#RabbitMQ-介绍" class="headerlink" title="RabbitMQ 介绍"></a>RabbitMQ 介绍</h1><p>RabbitMQ 是实现 AMQP（高级消息队列协议）的消息中间件的一种，最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 RabbitMQ 主要是为了实现系统之间的双向解耦而实现的。当生产者大量产生数据时，消费者无法快速消费，那么需要一个中间层。保存这个数据。</p><p>AMQP，即 Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP 的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。</p><p>RabbitMQ 是一个开源的 AMQP 实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP 等，支持 AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。</p><h1 id="RabbitMQ-安装"><a href="#RabbitMQ-安装" class="headerlink" title="RabbitMQ 安装"></a>RabbitMQ 安装</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get install libsctp1</span><br><span class="line">$ wget https:&#x2F;&#x2F;packages.erlang-solutions.com&#x2F;erlang&#x2F;,version: 20.0-1_ubuntu_xenial</span><br><span class="line">$ sudo dpkg -i esl-erlang_20.0-1_ubuntu_xenial_amd64.deb</span><br><span class="line">$ wget http:&#x2F;&#x2F;packages.erlang-solutions.com&#x2F;site&#x2F;esl&#x2F;esl-erlang&#x2F;FLAVOUR_1_general&#x2F;esl-erlang_20.0-1~ubuntu~xenial_amd64.deb</span><br><span class="line">$ sudo apt-get install -f -y</span><br><span class="line">$ sudo dpkg -i esl-erlang_20.0-1_ubuntu_xenial_amd64.deb</span><br><span class="line">$ wget https:&#x2F;&#x2F;packagecloud.io&#x2F;rabbitmq&#x2F;rabbitmq-server&#x2F;packages&#x2F;ubuntu&#x2F;xenial&#x2F;rabbitmq-server_3.7.6-1_all.deb&#x2F;download.deb</span><br><span class="line">$ sudo dpkg -i rabbitmq-server_3.7.6-1_all.deb</span><br></pre></td></tr></table></figure><h1 id="RabbitMQ-配置"><a href="#RabbitMQ-配置" class="headerlink" title="RabbitMQ 配置"></a>RabbitMQ 配置</h1><p><strong>支持跨域访问</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ sudo chmod 777 -R &#x2F;etc&#x2F;rabbitmq&#x2F;</span><br><span class="line">$ cd &#x2F;etc&#x2F;rabbitmq&#x2F;       </span><br><span class="line">$ sudo vim rabbitmq.conf</span><br><span class="line">$ sudo sed -i &quot;s&#x2F;# loopback_users.guest &#x3D; false&#x2F;loopback_users.guest &#x3D; false&#x2F;g&quot;   .&#x2F;rabbitmq.conf</span><br><span class="line">$ sudo chmod 777  .&#x2F;rabbitmq.conf</span><br><span class="line">$ sudo service rabbitmq-server restart</span><br></pre></td></tr></table></figure><h1 id="RabbitMQ-命令"><a href="#RabbitMQ-命令" class="headerlink" title="RabbitMQ 命令"></a>RabbitMQ 命令</h1><ul><li>/etc/init.d/rabbitmq-server start|stop|restart|reload</li><li>rabbitmqctl add_vhost vhostname 创建 Vhost</li><li>rabbitmqctl delete_vhost vhostname 删除 Vhost</li><li>rabbitmqctl list_vhost 遍历所有虚拟主机信息</li><li>rabbitmqctl add_user username password 添加用户名、密码</li><li>rabbitmqctl change_password username password 修改用户密码</li><li>rabbitmqctl set_permissions -p v_host user “.””.””.*” 绑定权限，并且具备读写的权限</li><li>rabbitmqctl list_queues 显示所有队列</li></ul><h1 id="RabbitMQ-模式"><a href="#RabbitMQ-模式" class="headerlink" title="RabbitMQ 模式"></a>RabbitMQ 模式</h1><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/rabbitmq1.png?raw=true"  alt></p><h3 id="1-fanout模式"><a href="#1-fanout模式" class="headerlink" title="1. fanout模式"></a>1. fanout模式</h3><p><strong>模式特点：</strong> 可以理解他是一个广播模式不需要routing key它的消息发送时通过Exchange binding进行路由的~~在这个模式routing key失去作用这种模式需要提前将Exchange与Queue进行绑定，一个Exchange可以绑定多个Queue，一个Queue可以同多个Exchange进行绑定如果接收到消息的Exchange没有与任何Queue绑定，则消息会被抛弃。</p><h3 id="2-Direct-模式"><a href="#2-Direct-模式" class="headerlink" title="2. Direct 模式"></a>2. Direct 模式</h3><p><strong>模式特点：</strong> 任何发送到Direct Exchange的消息都会被转发到routing_key中指定的Queue。一个routing_key可以绑定一个Queue，同时一个routing_key也可以绑定多个队列。</p><ul><li><ol><li>一般情况可以使用rabbitMQ自带的Exchange：”” (该Exchange的名字为空字符串)， 也可以自定义Exchange。</li></ol></li><li><ol start="2"><li>这种模式下不需要将Exchange进行任何绑定(bind)操作。当然也可以进行绑定。可以将不同的routing_key与不同的queue进行绑定，不同的queue与不同exchange进行绑定。</li></ol></li><li><ol start="3"><li>消息传递时需要一个“routing_key”。</li></ol></li><li><ol start="4"><li>如果消息中不存在routing_key中绑定的队列名，则该消息会被抛弃。</li></ol></li></ul><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/rabbitmq3.png?raw=true"  alt></p><h3 id="3-topic类型"><a href="#3-topic类型" class="headerlink" title="3. topic类型"></a>3. topic类型</h3><p><strong>模式特点：</strong> copic类型的Exchange在匹配规则上进行了扩展，它与direct类型的Exchage相似，也是将消息路由到binding key与routing key相匹配的Queue中，但这里的匹配规则有些不同如下所述：</p><ul><li>routing key为一个句点号“. ”分隔的字符串（我们将被句点号“. ”分隔开的每一段独立的字符串称为一个单词），如“stock.usd.nyse”、“nyse.vmw”、“quick.orange.rabbit”</li><li>binding key与routing key一样也是句点号“. ”分隔的字符串</li><li>binding key中可以存在两种特殊字符“<em>”与“#”，用于做模糊匹配，其中“</em>”用于匹配一个单词，“#”用于匹配多个单词（可以是零个）</li></ul><p><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/rabbitmq2.png?raw=true"  alt></p><h1 id="RabbitMQ实现RPC机制"><a href="#RabbitMQ实现RPC机制" class="headerlink" title="RabbitMQ实现RPC机制"></a>RabbitMQ实现RPC机制</h1><ul><li>客户端发送请求（消息）时，在消息的属性（MessageProperties，在AMQP协议中定义了14种properties，这些属性会随着消息一起发送）中设置两个值replyTo（一个Queue名称，用于告诉服务器处理完成后将通知我的消息发送到这个Queue中）和correlationId（此次请求的标识号，服务器处理完成后需要将此属性返还，客户端将根据这个id了解哪条请求被成功执行了或执行失败）</li><li>服务器端收到消息并处理</li><li>服务器端处理完消息后，将生成一条应答消息到replyTo指定的Queue，同时带上correlationId属性</li><li>客户端之前已订阅replyTo指定的Queue，从中收到服务器的应答消息后，根据其中的correlationId属性分析哪条请求被执行了，根据执行结果进行后续业务处理</li></ul><p><strong>Correlation id</strong></p><p>一般我们在设置RPC请求时给每个请求设置一个唯一值，最后当我们收到消息在这个callback Queue中，我们查看这个属性和请求的属性(Correlation_id)进行匹配如果没有匹配上，我们将拒绝这个消息它不是我们的。</p><p>为什么我们应该忽略回调队列中的未知消息，而不是错误地失败呢?这是由于服务器端可能出现竞态条件。虽然不太可能，但是RPC服务器可能在发送了答案后才会死亡，但在发送请求消息之前。</p><p>如果发生这种情况，重新启动的RPC服务器将再次处理此请求。这就是为什么在客户端我们必须优雅地处理重复的响应，而RPC应该是幂等（）的。</p><p>RPC幂等性：</p><p> f(x)=f(f(x))<br>如果消息具有操作幂等性，也就是一个消息被应用多次与应用一次产生的效果是一样的。</p><p><strong>博客著作权归本作者所有，任何形式的转载都请联系作者获得授权并注明出处。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis(二)之高可用(HA)</title>
      <link href="/2018-04-29-Redis(%E4%BA%8C)%E4%B9%8B%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
      <url>/2018-04-29-Redis(%E4%BA%8C)%E4%B9%8B%E9%AB%98%E5%8F%AF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Redis高可用方案HA（High-Available）"><a href="#Redis高可用方案HA（High-Available）" class="headerlink" title="Redis高可用方案HA（High Available）"></a>Redis高可用方案HA（High Available）</h1><h2 id="一、Redis单实例"><a href="#一、Redis单实例" class="headerlink" title="一、Redis单实例"></a>一、Redis单实例</h2><p>当系统中只运行一台Redis实例时，一旦该redis挂了，必然会导致系统不可用。</p><h2 id="二、Redis主从同步-备份"><a href="#二、Redis主从同步-备份" class="headerlink" title="二、Redis主从同步(备份)"></a>二、Redis主从同步(备份)</h2><p>主从备份，即主服务器与从服务器之间数据备份的问题。Redis 支持简单且易用的主从复制（master-slave replication）功能， 该功能可以让从服务器(slave server)成为主服务器(master server)的精确复制品。<br>但是Redis配置主从同步，当redis master节点挂掉之后，slave节点只能提供只读服务，无法提供写服务，所以还需要想办法实现当主redis挂了之后，让从redis(slave节点)升级为主redis(主节点)。这里提到一个概念，<strong>自动故障转移</strong>，redis sentinel带有这个功能，当一个主redis(master节点)不能提供服务时，redis sentinel可以将一个从redis(slave节点)升级为主redis(master节点)，并对其他从redis(slave节点)进行配置，让它们使用新的主redis(master节点)进行复制备份。</p><p><strong>主从备份的特点</strong></p><ul><li><p>（1）一个主服务器可以有多个从服务器。</p></li><li><p>（2）不仅主服务器可以有从服务器， 从服务器也可以有自己的从服务器。</p></li><li><p>（3）Redis 支持异步复制和部分复制（这两个特性从Redis 2.8开始），主从复制过程不会阻塞主服务器和从服务器。</p></li><li><p>（4）主从复制功能可以提升系统的伸缩性和功能，如让多个从服务器处理只读命令，使用复制功能来让主服务器免于频繁的执行持久化操作。</p></li></ul><h2 id="三、主从备份方案-Redis-sentinel-哨兵模式方案"><a href="#三、主从备份方案-Redis-sentinel-哨兵模式方案" class="headerlink" title="三、主从备份方案 Redis sentinel(哨兵模式方案)"></a>三、主从备份方案 Redis sentinel(哨兵模式方案)</h2><p><strong>哨兵</strong>的含义就是监控redis系统的运行状态。可以启动多个哨兵，去监控redis数据库的运行状态。其主要功能有两点:</p><ul><li><p>a、监控所有节点数据库是否在正常运行。</p></li><li><p>b、master数据库出现故障时，可以自动通过投票机制，从slave节点中选举新的master，实现将从数据库转换为主数据库的自动切换。</p></li></ul><p>在一个一主多从的Redis系统中，可以使用多个哨兵进行监控任务以保证系统足够稳健。此时，不仅哨兵会同时监控主数据库和从数据库，哨兵之间也会相互监控。在这里，建议大家哨兵至少部署3个，并且使用奇数个哨兵(奇数个哨兵是因为在决定中可以避免正反对等的结果出现)。</p><p>Redis的哨兵(sentinel) 系统用于管理多个 Redis 服务器,该系统执行以下三个任务:</p><ul><li><strong>监控(Monitoring):</strong> 哨兵(sentinel) 会不断地检查你的Master和Slave是否运作正常。</li><li><strong>提醒(Notification):</strong> 当被监控的某个 Redis节点出现问题时, 哨兵(sentinel) 可以通过 API 向管理员或者其他应用程序发送通知。</li><li><strong>自动故障迁移(Automatic failover):</strong> 当一个Master节点不能正常工作时，哨兵(sentinel) 会开始一次自动故障迁移操作,它会将失效Master节点的其中一个Slave节点升级为新的Master, 并让失效Master节点的其他Slave节点改为复制新的Master节点; 当客户端试图连接失效的Master节点时,集群也会向客户端返回新Master节点的地址,使得集群可以使用Master节点代替失效Master节点。</li></ul><p><strong>哨兵(sentinel)</strong> 是一个分布式系统,你可以在一个架构中运行多个哨兵(sentinel) 进程,这些进程使用流言协议(gossipprotocols)来接收关于Master节点是否下线的信息,并使用投票协议(agreement protocols)来决定是否执行自动故障迁移,以及选择哪个Slave节点作为新的Master节点。<br>每个哨兵(sentinel) 会向其它哨兵(sentinel)、master节点、slave节点定时发送消息,以确认对方是否”活”着,如果发现对方在指定时间(可配置)内未回应,则暂时认为对方已挂(所谓的”主观认为 <strong>宕机</strong> ” Subjective Down,简称sdown)。<br>若“哨兵群”中的多数sentinel,都报告某一master节点没响应,系统才认为该master节点”彻底死亡”(即:客观上的真正down机),通过一定的vote算法,从剩下的slave节点中,选一台提升为master节点,然后自动修改相关配置。</p><p><strong>监控</strong></p><p>sentinel会每秒一次的频率与之前创建了命令连接的实例发送PING，包括主服务器、从服务器和sentinel实例，以此来判断当前实例的状态。down-after-milliseconds时间内PING连接无效，则将该实例视为主观下线。之后该sentinel会向其他监控同一主服务器的sentinel实例询问是否也将该服务器视为主观下线状态，当超过某quorum后将其视为客观下线状态。</p><p>当一个主服务器被某sentinel视为客观下线状态后，该sentinel会与其他sentinel协商选出零头sentinel进行故障转移工作。每个发现主服务器进入客观下线的sentinel都可以要求其他sentinel选自己为领头sentinel，选举是先到先得。同时每个sentinel每次选举都会自增配置纪元，每个纪元中只会选择一个领头sentinel。如果所有超过一半的sentinel选举某sentinel领头sentinel。之后该sentinel进行故障转移操作。</p><p>如果一个Sentinel为了指定的主服务器故障转移而投票给另一个Sentinel，将会等待一段时间后试图再次故障转移这台主服务器。如果该次失败另一个将尝试，Redis Sentinel保证第一个活性(liveness)属性，如果大多数Sentinel能够对话，如果主服务器下线，最后只会有一个被授权来故障转移。 同时Redis Sentinel也保证安全(safety)属性，每个Sentinel将会使用不同的配置纪元来故障转移同一台主服务器</p><p><strong>故障转移</strong></p><p>首先是从主服务器的从服务器中选出一个从服务器作为新的主服务器。选点的依据依次是：网络连接正常-&gt;5秒内回复过INFO命令-&gt;10*down-after-milliseconds内与主连接过的-&gt;从服务器优先级-&gt;复制偏移量-&gt;运行id较小的。选出之后通过slaveif no ont将该从服务器升为新主服务器。通过slaveof ip port命令让其他从服务器复制该新主服务器。最后当旧主重新连接后将其变为新主的从服务器。注意如果客户端与就主服务器分隔在一起，写入的数据在恢复后由于旧主会复制新主的数据会造成数据丢失。故障转移成功后会通过发布订阅连接广播新的配置信息，其他sentinel收到后依据配置纪元更大来更新主服务器信息。Sentinel保证第二个活性属性：一个可以相互通信的Sentinel集合会统一到一个拥有更高版本号的相同配置上。</p><p><strong>哨兵机制图解如下：</strong></p><ul><li><p>正常集群系统<br><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/sentinel1.png?raw=true"  alt></p></li><li><p>master节点宕机<br><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/sentinel2.png?raw=true"  alt></p></li><li><p>故障转移，选举新的master节点。<br><img src="/img/loading.gif" class="lazyload" data-src="https://github.com/FrederickHou/FrederickHou.github.io/blob/master/img/sentinel3.png?raw=true"  alt></p></li></ul><p><strong>哨兵机制性能缺点：</strong></p><ul><li><p>1.主从服务器的数据要经常进行主从复制，这样造成性能下降。</p></li><li><p>2.当主服务器宕机后，从服务器切换成主服务器的这段时间，服务是不可用的，实时用户场景不可接受。</p></li></ul><p><strong>博客著作权归本作者所有，任何形式的转载都请联系作者获得授权并注明出处。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis(一)之入门详解</title>
      <link href="/2019-04-28-Redis(%E4%B8%80)%E4%B9%8B%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019-04-28-Redis(%E4%B8%80)%E4%B9%8B%E5%85%A5%E9%97%A8%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Redis简介："><a href="#Redis简介：" class="headerlink" title="Redis简介："></a>Redis简介：</h2><p>Redis是一款开源的、高性能的键-值存储（key-value store）。它常被称作是一款数据结构服务器（data structure server）。</p><p>Redis的键值可以包括字符串（strings）类型，同时它还包括哈希（hashes）、列表（lists）、集合（sets）和 有序集合（sorted sets）等数据类型。 对于这些数据类型，你可以执行原子操作。例如：对字符串进行附加操作（append）；递增哈希中的值；向列表中增加元素；计算集合的交集、并集与差集等。</p><p>为了获得优异的性能，Redis采用了内存中（in-memory）数据集（dataset）的方式。同时，Redis支持数据的持久化，你可以每隔一段时间将数据集转存到磁盘上（snapshot），或者在日志尾部追加每一条操作命令（append only file,aof）。</p><p>Redis同样支持主从复制（master-slave replication），并且具有非常快速的非阻塞首次同步（ non-blocking first synchronization）、网络断开自动重连等功能。同时Redis还具有其它一些特性，其中包括简单的事物支持、发布订阅 （ pub/sub）、管道（pipeline）和虚拟内存（vm）等 。<br>Redis具有丰富的客户端，支持现阶段流行的大多数编程语言</p><h2 id="Redis安装："><a href="#Redis安装：" class="headerlink" title="Redis安装："></a>Redis安装：</h2><p>下载最新稳定版 redis（ <a href="http://redis.io/download" target="_blank" rel="external nofollow noopener noreferrer">http://redis.io/download</a> )<br>tar zxvf redis-5.0.4.tar.gz 解压后的目录如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ls</span><br><span class="line">00-RELEASENOTES  COPYING  Makefile   redis.conf       runtest-sentinel  tests</span><br><span class="line">BUGS             deps     MANIFESTO  runtest          sentinel.conf     utils</span><br><span class="line">CONTRIBUTING     INSTALL  README.md  runtest-cluster  src</span><br></pre></td></tr></table></figure><p>cd src 进入src目录<br>make 编译Redis<br>make test 可以测试一下，最终成功测试结果如下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\o&#x2F; All tests passed without errors!</span><br></pre></td></tr></table></figure><p>make install 安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Hint: It&#39;s a good idea to run &#39;make test&#39; ;)</span><br><span class="line"></span><br><span class="line">    INSTALL install</span><br><span class="line">    INSTALL install</span><br><span class="line">    INSTALL install</span><br><span class="line">    INSTALL install</span><br><span class="line">    INSTALL install</span><br></pre></td></tr></table></figure><p><strong>启动Redis服务端如下</strong>(默认端口号6379)：<br>此时redis已经运行，但要获得好的性能和符合项目特点，还需要对配置文件进行合理的配置,对/etc/redis/redis.conf文件进行修改即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">redis-server </span><br><span class="line">16923:C 27 Apr 21:57:47.289 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server &#x2F;path&#x2F;to&#x2F;redis.conf</span><br><span class="line">16923:M 27 Apr 21:57:47.290 * Increased maximum number of open files to 10032 (it was originally set to 1024).</span><br><span class="line">                _._                                                  </span><br><span class="line">           _.-&#96;&#96;__ &#39;&#39;-._                                             </span><br><span class="line">      _.-&#96;&#96;    &#96;.  &#96;_.  &#39;&#39;-._           Redis 3.0.6 (00000000&#x2F;0) 64 bit</span><br><span class="line">  .-&#96;&#96; .-&#96;&#96;&#96;.  &#96;&#96;&#96;\&#x2F;    _.,_ &#39;&#39;-._                                   </span><br><span class="line"> (    &#39;      ,       .-&#96;  | &#96;,    )     Running in standalone mode</span><br><span class="line"> |&#96;-._&#96;-...-&#96; __...-.&#96;&#96;-._|&#39;&#96; _.-&#39;|     Port: 6379</span><br><span class="line"> |    &#96;-._   &#96;._    &#x2F;     _.-&#39;    |     PID: 16923</span><br><span class="line">  &#96;-._    &#96;-._  &#96;-.&#x2F;  _.-&#39;    _.-&#39;                                   </span><br><span class="line"> |&#96;-._&#96;-._    &#96;-.__.-&#39;    _.-&#39;_.-&#39;|                                  </span><br><span class="line"> |    &#96;-._&#96;-._        _.-&#39;_.-&#39;    |           http:&#x2F;&#x2F;redis.io        </span><br><span class="line">  &#96;-._    &#96;-._&#96;-.__.-&#39;_.-&#39;    _.-&#39;                                   </span><br><span class="line"> |&#96;-._&#96;-._    &#96;-.__.-&#39;    _.-&#39;_.-&#39;|                                  </span><br><span class="line"> |    &#96;-._&#96;-._        _.-&#39;_.-&#39;    |                                  </span><br><span class="line">  &#96;-._    &#96;-._&#96;-.__.-&#39;_.-&#39;    _.-&#39;                                   </span><br><span class="line">      &#96;-._    &#96;-.__.-&#39;    _.-&#39;                                       </span><br><span class="line">          &#96;-._        _.-&#39;                                           </span><br><span class="line">              &#96;-.__.-&#39;</span><br></pre></td></tr></table></figure><p><strong>连接客户端如下</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 6379</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><h2 id="Redis的数据类型："><a href="#Redis的数据类型：" class="headerlink" title="Redis的数据类型："></a>Redis的数据类型：</h2><p><strong>Keys</strong>  非二进制安全的字符类型（ not binary-safe strings ）</p><p><strong>Values</strong> Strings Lists Sets Sorted sets Hash</p><p><strong>String类型</strong>：</p><p>string是redis最基本的类型，而且string类型是二进制安全的。<br>redis的string可以包含任何数据。包括jpg图片或者序列化的对象。<br>最大上限是1G字节。<br>如果只用string类型，redis就可以被看作加上持久化特性的memcached</p><p><strong>String相关命令</strong>：</p><p><strong>set</strong> key value 设置key对应的值为string类型的value,返回1表示成功，0失败</p><p><strong>setnx</strong> key value 同上，如果key已经存在，返回0 。nx 是not exist的意思</p><p><strong>get</strong> key 获取key对应的string值,如果key不存在返回nil</p><p><strong>getset</strong> key value 设置key的值，并返回key的旧值。如果key不存在返回nil</p><p><strong>mget</strong> key1 key2 … keyN 一次获取多个key的值，如果对应key不存在，则对应返回nil。下面是个实验, nonexisting不存在，对应返回nil</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set newKey abd</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; setnx newKey abd</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; get newKey</span><br><span class="line">&quot;abd&quot;</span><br><span class="line">127.0.0.1:6379&gt; mget myKey newKey otherkey</span><br><span class="line">1) &quot;abc&quot;</span><br><span class="line">2) &quot;abd&quot;</span><br><span class="line">3) (nil)</span><br></pre></td></tr></table></figure><p><strong>List类型：</strong><br>redis的list类型其实就是一个每个子元素都是string类型的双向链表。我们可以通过push,pop操作从链表的头部或者尾部添加删除元素。这使得list既可以用作栈，也可以用作队列。<br>list的pop操作还有阻塞版本的。当我们[lr]pop一个list对象时，如果list是空，或者不存在，会立即返回nil。但是阻塞版本的b[lr]pop则可以阻塞，当然可以加超时时间，超时后也会返回nil。为什么要阻塞版本的pop呢，主要是为了避免轮询。举个简单的例子如果我们用list来实现一个工作队列。执行任务的thread可以调用阻塞版本的pop去获取任务这样就可以避免轮询去检查是否有任务存在。当任务来时候工作线程可以立即返回，也可以避免轮询带来的延迟。</p><p><strong>List的相关命令：</strong></p><p><strong>lpush</strong> key string 在key对应list的头部添加字符串元素，返回1表示成功，0表示key存在且不是list类型。</p><p><strong>rpush</strong> key string 同上，在尾部添加。</p><p><strong>llen</strong> key 返回key对应list的长度，key不存在返回0,如果key对应类型不是list返回错误。</p><p><strong>lrange</strong> key start end 返回指定区间内的元素，下标从0开始，负值表示从后面计算，-1表示倒数第一个元素 ，key不存在返回空列表。</p><p><strong>ltrim</strong> key start end  截取list，保留指定区间内元素，成功返回1，key不存在返回错误。</p><p><strong>lset</strong> key index value 设置list中指定下标的元素值，成功返回1，key或者下标不存在返回错误。</p><p><strong>lrem</strong> key count value 从key对应list中删除count个和value相同的元素。count为0时候删除全部。</p><p><strong>lpop</strong> key 从list的头部删除元素，并返回删除元素。如果key对应list不存在或者是空返回nil，如果key对应值不是list返回错误。</p><p><strong>rpop</strong> 同上，但是从尾部删除。</p><p><strong>blpop</strong> key1…keyN timeout 从左到右扫描返回对第一个非空list进行lpop操作并返回，比如blpop list1 list2 list3 0 ,如果list不存在，list2,list3都是非空则对list2做lpop并返回从list2中删除的元素。如果所有的list都是空或不存在，则会阻塞timeout秒，timeout为0表示一直阻塞。当阻塞时，如果有client对key1…keyN中的任意key进行push操作，则第一在这个key上被阻塞的client会立即返回。如果超时发生，则返回nil。</p><p><strong>brpop</strong> 同blpop，一个是从头部删除一个是从尾部删除。</p><p><strong>rpoplpush</strong> srckey destkey 从srckey对应list的尾部移除元素并添加到destkey对应list的头部,最后返回被移除的元素值，整个操作是原子的.如果srckey是空或者不存在返回nil。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lpush myList a</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; llen myList</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; lrange myList 0 -1</span><br><span class="line">1) &quot;b&quot;</span><br><span class="line">2) &quot;a&quot;</span><br><span class="line">127.0.0.1:6379&gt; ltrim myList 0 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; lset myList 0 www</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; lrem myList 3 b</span><br><span class="line">(integer) 3</span><br></pre></td></tr></table></figure><p><strong>Set类型：</strong></p><p>redis的set是string类型的无序集合。<br>set元素最大可以包含(2的32次方-1)个元素。<br>set的是通过hash table实现的，hash table会随着添加或者删除自动的调整大小<br>关于set集合类型除了基本的添加删除操作，其他有用的操作还包含集合的取并集(union)，交集(intersection)，差集(difference)。通过这些操作可以很容易的实现sns中的好友推荐和blog的tag功能。</p><p><strong>Set的相关命令：</strong></p><p><strong>sadd</strong> key member 添加一个string元素到,key对应的set集合中，成功返回1,如果元素以及在集合中返回0,key对应的set不存在返回错误。</p><p><strong>srem</strong> key member 从key对应set中移除给定元素，成功返回1，如果member在集合中不存在或者key不存在返回0，如果key对应的不是set类型的值返回错误。</p><p><strong>spop</strong> key 删除并返回key对应set中随机的一个元素,如果set是空或者key不存在返回nil<br><strong>srandmember</strong> key 同spop，随机取set中的一个元素，但是不删除元素。</p><p><strong>smove</strong> srckey dstkey member 从srckey对应set中移除member并添加到dstkey对应set中，整个操作是原子的。成功返回1,如果member在srckey中不存在返回0，如果key不是set类型返回错误。</p><p><strong>scard</strong> key 返回set的元素个数，如果set是空或者key不存在返回0。</p><p><strong>sismember</strong> key member 判断member是否在set中，存在返回1，0表示不存在或者key不存在。</p><p><strong>sinter</strong> key1 key2…keyN 返回所有给定key的交集。</p><p><strong>sinterstore</strong> dstkey key1…keyN 同sinter，但是会同时将交集存到dstkey下。</p><p><strong>sunion</strong> key1 key2…keyN 返回所有给定key的并集。</p><p><strong>sunionstore</strong> dstkey key1…keyN 同sunion，并同时保存并集到dstkey下。</p><p><strong>sdiff</strong> key1 key2…keyN 返回所有给定key的差集。</p><p><strong>sdiffstore</strong> dstkey key1…keyN 同sdiff，并同时保存差集到dstkey下。</p><p><strong>smembers</strong> key 返回key对应set的所有元素，结果是无序的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sadd newKey hello</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; sadd newKey work</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; sadd newKey word</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; spop newKey</span><br><span class="line">&quot;work&quot;</span><br><span class="line">127.0.0.1:6379&gt; srandmember newKey</span><br><span class="line">&quot;hello&quot;</span><br><span class="line">127.0.0.1:6379&gt; sadd myKey hello</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; smove newKey myKey word</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; scard newKey</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; scard myKey</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; sismember myKey hello </span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; sinter newKey myKey</span><br><span class="line">1) &quot;hello&quot;</span><br><span class="line">127.0.0.1:6379&gt; sunion newKey myKey</span><br><span class="line">1) &quot;hello&quot;</span><br><span class="line">2) &quot;word&quot;</span><br><span class="line">127.0.0.1:6379&gt; sunionstore dstkey newKey myKey</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; sdiff newKey myKey</span><br><span class="line">(empty list or set)</span><br></pre></td></tr></table></figure><p><strong>Sorted Set类型：</strong></p><p>和set一样sorted set也是string类型元素的集合，不同的是每个元素都会关联一个double类型的score。sorted set的实现是skip list和hash table的混合体。当元素被添加到集合中时，一个元素到score的映射被添加到hash table中，另一个score到元素的映射被添加到skip list并按照score排序，所以就可以有序的获取集合中的元素。</p><p><strong>Sorted Set的相关命令：</strong></p><p><strong>zadd</strong> key score member 添加元素到集合，元素在集合中存在则更新对应score。</p><p><strong>zrem</strong> key member 删除指定元素，1表示成功，如果元素不存在返回0。</p><p><strong>zincrby</strong> key incr member 增加对应member的score值，然后移动元素并保持skip list有序。返回更新后的score值。</p><p><strong>zrank</strong> key member 返回指定元素在集合中的排名（下标，非score）,集合中元素是按score从小到大排序的。</p><p><strong>zrevrank</strong> key member 同上,但是集合中元素是按score从大到小排序。</p><p><strong>zrange</strong> key start end 类似lrange操作从集合中取指定区间的元素。返回的是有序结果。</p><p><strong>zrevrange</strong> key start end 同上，返回结果是按score逆序的。</p><p><strong>zrangebyscore</strong> key min max 返回集合中score在给定区间的元素。</p><p><strong>zcount</strong> key min max 返回集合中score在给定区间的数量。</p><p><strong>zcard</strong> key 返回集合中元素个数。</p><p><strong>zscore</strong> key element  返回给定元素对应的score。</p><p><strong>zremrangebyrank</strong> key min max 删除集合中排名在给定区间的元素。</p><p><strong>zremrangebyscore</strong> key min max 删除集合中score在给定区间的元素。</p><p><strong>Hash类型：</strong></p><p>redis hash是一个string类型的field和value的映射表。<br>hash特别适合用于存储对象。相较于将对象的每个字段存成单个string类型。将一个对象存储在hash类型中会占用更少的内存，并且可以更方便的存取整个对象。</p><p><strong>Hash的相关命令：</strong></p><p><strong>hset</strong> key field value 设置hash field为指定值，如果key不存在，则先创建。</p><p><strong>hget</strong> key field  获取指定的hash field。</p><p><strong>hmget</strong> key filed1….fieldN 获取全部指定的hash filed。</p><p><strong>hmset</strong> key filed1 value1 … filedN valueN 同时设置hash的多个field。</p><p><strong>hincrby</strong> key field integer。</p><h3 id="key的相关命令"><a href="#key的相关命令" class="headerlink" title="key的相关命令"></a>key的相关命令</h3><p><strong>set</strong> key value 设置一个新的数据，如果key不存在则创建，如果存在则更新key对应value的值。</p><p><strong>GET</strong> key 获取key对应value的值，如果存在则返回，不存在返回nil。</p><p><strong>exits</strong> key 测试指定key是否存在，返回1表示存在，0不存在。</p><p><strong>del</strong> key1 key2 ….keyN  删除给定key,返回删除key的数目，0表示给定key都不存在。</p><p><strong>type</strong> key 返回给定key的value类型。返回 none 表示不存在，key有string字符类型，list 链表类型 set无序集合类型等…</p><p><strong>keys</strong> pattern 返回匹配指定模式的所有key（支持*，？，[abc ])的方式。</p><p><strong>RANDOMKEY</strong> 返回从当前数据库中随机选择的一个key,如果当前数据库是空的，返回空串。</p><p><strong>RENAME</strong> oldkey newkey 原子的重命名一个key,如果newkey存在，将会被覆盖，返回1表示成功，0失败。失败可能是oldkey不存在或者和newkey相同。</p><p><strong>RENAMENX</strong> oldkey newkey 同上，但是如果newkey存在返回失败。</p><p><strong>DBSIZE</strong> 返回当前数据库的key数量。</p><p><strong>EXPIRE</strong> key seconds 为key指定过期时间，单位是秒。返回1成功，0表示key已经设置过过期时间或者不存在。</p><p><strong>ttl</strong> key 返回设置了过期时间的key的剩余过期秒数， -2表示key不存在或者没有设置过过期时间。</p><p><strong>SELECT</strong> db-index 通过索引选择数据库，默认连接的数据库索引是0,默认数据库数是16个。返回1表示成功，0失败。</p><p><strong>MOVE</strong> key db-index  将key从当前数据库移动到指定数据库。返回1成功。0 如果key不存在，或者已经在指定数据库中。</p><p><strong>FLUSHDB</strong> 删除当前数据库中所有key,此方法不会失败。慎用。</p><p><strong>FLUSHALL</strong> 删除所有数据库中的所有key，此方法不会失败。更加慎用。</p><p><strong>示例如下：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set newKey abc</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; EXISTS newKey</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; type newKey</span><br><span class="line">string</span><br><span class="line">127.0.0.1:6379&gt; KEYS new*</span><br><span class="line">1) &quot;newKey&quot;</span><br><span class="line">127.0.0.1:6379&gt; del newKey</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; RANDOMKEY</span><br><span class="line">(nil)</span><br><span class="line">127.0.0.1:6379&gt; RENAME newKey myKey</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; DBSIZE</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; EXPIRE myKey 10</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ttl myKey</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; FLUSHDB</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; FLUSHALL</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><h2 id="Redis功能："><a href="#Redis功能：" class="headerlink" title="Redis功能："></a>Redis功能：</h2><h3 id="持久化："><a href="#持久化：" class="headerlink" title="持久化："></a>持久化：</h3><p>redis是一个支持持久化的内存数据库，也就是说redis需要经常将内存中的数据同步到磁盘来保证持久化，这是相对memcache来说的一个大的优势。redis支持两种持久化方式，一种是 Snapshotting（快照）也是默认方式，另一种是Append-only file（缩写aof）的方式。 </p><ul><li><strong>Snapshotting</strong></li></ul><p><strong>快照</strong>是默认的持久化方式。这种方式将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。可以配置自动做快照持久 化的方式。我们可以配置redis在n秒内如果超过m个key被修改就自动做快照，下面是默认的快照保存配置。<br>save 900 1  #900秒内如果超过1个key被修改，则发起快照保存<br>save 300 10 #300秒内容如超过10个key被修改，则发起快照保存</p><ul><li><strong>Append-only file</strong></li></ul><p><strong>aof</strong>比快照方式有更好的持久化性，是由于在使用aof持久化方式时,redis会将每一个收到的写命令都通过write函数追加到文件中(默认是 appendonly.aof)。当redis重启时会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。当然由于os会在内核中缓存 write做的修改，所以可能不是立即写到磁盘上。这样aof方式的持久化也还是有可能会丢失部分修改。不过我们可以通过配置文件告诉redis我们想要 通过fsync函数强制os写入到磁盘的时机。</p><p>有三种方式如下（默认是：每秒fsync一次）</p><p>appendonly yes                //启用aof持久化方式</p><p>appendfsync always      //每次收到写命令就立即强制写入磁盘，最慢的，但是保证完全的持久化，不推荐使用</p><p>appendfsync everysec      //每秒钟强制写入磁盘一次，在性能和持久化方面做了很好的折中，推荐</p><p>appendfsync no          //完全依赖os，性能最好,持久化没保证</p><h3 id="主从复制："><a href="#主从复制：" class="headerlink" title="主从复制："></a>主从复制：</h3><p>主从复制允许多个slave server拥有和master server相同的数据库副本。下面是关于redis主从复制的一些特点</p><ul><li>1.master可以有多个slave</li><li>2.除了多个slave连到相同的master外，slave也可以连接其他slave形成图状结构</li><li>3.主从复制不会阻塞master。也就是说当一个或多个slave与master进行初次同步数据时，master可以继续处理client发来的请求。相反slave在初次同步数据时则会阻塞，不能处理client的请求。</li><li>4.主从复制可以用来提高系统的可伸缩性（我们可以用多个slave 专门用于client的读请求，比如sort操作可以使用slave来处理），也可以用来做简单的数据冗余。</li><li>5.可以在master禁用数据持久化，只需要注释掉master 配置文件中的所有save配置，然后只在slave上配置数据持久化。</li></ul><h3 id="事务："><a href="#事务：" class="headerlink" title="事务："></a>事务：</h3><p>redis对事务的支持目前还比较简单。redis只能保证一个client发起的事务中的命令可以连续的执行，而中间不会插入其他client的命令。<br><strong>Multi</strong> 事物开始<br><strong>Exec</strong> 执行事务<br><strong>Discard</strong> 放弃事物<br><strong>Watch</strong> 监听key<br><strong>Unwatch</strong> 放弃所有key的监听<br><strong>watch</strong> 命令会监视给定的key,当exec时候如果监视的key从调用watch后发生过变化，则整个事务会失败。注意watch的key是对整个连接有效的，和事务一样，如果连接断开，监视和事务都会被自动清除</p><h3 id="发布订阅："><a href="#发布订阅：" class="headerlink" title="发布订阅："></a>发布订阅：</h3><p>发布订阅(pub/sub)是一种消息通信模式。订阅者可以通过subscribe和psubscribe命令向redis server订阅自己感兴趣的消息类型，redis将消息类型称为通道(channel)。当发布者通过publish命令向redis server发送特定类型的消息时。订阅该消息类型的全部client都会收到此消息。这里消息的传递是多对多的。一个client可以订阅多个 channel,也可以向多个channel发送消息。<br><strong>Subscribe</strong><br><strong>Unsubscribe</strong><br><strong>Psubscribe</strong><br><strong>Punsubscribe</strong><br><strong>Publish</strong></p><h3 id="管道："><a href="#管道：" class="headerlink" title="管道："></a>管道：</h3><p>redis是一个cs模式的tcp server，使用和http类似的请求响应协议。一个client可以通过一个socket连接发起多个请求命令。每个请求命令发出后client通常 会阻塞并等待redis服务处理，redis处理完后请求命令后会将结果通过响应报文返回给client。</p><h3 id="虚拟内存："><a href="#虚拟内存：" class="headerlink" title="虚拟内存："></a>虚拟内存：</h3><p>redis没有使用os提供的虚拟内存机制而是自己实现了自己的虚拟内存机制 ，但是思路和目的都是相同的。就是暂时把不经常访问的数据从内存交换到磁盘中，从而腾出内存空间用于其他需要访问的数据。尤其是对于redis这样的内存数据库，内存总是不够用的。除了可以将数据分割到多个redis server外。另外的能够提高数据库容量的办法就是使用vm把那些不经常访问的数据交换的磁盘上。如果我们的存储的数据总是有少部分数据被经常访问，大 部分数据很少被访问，对于网站来说确实总是只有少量用户经常活跃。当少量数据被经常访问时，使用vm不但能提高单台redis server数据库的容量，而且也不会对性能造成太多影响。<br>vm-enabled yes                             #开启vm功能<br>vm-swap-file /tmp/redis.swap         #交换的value保存的文件路径/tmp/redis.swap<br>vm-max-memory 1000000            #最大内存上限，超过后开始交换value到磁盘文件<br>vm-page-size 32                          #每个页面的大小32个字节<br>vm-pages 134217728                 #最多使用在文件中使用多少页面<br>vm-max-threads 4                    #用于执行value对象换入换出的工作线程数量，0表示不使用工作线程</p><h3 id="Redis应用场景："><a href="#Redis应用场景：" class="headerlink" title="Redis应用场景："></a>Redis应用场景：</h3><ul><li><strong>1.排行榜应用，取TOP N操作</strong></li></ul><p>这个是以某个条件为权重，比如按顶的次数排序，这时候就需要我们的sorted set出马了，将你要排序的值设置成sorted set的score，将具体的数据设置成相应的value，每次只需要执行一条ZADD命令即可。</p><ul><li><strong>2.需要精准设定过期时间的应用</strong></li></ul><p>比如你可以把上面说到的sorted set的score值设置成过期时间的时间戳，那么就可以简单地通过过期时间排序，定时清除过期数据了，不仅是清除Redis中的过期数据，你完全可以把Redis里这个过期时间当成是对数据库中数据的索引，用Redis来找出哪些数据需要过期删除，然后再精准地从数据库中删除相应的记录。</p><ul><li><strong>3.计数器应用</strong></li></ul><p>Redis的命令都是原子性的，你可以轻松地利用INCR，DECR命令来构建计数器系统。</p><ul><li><strong>5.Uniq操作，获取某段时间所有数据排重值</strong></li></ul><p>这个使用Redis的set数据结构最合适了，只需要不断地将数据往set中扔就行了，set意为集合，所以会自动排重。</p><ul><li><strong>5.实时系统，反垃圾系统</strong></li></ul><p>通过上面说到的set功能，你可以知道一个终端用户是否进行了某个操作，可以找到其操作的集合并进行分析统计对比等。没有做不到，只有想不到。</p><ul><li><strong>6.Pub/Sub构建实时消息系统</strong></li></ul><p>Redis的Pub/Sub系统可以构建实时的消息系统，比如很多用Pub/Sub构建的实时聊天系统的例子。</p><ul><li><strong>7.构建队列系统</strong></li></ul><p>使用list可以构建队列系统，使用sorted set甚至可以构建有优先级的队列系统。</p><ul><li><strong>8.缓存</strong></li></ul><p>缓存不多做解释，性能优于Memcached（在某些方面，并不是全面优于），数据结构更多样化。</p><p><strong>博客著作权归本作者所有，任何形式的转载都请联系作者获得授权并注明出处。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统技术概要</title>
      <link href="/2019-04-18-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%8B%E7%BB%8D/"/>
      <url>/2019-04-18-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="分布式系统技术概要"><a href="#分布式系统技术概要" class="headerlink" title="分布式系统技术概要"></a>分布式系统技术概要</h1><p>现在互联网应用，尤其是大型互联网公司的应用已经发展为大规模或超大规模的分布式的，集群化的应用。而中小规模的分布式应用也已广泛出现在各个领域。未来，随着云计算向社会生活的方方面面去渗透，分布式应用将更加地普及。所以，任何一个要从事服务器端应用开发的人员，都有具备对分布式应用的基本认识。<br>本文将简要介绍分布式应用的各基本领域的相关技术。这些技术在一个分布式应用中都会有或多或少的设计，即便暂时没有涉及到，设计人员也要有所考虑，保证系统有进一步发展的空间。<br><img src="/img/loading.gif" class="lazyload" data-src="img/fenbushi.jpeg"  alt></p><h2 id="1-集群管理"><a href="#1-集群管理" class="headerlink" title="1 集群管理"></a>1 集群管理</h2><p> 在一个分布式系统中，存在着一些和系统运行，以及重要业务紧密相关的数据，如节点相关的数据、应用服务和数据服务相关的数据等，这些数据对集群的正常运行至关重要。</p><ul><li><strong>服务器节点相关数据：</strong>服务器的地址、状态</li><li><strong>服务相关数据：</strong>服务的IP、端口、版本、协议、状态、主备节点信息</li><li><strong>数据库相关数据：</strong>路由规则、分库分表规则</li></ul><p>这些重要的数据在分布式系统中存在着多份拷贝，以保证高可用性。但这产生了另外一个问题，就是如何保证这些数据的一致性。因为这些数据是如此重要，不一致的数据会产生严重甚至致命的错误。在一个小规模的分布式系统中，因为可以用一两台服务器去做集群管理，所以数据的一致性容易实现。但是对于一个大规模的分布式系统，一两台集群配置管理服务器无法支撑整个集群所带来的大量并发读写操作，所以要使用几台、十几台，甚至更多的服务器去支撑这些请求。此时，就需要一个保持这些服务器中集群配置数据的一致性的方案了。</p><p> 这众多方案中，Paxos 算法算是最佳方案之一。关于 Paxos 算法的内容，不在这里详述了。简单描述就是集群中各节点相互以提议的方式通信（对一项数据的修改），提议中带有不断增加的 ID 号，节点永远同意当前 ID 号最大的提议，并拒绝其它提议。当有半数以上节点同意一项提议之后，这个提议便被整个节点所接受并采纳</p><h2 id="2-远程调用"><a href="#2-远程调用" class="headerlink" title="2 远程调用"></a>2 远程调用</h2><p> 分布式系统中，模块间的调用通常需要用远程调用来实现。而且随着微服务架构模式的流行，使用远程调用的比例会越来越高。其实远程调用这种方式很早以前就出现了，早年的技术有诸如 COBRA、EJB、SOAP 等，但这些技术存在着用法复杂、性能差等缺点。这些缺点限制着远程调用的普及。这些年，随着异步 IO 技术、序列化技术的发展进步，以及像 Zookeeper 这样的集群管理服务的出现普及，妨碍远程调用普及的技术障碍逐渐被打破。</p><p> 使用 HTTP + JSON 的方式同样可以实现模块之间的远程调用，但这种方式通常用来实现 Public API。在系统内部，远程调用要求更快的速度，更小的延迟，还有还有异步调用的需求，所以 HTTP + JSON 通常无法满足这样的要求。远程调用有两个重要的技术点，一个是 IO 技术、一个是序列化技术。另外，远程调用还引出来另两个问题：1. 服务注册、发现、路由的问题。这个问题的需要结合例如 Zookeeper 服务去解决；2. 如何简化远程调用的使用，使其如同本地调用一样简单。这个问题需要结合 AOP 之类的技术。这两个问题的具体解决不在本节讨论范围之内。</p><h3 id="2-1-IO"><a href="#2-1-IO" class="headerlink" title="2.1. IO"></a>2.1. IO</h3><p>(这里只说 Socket IO）常见的 IO 模型有阻塞 IO、非阻塞 IO 和异步 IO。阻塞 IO 指的是如果一个线程要在 Socket 连接上进行某种 IO 操作时（读或写数据），当没有操作不可执行时（没有数据可读或无法写数据），执行操作的线程便会被挂起，操作便会被阻塞，直到操作可以执行。这种方式的好处是业务代码编写起来很简单，缺点是资源利用率不高。因为一个连接必须有一个线程去处理。当有大量连接时，便会消耗大量的线程。这个缺点放在服务器端开发领域就显得非常严重了。</p><p>非阻塞 IO 实现了线程的多路复用，一个线程被用来可以处理多个连接；异步 IO 则是由操作系统来实现 IO 的读写操作。在数据 ready 之后，通知业务线程处理。</p><p>上面只是对阻塞 IO 和非阻塞 IO 的一个笼统的介绍。从具体的技术来看，Linux 通过 epoll 技术提供了对非阻塞 IO 的支持。epoll 是 Linux 内核的一个系统调用，最早在 2.5.44 版中被加入。epoll 的意思是 event poll。简单来说就是当有一个 IO 事件发生时，Linux 内核便会通知用户。使用方式是在创建 epoll 句柄之后，用户在其上不断地循环以获取新的事件（当有事件发生时）。这些事件是来自多个连接的，从而实现了线程的多路复用。<br>在 Java 1.4 中，也引入了 NIO 的支持 (java.nio.*)。在 Java NIO API 中，用户的程序可以将一个连接 (SelectableChannel.register(Selector sel, int ops)) 注册到一个 Selector 上（一个 Selector 可以有多个连接注册）。注册之后，用户的程序便可以通过不断地循环调用 Selector.selectedKeys() 方法获得这个连接上的事件并进行处理（通常会使用另外的线程去处理事件，即 Reactor 模型）</p><p>虽然 Java 为 NIO 开发提供了良好的 API 支持（从 1.7 开始还支持了 AIO），但是 IO 开发依旧有很高的复杂性，且 Java NIO 类库的是 JDK 中 bug 较多的部分。故不推荐普通开发者直接基于 JDK 开发网络 IO 功能，而是建议使用 Netty 进行开发。关于 Netty 这里就不做介绍了</p><h3 id="2-2序列化技术"><a href="#2-2序列化技术" class="headerlink" title="2.2序列化技术"></a>2.2序列化技术</h3><p>序列化技术是远程调用的通信协议中的重要一部分，它定义了编程语言中的数据结构和数据传输协议中的数据结构之间如何相互转化。序列化技术的性能的好坏会影响到对远程调用性能的好坏在序列化方面。序列化技术性能的好坏主要包含两方面的含义：一个是序列化时占用的资源（CPU、内存、所需时间）；另一个是序列化之后数据的大小。SOAP WebService 和 REST WebService 通常会把数据序列化成 XML 格式或者 JSON 格式。这两种格式因为都是文本格式，所以有着良好的可读性，但是对于需要频繁使用的远程调用来说，它们的体积偏大。所以边有了性能更好的序列化解决方案，被大家所熟知的有 Protocol Buffers 和 Apache Arvo。此外，Apache Thrift 的序列化的性能也很好，但是 Thrift 无法被当做一个单独的序列化技术被使用，而是一个完整的远程调用解决方案。其序列化部分不太容易被剥离出来，没有完整的 API 被开放使用。这里列出了常见的序列化技术的性能比较。</p><h2 id="消息中间件"><a href="#消息中间件" class="headerlink" title="消息中间件"></a>消息中间件</h2><h3 id="Apache-Kafka"><a href="#Apache-Kafka" class="headerlink" title="Apache Kafka"></a>Apache Kafka</h3><p>Apache Kafka 充分利用了机械磁盘顺序读写速度快的特点，在接受消息之后同步地写入到磁盘中，保证数据可靠性的同时，也保证了非常快的速度。每个 Kafka 集群上都有多个 Topic，Topic 相当于一个 category，消费者可以订阅一个或多个 Topic。每个 Topic 由多个 Partition 组成。消息被顺序的添加到 Partition 中，每条消息有一个唯一的、有序的 ID，这个 ID 被称为 Offset。Consumer 需要维护自己消费到的消息的位置 (Offset)。</p><p>Apache Kafka 不同于传统的消息中间件，它采用“拉”消息模式，而不是传统的“推”消息模式。即客户端需要主动从消息中间件获取消息，好处是客户端可以更好地控制请求量。</p><h4 id="Queue-模式和-Topic-模式"><a href="#Queue-模式和-Topic-模式" class="headerlink" title="Queue 模式和 Topic 模式"></a>Queue 模式和 Topic 模式</h4><p>传统消息队列服务中有队列模式和发布订阅模式两种模式，前者一条消息只会被一个消费者消费；后者一条消息会发布给所有的订阅这个 Topic 的消费者。在 Kafka 中，这两种模式是使用一种方式 —— 消费者组来实现的。在同一个消费者组中的不同消费者不会受到相同的消息。如果想实现发布订阅模式，消费者必须处于不同的消费者组中。</p><h4 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h4><p>RabbitMQ 是一个使用 Erlang 开发的 AMQP (Advanced Message Queue Protocol) 实现。现在 RabbitMQ 是由 VMware 旗下的 SpringSource 负责开发。AMQP 是一个语言无关的消息队列协议。在 RabbitMQ 中，有三个概念：Exchange、Queue 和 Route key。Exchange 用来标示生产者，Queue 用来标示消费者，而 Route key 用来关联这两者。RabbitMQ 中这种方式提供了更灵活的应用模式。</p><h2 id="分布式文件系统"><a href="#分布式文件系统" class="headerlink" title="分布式文件系统"></a>分布式文件系统</h2><h3 id="块存储与对象存储"><a href="#块存储与对象存储" class="headerlink" title="块存储与对象存储"></a>块存储与对象存储</h3><p>块存储是将一块裸盘提供给客户使用，但是这块裸盘可能是来自一块物理硬盘，也有可能是多块，或是来自不同服务器上的硬盘。对象存储提供了更高级的接口，通过这些接口可以读写文件以及相关的元数据。其中的元数据包含了文件每一个块的存储信息。通过文件元数据，文件可以被并行地操作。</p><h3 id="分布式文件系统的高可用"><a href="#分布式文件系统的高可用" class="headerlink" title="分布式文件系统的高可用"></a>分布式文件系统的高可用</h3><p>为了保证数据的安全，分布式文件系统通常会将文件复制为三份。这三份数据会位于不同的服务器上，对应要求更高的系统，比如公有云存储。其中的一份数据会放置在另一个机房中，以保证即便整个机房出现故障，整个文件系统仍是可用的。</p><h2 id="分布式数据库"><a href="#分布式数据库" class="headerlink" title="分布式数据库"></a>分布式数据库</h2><h3 id="关系型数据库"><a href="#关系型数据库" class="headerlink" title="关系型数据库"></a>关系型数据库</h3><p>在大规模的分布式应用中，单库或者简单的读写分离已经无法满足要求，因此必须对数据库进行水平和垂直的划分和分库分表。在对数据库进行分库分表之后，应用对数据库的访问便不再是一件简单的事情了。应用在进行一次数据库操作时，其所对应的数据库的地址和表名必须通过某种逻辑运算才能得到。例如，ID从1到1,000,000的User数据是数据库1的User_1表中，ID从1,000,001到2,000,000的User数据在数据库1的User_2表中，而其它的User数据又会在不同的数据库的不同的表中。同时，还要考虑主从数据库，读写分离的问题。这样的数据库使用方式会使数据操作变得极为复杂，也会增加数据迁移，增容扩容时的难度。</p><p>对于这样复杂的问题，靠应用自己解决显然是不合适的。所以各家分布式应用的使用大户——互联网厂商，都自己实现了相应的解决方案。这些解决方案可分为中间间方式和框架方式，前者作为数据库访问的代理，使得分布式的数据库对应用是透明的。后者作为一个框架嵌入到应用中，也能起到类似的作用。这两种方式各有优劣，分别适合不同的场合。</p><h3 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h3><p>大部分 NoSQL 虽然对分布式的支持是友好的，但这并不意味着使用这些 NoSQL 数据库就可以轻轻松松地实现一个集群。例如著名的 Key/Value 数据库 Redis。它 3.0 之前一直没有官方的集群方案，所以各个大规模使用 Redis 都需要自己实现分布式方案，例如 Twitter 的 Twemproxy、豌豆荚的 Codis 等等。</p><p><strong>博客著作权归本作者所有，任何形式的转载都请联系作者获得授权并注明出处。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「体能训练理论」之金字塔</title>
      <link href="/2017-07-10-%E3%80%8C%E4%BD%93%E8%83%BD%E8%AE%AD%E7%BB%83%E7%90%86%E8%AE%BA%E3%80%8D%E4%B9%8B%E9%87%91%E5%AD%97%E5%A1%94/"/>
      <url>/2017-07-10-%E3%80%8C%E4%BD%93%E8%83%BD%E8%AE%AD%E7%BB%83%E7%90%86%E8%AE%BA%E3%80%8D%E4%B9%8B%E9%87%91%E5%AD%97%E5%A1%94/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>体能，人体基础运动能力的统称，人体的本质属性，它支撑着日常生活工作的需要，也支撑着运动技战术的表现。 体能思路，是指导我们设计实施体能训练的思维方式，分析逻辑。它包括回归原点的 <strong>五大运动素质</strong> &amp; <a href="http://qiubaiying.top/2017/07/10/%E4%BD%93%E8%83%BD%E8%AE%AD%E7%BB%83%E7%90%86%E8%AE%BA-%E4%B9%8B%E5%8A%A8%E5%8A%9B%E9%93%BE/" target="_blank" rel="external nofollow noopener noreferrer"><strong>动力链理论</strong></a>，也包括在过程中引领方向的 <a href="http://qiubaiying.top/2017/07/10/%E4%BD%93%E8%83%BD%E8%AE%AD%E7%BB%83%E7%90%86%E8%AE%BA-%E4%B9%8B%E5%8A%9F%E8%83%BD%E6%80%A7/" target="_blank" rel="external nofollow noopener noreferrer"><strong>功能性原则</strong></a> 和 <a href="http://qiubaiying.top/2017/07/10/%E4%BD%93%E8%83%BD%E8%AE%AD%E7%BB%83%E7%90%86%E8%AE%BA-%E4%B9%8B%E9%87%91%E5%AD%97%E5%A1%94/" target="_blank" rel="external nofollow noopener noreferrer"><strong>金字塔</strong></a> 。</p><h2 id="金字塔"><a href="#金字塔" class="headerlink" title="金字塔"></a>金字塔</h2><p>体能训练是一门实践科学，实践先于理论，而理论印证实践。体能训练有四大基础学科，分别是运动解剖学、运动生理学、运动生物力学和运动训练学。</p><p>五大运动素质对应生理学和运动训练学；动力链对应解剖学和运动生物力学；功能性对应着生理和生物力。而金字塔则对应了它们全部！或者说金字塔其实是诸学科在体能训练中的交汇，它囊括了所有之前的理论，并且赋予了更深层的意义。</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws4.sinaimg.cn/large/006tKfTcgy1fhg20ydk8uj30go0brwh1.jpg"  alt></p><p>金字塔代表了人体运动能力发展的客观规律，它是一个流程的引领，思维的分级，以及训练阶段的划分。</p><p>这里包括 <strong>关节功能+核心控制</strong>、<strong>基础动作模式</strong>、<strong>基础力量</strong>、<strong>综合体能</strong>、<strong>专项运动</strong>。他们在逻辑上互为基础和进阶，关节是动作的基础，动作承载力量，力量支撑各个运动素质，而专项是各个运动素质在具体运动中的表现。</p><p>也许这么说可能不能够让大家有清晰的认识，那么接下来我就把每层的内容和它们之间的逻辑关系简单的跟大家分享一下。 99%的运动者都是基础不足，上层过度。我们从基础开始，从下往上说起。</p><h3 id="运动基础（关节功能-核心控制）"><a href="#运动基础（关节功能-核心控制）" class="headerlink" title="运动基础（关节功能 + 核心控制）"></a>运动基础（关节功能 + 核心控制）</h3><p>运动基础主要内容包括 <strong>关节功能</strong> 和 <strong>核心控制</strong> 能力。</p><p>人体的关节功能有两个属性，一个是灵活性，一个是稳定性。举例来说，很多人由于长期缺乏锻炼，肩关节灵活性缺失，第一次学习竖直上举时，怎么努力都举不到头顶，显然应该先改善肩关节灵活性。再比如，膝关节的结构导致它只能进行屈伸的运动，所以我们要保证运动过程中不出现膝内扣，膝外翻的现象，也就是膝关节需要具备的稳定能力。在健身之前我们，应该先评估我们的关节功能。</p><p>运动基础中的第二部分内容就是核心控制能力。很多健身者入门者都会觉得核心是腹肌，觉得练核心的目的是拥有一个好看的腹肌。实际上，腹肌只是核心的一部分，核心是指一个区域，我们的整个躯干都属于核心区域。</p><p>运动的外在表现虽来源于四肢，比如跑步时你的四肢在运动，但是一个出色的外在运动表现是建立在稳定的核心基础之上的。如果躯干不稳定，在跑步的过程中整个脊柱很松散，甩来甩去，这样是很难提高跑步速度的。所以在学习动作之前，应该先加强核心控制能力。</p><p>所以我们会推荐没有进行过抗阻训练、长期久坐的同学先去练习一段时间的瑜伽和普拉提，瑜伽可以很好地改善关节灵活性，进而提高身体的柔韧性；而普拉提能提高的核心控制能力，并提高关节稳定性。<br>一个合格的健身训练者，应该了解不同的训练体系，他要知道自身还缺乏什么，然后向不同的训练体系去借鉴，以提高自己。</p><h3 id="基础动作模式"><a href="#基础动作模式" class="headerlink" title="基础动作模式"></a>基础动作模式</h3><h4 id="什么是基础动作模式？"><a href="#什么是基础动作模式？" class="headerlink" title="什么是基础动作模式？"></a>什么是基础动作模式？</h4><p>简单地说就是，所有动作肢体特有的运动程序。人体就这么些零件，所以很多的动作之间都存在着些许的共性，我们将这些共性提炼出来并进行功能上的抽象，那么就形成了我们现在所要说的基础动作模式——<strong>双腿蹲</strong>、<strong>单腿蹲</strong>、<strong>推</strong>、<strong>拉</strong>、<strong>旋转</strong>、<strong>屈髋</strong>。</p><ul><li><strong>蹲</strong>：分为单腿蹲、双腿蹲。对应的训练动作有剪蹲和深蹲。</li><li><strong>推</strong>：分为水平推、竖直推。对应的训练动作是卧推和实力举。</li><li><strong>拉</strong>：分为竖直拉、水平拉。竖直拉包括引体向上、高位下拉，水平拉包括弹力带划船等等。</li><li><strong>屈髋</strong>：最具代表性的动作就是硬拉。</li><li><strong>旋转</strong>：动作比较复杂，在训练当中比较少出现，适合比较资深的训练者，比如说劈和砍，比如下劈球，比如拿锤子砸轮胎。前期不建议做，当你有一定训练水平的时候再去做旋转类动作。</li></ul><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws4.sinaimg.cn/large/006tKfTcgy1fhg20yeticj30go0ptdmg.jpg"  alt></p><h4 id="基础动作模式的意义是什么？"><a href="#基础动作模式的意义是什么？" class="headerlink" title="基础动作模式的意义是什么？"></a>基础动作模式的意义是什么？</h4><ol><li>教会我们如何正确的使用我们的身体</li><li>评估你的是否存在关节功能缺陷</li></ol><p>基于基础动作模式的学习意义和诊断意义，我们对待健身者或者需要进行体能训练的人很多时候都从这里开始。如果诊断结果良好，那么我们学习动作之后就可以上升到基础力量训练，如果诊断出关节功能缺陷，我们就要进行针对性的解决。</p><h3 id="基础力量（肌肉力量）"><a href="#基础力量（肌肉力量）" class="headerlink" title="基础力量（肌肉力量）"></a>基础力量（肌肉力量）</h3><p>力量是所有运动素质的基础，如果你没有足够的力量，很多事情都很难完成。你想学习倒立，如果上肢力量足够，只需要了解动作技巧和细节，可能半个小时就能学会倒立。但是如果力量水平很低，就算把各种技巧和细节都学会了，也没有力气把自身撑起来，更不可能完成倒立。日常生活中，力量水平不足经常会成为我们突破运动瓶颈的障碍，有足够的力量才能跑得更快、跑得更远、跳得更高。所以，力量是所有运动素质的基础。</p><p>因此，在金字塔的这层，我们就要从徒手训练的阶段进阶到自由力量训练的阶段。负重和徒手的训练效果差异非常大，它不仅仅在于力量的提高，在重心控制、身体平衡、协调性控制等方面的区别也很大。力量训练能让身体各项能力同时提高，只有真正进入力量训练阶段（对于健身来说），才可以说真正踏上健身入门之路。</p><h3 id="训练目标（综合体能和专项体能）"><a href="#训练目标（综合体能和专项体能）" class="headerlink" title="训练目标（综合体能和专项体能）"></a>训练目标（综合体能和专项体能）</h3><p>最后，我们来到了金字塔的顶端，这就是我们的最终追求。</p><p>综合体能在此指的是体能所包含的五大运动素质——力量，速度，灵敏，耐力，柔韧。对于有专项运动需求的人，我们需要有针对性的重点发展这五大运功素质中的某几个。</p><p>当我们身体各关节灵活性和稳定性都可以满足要求，且核心控制能力也很强的情况下，又在标准动作的基础上储备了足够的肌肉力量，那么，不管你的目标是减肥，增肌，或者是进行某一个竞技性运动项目，你都可以相对安全且轻松地达成你的目标。</p><p>一般我们把还处在第一第二层的健身者称为健身入门者。不管你是刚刚走进健身房的新手，还是健身多年的老司机，都可以根据这个健身发展流程来审视自己目前的训练处在哪一个阶段。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>体能训练金字塔告诉我们，体能训练要从关节功能和核心控制开始训练，通过六大基础运动模式的训练增强身体基础力量，只有基础力量够了，我们才能真正开始我们的训练目标，根据我们训练的项目增强专项体能，比如拳击，我们要增强力量，耐力，灵敏。</p><p>清楚了这个体能训练金字塔之后，更重要的事还是要去执行。执行层面会涉及更多技术问题，也就是我们常说的如何做标准的动作，如何制定适合自己的训练计划等等。</p><p>健身是一项系统性工程，愿每一个人都能找到方法，科学有效地塑造自己的身体。</p><blockquote><p>参考 </p></blockquote><blockquote><ul><li><a href="https://zhuanlan.zhihu.com/p/20801623" target="_blank" rel="external nofollow noopener noreferrer">《体能训练之金字塔》</a></li><li><a href="http://www.jianshenjiaolian.com.cn/lingjichu-fazhan.html" target="_blank" rel="external nofollow noopener noreferrer">零基础健身者的运动发展流程</a></li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生活 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「体能训练理论」之动力链</title>
      <link href="/2017-07-10-%E3%80%8C%E4%BD%93%E8%83%BD%E8%AE%AD%E7%BB%83%E7%90%86%E8%AE%BA%E3%80%8D%E4%B9%8B%E5%8A%A8%E5%8A%9B%E9%93%BE/"/>
      <url>/2017-07-10-%E3%80%8C%E4%BD%93%E8%83%BD%E8%AE%AD%E7%BB%83%E7%90%86%E8%AE%BA%E3%80%8D%E4%B9%8B%E5%8A%A8%E5%8A%9B%E9%93%BE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>与其说体能训练是一种行为，不如说体能训练是一种程序。只要符合逻辑，就可以自由组合。<br> 那么体能训练的逻辑是什么？我们将之总结为：<a href="http://qiubaiying.top/2017/07/10/%E4%BD%93%E8%83%BD%E8%AE%AD%E7%BB%83%E7%90%86%E8%AE%BA-%E4%B9%8B%E5%8A%A8%E5%8A%9B%E9%93%BE/" target="_blank" rel="external nofollow noopener noreferrer"><strong>动力链</strong></a>、<a href="http://qiubaiying.top/2017/07/10/%E4%BD%93%E8%83%BD%E8%AE%AD%E7%BB%83%E7%90%86%E8%AE%BA-%E4%B9%8B%E5%8A%9F%E8%83%BD%E6%80%A7/" target="_blank" rel="external nofollow noopener noreferrer"><strong>功能性</strong></a>、<a href="http://qiubaiying.top/2017/07/10/%E4%BD%93%E8%83%BD%E8%AE%AD%E7%BB%83%E7%90%86%E8%AE%BA-%E4%B9%8B%E9%87%91%E5%AD%97%E5%A1%94/" target="_blank" rel="external nofollow noopener noreferrer"><strong>金字塔</strong></a>。</p><h2 id="动力链"><a href="#动力链" class="headerlink" title="动力链"></a>动力链</h2><p>如果说 <strong>五大运动素质</strong>（力量、速度、耐力、灵敏、柔韧）代表了体能的宏观表现，那么动力链理论则阐释了人体解剖结构在运动中的客观规律，这二者同为人体的本质属性。</p><p>动力链这一理论早在1875年就被提出过，当时的定义还很简单，就是指几个相邻的关节所组成的复杂动作单元。后来在不断地实践与研究中，动力链理论也不断的升级，越来越清晰，越来越客观，也越来越复杂，并且逐渐成为了体能训练师们必备的思考工具之一。</p><p>来看看动力链的英文解释:</p><blockquote><p>The concept of the kinetic chain originated in 1875, when a mechanical engineer named Franz Reuleaux proposed that if a series of overlapping segments were connected via pin joints, these interlocking joints would create a system that would allow the movement of one joint to affect the movement of another joint within the kinetic link. Dr. Arthur Steindler adapted this theory in 1955, and included an analysis of human movement. Steindler suggested that the extremities be viewed as a series of rigid, overlapping segments and defined the kinetic chain as a “combination of several successively arranged joints constituting a complex motor unit.” The movements that occur within these segments present as two primary types—open and closed.</p></blockquote><p>这种模糊形容根本无法让人们理解它真正的内核，虽然它看起来就像是一堆联动的齿轮和杠杆。实际上它也真的很像一堆齿轮和杠杆，有的负责驱动，有的负责传力，有的负责稳定。</p><p>为了方便大家理解，下面我要将这个理论拆解开来跟大家分享。</p><p>首先，我们需要从以上的定义中提炼出来一些关键词，比如说 “运动”、“几个”、“相邻”等等。那么这几个词分别代表了什么？</p><ol><li>我们讨论问题的角度是<strong>运动</strong>的；</li><li>我们需要考虑的<strong>人体解剖结构</strong>问题；</li><li>我们需要考虑相邻关节的<strong>协作关系</strong>；</li><li>我们需要分析每一个关节的<strong>使用特点</strong>。</li></ol><p>所以，它似乎并不能被完美的定义，而是只可意会不可言传。<br> 那么关于动力链，我们需要掌握两个最基本的知识：<strong>动力链模型</strong>、<strong>开链与闭链</strong>。</p><h3 id="动力链模型"><a href="#动力链模型" class="headerlink" title="动力链模型"></a>动力链模型</h3><p>在动力链理论中，我们考虑运动的最小单位是<strong>关节</strong>，诸多关节运动的协作产生了整体上的复杂动作。所以每一个关节的功能就决定了整体动作的表现，任何一个关节功能受限都会导致整体动作的失衡。 </p><p>而我们所指的关节功能，可以从生物力学角度简单的概括为：</p><ul><li><strong>灵活</strong>(<strong>M</strong>,Mobility)</li><li><strong>稳定</strong>(<strong>S</strong>,Stability)</li></ul><p>但看起来简单的两个词，其实意义非常。</p><h4 id="什么是灵活？"><a href="#什么是灵活？" class="headerlink" title="什么是灵活？"></a>什么是灵活？</h4><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws2.sinaimg.cn/large/006tKfTcgy1fhg2avap5sj30ao08rdg4.jpg"  alt></p><p>很多人的第一反应就是能自由的运动呗~然后部分专业人士可能会想到活动度。但是你的关节如果仅仅具备很好的活动度就能够胜任运动中的需求么？显然是不能的。所以灵活的意义远不止关节活动度，关节活动度仅仅是灵活的基础，而更重要的还有产力的能力。没错，这里的灵活既包括关节主被动活动范围，也包括产力的能力，比如产力的大小，产力的快慢等等。<br> 举个例子：小明的髋关节活动范围非常好，能竖叉能横叉，但是臀大肌并没有很好的力量，所以不能够支撑你的跑步与跳跃，所以此时的髋关节灵活性仍然是不足的，只不过这里强调的是力量的缺失。</p><h4 id="什么是稳定？"><a href="#什么是稳定？" class="headerlink" title="什么是稳定？"></a>什么是稳定？</h4><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws2.sinaimg.cn/large/006tKfTcgy1fhg2b1gendj30fa08t74f.jpg"  alt></p><p>稳定就是稳定呗<del>就是待着不动呗</del>就是牢固呗~灵活还能说出个关节活动度，而稳定的定义真的让很多人摸不到头脑，因为似乎“稳定”一词已经很好地形容了关节的功能表现。但是实际上我们仍然可以对其进行深究，并且这样做是有意义的，因为表现的不同直接影响训练的手段。</p><p>如果我们把“稳定”定义为是一种提供安全性的保护，那么我们就可以假想出两个现象：</p><ol><li>一个非常贵重的瓷器抱在手中，我不能把它摔碎，所以我抱着不动~</li><li>同样是这个非常贵重的瓷器抱在手中，我不能把它摔碎，但是我可以慢慢的把它放在地上。<br>同样是保护瓷器不被摔碎，但是却有两个表现，一个是hold住，另外一个是慢慢的放在地上，一个不动，一个动。所以我们人体关节的稳定也是如此，既包括保持身体姿态，关节位置的相对固定，也包括有控制的缓冲外力，退让做功。</li></ol><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws1.sinaimg.cn/large/006tKfTcgy1fhg2b6eo7uj30m80h477k.jpg"  alt></p><p>举个例子：我们的核心区域在运动中应该尽可能的保持姿态的稳定，所以是抱着瓷器不动；我们的膝关节在走路与跑步中从伸到屈，缓冲脚落地产生的冲击力，所以是抱着瓷器往下放。 </p><p>在了解了 SM (稳定和灵活)的意义之后，更重要的是明白：这两种并不会孤立的存在，而是相辅相成同时存在的，只不过在人体整体动力链中体现的侧重点不一样，在肢体的协同运动中扮演的角色不一样。比如对于核心区域来说，灵活恰是其稳定的基础，因为不同体位下脊柱的排列形式直接影响稳定的表现。</p><p>当 SM 代表了关节功能之后，在人体的整体运动结构中，不同的关节所凸显出来的功能是不同的，并且它们遵循一定的逻辑分布。</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws3.sinaimg.cn/large/006tKfTcgy1fhg2bewsh2j30hs0b0t8y.jpg"  alt></p><p>从下往上说：</p><ol><li><p>足弓——稳定</p><p> 第一个缓冲冲击力的关节，并且没有多大的关节活动度。</p></li><li><p>足踝——灵活</p><p> “足” “踝”形成了一个稳定与灵活兼备的整体，但是在运动中它是下肢蹬伸最后一个主动发力的关节，并且无时无刻不在调整着身体与地面之间的位置关系，所以在这里我们更强调它的灵活性。</p></li><li><p>膝关节——稳定</p><p> 强大的承重关节，且仅存在屈伸的动作（屈膝位的内外旋的意义是提供可控的缓冲空间，并非叫你主动旋转），更重要的是，无论走路、跑步、跳跃，膝关节都是非常重要的离心缓冲关节。</p></li><li><p>髋关节——灵活</p><p> 强大的发力关节，而且活动范围也非常广泛，它引领着下肢的动作产生。但是由于位置与功能的特殊，所以其稳定性也相当重要，直接可以影响核心的稳定结构，特别是在闭链状态下。</p></li><li><p>腰椎——稳定</p><p> 相对的绝对稳定体。所谓绝对，是因为腰椎所处的位置恰好为核心地带，这里的功能是维持姿态以及为上下肢的运动提供稳定基础，所以要“抱着缸不动”。而所谓相对，是因为不同的体位下腰椎的姿态是需要随之调整的，并不能以不变应万变。</p></li><li><p>胸椎——灵活</p><p> 胸椎的灵活性其实并不好，但是相比于腰椎来说就好太多了，特别是在旋转动作上。在旋转鞭打的动作模式中，胸椎是继下肢产力之后的第一个角速度放大的关节，其灵活程度直接影响了上肢的鞭打效果。当然，在更多的时候胸椎要参与承重，但即便承重，也是以其良好的灵活性为基础的，比如说手臂上举过头负重的动作。</p></li><li><p>颈椎——稳定</p><p> 虽然很灵活，但却需要很稳定！因为头部的位置变化会直接改变身体肌张力的大小分布，这个不仅可以让我们身体姿态发生变化，还会破坏掉本体感觉的准确性。当然，这也是猫在空中可以转体的原因，以及为什么我们打拳的时候不能回头。</p></li><li><p>肩胛胸关节——稳定</p><p> 这是一个很奇葩的关节，从动力链结构上看，它是稳定关节，但稳定的并不是它自己，而是肩关节。在实际运动中，肩胛胸关节和肩关节是联动运动的，而且前者为后者提供稳定性，是后者得以安全展现灵活的基础。但是这个“稳定”恰恰是通过肩胛胸关节本身的灵活性来展现的，比如手臂上举时的上回旋。</p></li><li><p>肩关节——灵活</p><p> 没的说，人体最灵活的关节，也是人体最不稳定的关节，其球窝关节的解剖结构已经说明了一切。</p></li><li><p>肘关节——稳定</p><p>结构上跟膝关节相对，但是实际上要比膝关节灵活的多。所以如果进化论成立的话，人类从四脚着地变成双脚着地的过程，使我们的下肢关节趋向于稳定，上肢关节趋向于灵活。而这正与 “开链”或者“闭链”的需求相适应。</p></li></ol><h3 id="开链-amp-闭链"><a href="#开链-amp-闭链" class="headerlink" title="开链&amp;闭链"></a>开链&amp;闭链</h3><p>我们的关节同时存在S与M，而在整体的运动中有不同的体现，甚至于同样是S或者M的上下肢关节却存在了显著的差别。那么在此我们需要引出一个新的概念：<strong>开链</strong> &amp; <strong>闭链</strong>。</p><h4 id="开链"><a href="#开链" class="headerlink" title="开链"></a>开链</h4><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws2.sinaimg.cn/large/006tKfTcgy1fhg2bltahoj30dg09h74k.jpg"  alt></p><p>开链，简单地说就是我们身体产生力量，改变了外界物体的运动状态。比如说哑铃二头弯举，投掷，摘苹果等动作都是开链动作。我们可以认为我们的身体在对抗趋于无穷小的阻力，那么我们就可以随意改变物体的运动状态，随便摆弄它，所以此时我们的肢体的灵活性就可以充分的发挥。比如我们的上肢就是以开链运动为主的，所以它整体表现出更好的灵活性。</p><h4 id="闭链"><a href="#闭链" class="headerlink" title="闭链"></a>闭链</h4><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws3.sinaimg.cn/large/006tKfTcgy1fhg2bq4z76j30fk0dp0tf.jpg"  alt></p><p>闭链，简单的说就是我们的身体产生力量，却没能推动外界的物体，反而改变了我们自身的运动状态。比如说跑步与深蹲，我们扒地，我们蹬地，并没有让地板产生位移，我们自己却向前或者向上运动了。所以我们可以认为闭链运动时，我们的身体在对抗趋于无穷大的阻力，我们根本不可能改变它，所以只能运动我们自己。而在面对这样无穷大的阻力的时候，我们需要将我们的关节摆在力学结构最优的位置上才能发挥我们自身的最大经济性和效率，而且在这个状态下，各个关节的位置直接影响了身体的整体姿态和状态，所以灵活性被抑制。我们的下肢，最擅长、做的最多的就是闭链运动，所以它更加的趋于稳定。</p><p>开链和闭链直接影响我们的训练适应，因为它们所表现的力学结构是不同的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>了解动力链并不是让我们<strong>装逼</strong>的，而是让我们更加了解人体的客观规律来指导训练的。</p><p>它是一个非常好的思考工具。比如我们在训练下肢力量的时候，我们就需要考虑髋关节灵活性对于下肢力量表现的影响，于是乎我们可能更加重点强化髋的产力能力。但是当考虑到屈髋动作时，也许实际中更多的是开链的屈髋，所以我们就能以此为依据来选择髂腰肌和股直肌的训练动作。</p><p>除此之外，每个关节本身的功能完整性是非常重要的，如果一个关节有功能缺陷，那么在整体运动中它就不能够尽到它的职责，所以一定会有另外一个或者几个关节来代偿它的功能，那么就相当于一个3人的团队，一个请假了，另外两个就得加班。如果一次两次没关系，它要是请了一年的产假，那么另外俩人可能会由于长期超负荷工作而积劳成疾。当然，对于公司来说我可以再雇人，但是我们的人体可没有能再多长一个关节之说。</p><p>所以其实很多跑步膝的问题恰是由于髋和踝的功能缺陷而导致的。</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws3.sinaimg.cn/large/006tKfTcgy1fhg2buv4nwj30ia0a2dfx.jpg"  alt></p><p><strong>最后我要再次强调</strong>：任何一个关节，稳定与灵活同时存在，只不过体现的程度和侧重不同。在动力链中，灵活的关节不代表没有稳定，更不代表稳定不重要；稳定的关节也需要灵活，而且灵活可能是稳定的基础。</p><p>了解了动力链，你会更懂运动中的人体，也许你有了思考问题的方向，但仍然缺少方法，所以你还需要具备<a href="http://qiubaiying.github.io/2017/07/10/%E4%BD%93%E8%83%BD%E8%AE%AD%E7%BB%83%E7%90%86%E8%AE%BA-%E4%B9%8B%E5%8A%9F%E8%83%BD%E6%80%A7/" target="_blank" rel="external nofollow noopener noreferrer">「功能性」</a>的思维方式。</p><blockquote><p>转自 <a href="https://zhuanlan.zhihu.com/p/20774747" target="_blank" rel="external nofollow noopener noreferrer">《体能训练之动力链》</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生活 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「体能训练理论」之功能性</title>
      <link href="/2017-07-10-%E3%80%8C%E4%BD%93%E8%83%BD%E8%AE%AD%E7%BB%83%E7%90%86%E8%AE%BA%E3%80%8D%E4%B9%8B%E5%8A%9F%E8%83%BD%E6%80%A7/"/>
      <url>/2017-07-10-%E3%80%8C%E4%BD%93%E8%83%BD%E8%AE%AD%E7%BB%83%E7%90%86%E8%AE%BA%E3%80%8D%E4%B9%8B%E5%8A%9F%E8%83%BD%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>体能训练是一种开源的程序它所依仗的并不是固有的方法手段，而是能够贯穿始终的逻辑，它是一种指导实践的思维方式，我们管它叫“体能思路”。</p><p>体能思路有两个方向，一个是原点，一个是过程。所谓原点我们认为是人体的本质属性，比如之前我们分享的五大运动素质以及动力链理论。所谓过程是我们分析问题实现目的的思考方向以及逻辑，它主要体现在接下来要跟大家分享的功能性原则和金字塔。</p><p>今天先来说功能性原则。</p><h2 id="功能性"><a href="#功能性" class="headerlink" title="功能性"></a>功能性</h2><p>我们所说的功能性是一种解决问题的思维方式，而功能性训练则定义了一种多关节参与，多平面运动的复杂练习。功能性训练是具体的，比较好理解，我就不赘述了，也不评价其优劣，因为在“功能性”的思维方式下，只存在目标之下的合适与否。</p><h3 id="什么是功能性？"><a href="#什么是功能性？" class="headerlink" title="什么是功能性？"></a>什么是功能性？</h3><p>我们把它定义为目标导向下的效率，所以它是一种程度的体现。如果一个练习与目标的相关性强，那么我们认为它具备较强的功能意义；而如果一个练习与它的目标背道而驰，那么我们就认为它缺乏功能意义。</p><p>举个例子，对于偏瘫患者来说，一个手指的屈伸就已经具备非常强的功能意义了，而对于一个马拉松爱好者来说，静蹲的价值可能并不是想象中那么高。</p><p>一般来说，在思考功能性问题的时候我习惯从以下三个方面入手：<strong>肌肉的生理适应</strong> 、<strong>动作模式</strong> 和 <strong>专项需求</strong>。</p><h4 id="1-肌肉的生理适应"><a href="#1-肌肉的生理适应" class="headerlink" title="1. 肌肉的生理适应"></a>1. 肌肉的生理适应</h4><p>其实练肌肉谁都会，是一个相对好入手的技能，但是当你给这个行为赋予体能训练使命的时候就需要思考一些问题，比如说你现在练习所发展的东东真的是你实际运动中所需要的东东么？</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws1.sinaimg.cn/large/006tKfTcgy1fhg24pm22dj30e709474v.jpg"  alt></p><p>我们都知道肌肉的生理收缩模式可以简单的分为向心收缩，离心收缩和静力收缩。现在的研究表明，这三种收缩模式的练习所产生的适应性提高存在显著的特异性。也就是说我向心练习所发展的能力只在向心运动中表现最好，在离心和静力中都不佳。同样，离心收缩也只能获得最好的离心能力收益。而静力就更变态，其训练最佳效果仅仅体现在所锻炼的关节角度下，换一个角度能够迁移的效果有可能都不到一半儿。这样看来，你的训练是不是并没有达到你想要的效果呢？</p><p>举个例子：</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws1.sinaimg.cn/large/006tKfTcgy1fhg251pmatj30go0b5q5d.jpg"  alt></p><p>为什么静蹲对于跑步爱好者来说可能并没有那么理想？因为膝关节股四头肌在跑步中以离心缓冲为主，而且角度在伸膝末端的30°左右，而静蹲却是在屈曲90°左右的角度下呆着不动……着不动……不动……动……</p><p>除此之外，需要考虑的问题还很多，比如说发力模式，是加速？减速？还是匀速？再比如关节活动角度上发力点的位置，是伸展末端发力？屈曲极限发力？还是在屈伸过程中的某一点发力？阻力加在哪里，就会在哪里产生最好的适应，那么功能的意义就体现在这里。</p><h4 id="2-动作模式"><a href="#2-动作模式" class="headerlink" title="2. 动作模式"></a>2. 动作模式</h4><p>动作模式是动作程序的体现，而基础动作模式是诸多复杂动作模式共性的抽象体现，并且基础动作模式一定是符合解剖结构和生物力学特点的，说白了也就是我们人体被设计来应该完成的动作。</p><p>如果说大多数运动都可以认为是基础动作模式的升级与排列组合，同时基础动作模式本身又能衍生出来很多训练动作，那么选择和实际运动相对应的练习就是另一个功能性的体现了。</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws2.sinaimg.cn/large/006tKfTcgy1fhg25l7ep2j30g609o0ue.jpg"  alt></p><p>比如说发展起跳能力，因为跳是蹲的升级，所以我一定首选深蹲练习；再比如说跑步，存在大量的下肢摆动与支撑的交替，摆动可以认为是下肢开链屈髋与蹬伸，而支撑可以认为是下肢单腿蹲的一瞬间，那么我会选择箱式单腿蹲，保加利亚蹲，悬垂屈髋等等；再再比如，拳击是基于“旋转”加“上肢推”加“单腿蹲”的动作模式，那么我就要练习剪蹲…旋转…单臂…推举…吗？</p><p>其实动作模式的选择要结合动力链一起去思考，这里除了要思考开链还是闭链之外，还要考虑动力链的完整性以及发力的顺序或者说是力学结构。说到上肢推的动作模式，水平推的话我相信很多人都会想到卧推和俯卧撑，那么这两个动作的功能性如何评价呢？</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws2.sinaimg.cn/large/006tKfTcgy1fhg26a2ve0j30go0ce76n.jpg"  alt></p><p><strong>卧推</strong>，一个挺奇葩的动作，奇葩在哪呢？来，咱们数数卧推的主动关节都有哪些：肩关节，肘关节。那么我们上肢链在上肢推动作模式下参与的关节都有哪些呢？肩关节，肘关节！就这些么？再想想！其实你还疏漏了一个非常重要的关节——<strong>肩胛胸关节</strong>！几乎所有上肢的动作都以肩胛胸关节的运动为基础，而卧推却并没有，特别是标准的卧推~</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws4.sinaimg.cn/large/006tKfTcgy1fhg26h6oejj30go09lwgj.jpg"  alt></p><p><strong>俯卧撑</strong>，虽然肩胛胸，肩关节，肘关节全面参与到运动中去，但不巧的是它是一个闭链运动，而实际运动中我们的上肢会以开链为主！呵呵~</p><p>别着急，认真你就输了！上面两段其实是个伪命题，我这么做主要是想通过这个平易近人的例子来帮助大家掌握的分析问题的思路！如果你需要发展上肢最大力量表现，那么显然卧推是你的首选。而如果你要优化上肢的力学结构，特别是水平推的发力顺序，那么俯卧撑是你首选。再如果你要提高上肢的延展性以及伴随旋转的加速能力，那么单臂水平推的练习给你的帮助最大！</p><p>所以，选择什么，看目标喽~</p><h4 id="3-专项需求"><a href="#3-专项需求" class="headerlink" title="3. 专项需求"></a>3. 专项需求</h4><p>其实这个非常好理解，也是功能性原则的根本目的，但是为了和上面两个方向区分开，这里主要针对的是不同的运动素质需求。</p><p>Q：对一个英超的后卫进行长距离高强度的游泳练习是否具备功能性意义？！</p><p>A：具备！</p><p>Q：为什么？</p><p>A：因为他喜欢游泳，这个可以让他心情愉悦然后更好的训练和比赛！</p><p>咳咳！当然，这样的答案是合情合理的！但是我们不妨换一个角度去分析。</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws2.sinaimg.cn/large/006tKfTcgy1fhg26rdi6vj30go0b4goo.jpg"  alt></p><p>英超，几乎是足球联赛中对抗最强的，他们的后卫每场比赛动不动就跑个8千1万的，而这8千1万真心不是慢慢悠悠颠儿下来的，而是各种加速减速变向拼抢，所以其强度非常之大。那么这就需要很好的心肺系统功能，一方面体现在有氧与无氧耐力上，另一方面呼吸器官的机能上。游泳练习，不仅可以提高有氧以及无氧耐力，其水环境还可以给胸扩张带来阻力，直接锻炼了呼吸肌的收缩能力。另外，水环境真的能够给人们带来愉悦的感觉，特别是水流水压给肌肉和筋膜的按摩效果，真的是一举两得的“功能性”训练。</p><p>还有，你以为篮球运动员的拳击练习真的只是给枯燥乏味的体能训练增加一点乐趣么？并不是！</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws2.sinaimg.cn/large/006tKfTcgy1fhg276m81pj31h50rgtbv.jpg"  alt></p><p><strong>1. 拳击可以在发生场内冲突的时候很好地保护自己；</strong></p><p><strong>2. 拳击运动可以强化旋转动作模式下的速度、稳定、和准确性；</strong></p><p><strong>3. 拳击是手脚高度协调的运动，对于发展手脚搭配的动作灵敏有神奇的效果。</strong></p><p>而这些不就是一名篮球运动员所需要的么？！</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>所以，功能性原则，解决的是“<strong>为什么练</strong>（for！not why）以及 <strong>练什么</strong>”的问题！</p><p>如果我们是简单活动活动身体那就算了，但如果我们要进行一个有针对性的体能训练，那么请琢磨琢磨你选择的动作是否合理，是否能够满足你的专项需求！</p><p>所以，招财猫式弹力带抗阻外旋真的是练习肩袖首推的动作么？</p><p>所以，蚌式练习和dirty dog真的是发展髋外旋外展能力最好的练习么？</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://ws2.sinaimg.cn/large/006tKfTcgy1fhg28jvnhqj30dw099q3z.jpg"  alt></p><p>所以，仰卧卷腹发展出来的腹直肌是好看呢？还是好用呢？</p><p>所以，我们真的要来一次大清洗，摒弃掉我们以前那些练习么？</p><p>当然不要！每一个动作都有它存在的意义，都有它的价值所在！有可能这个动作和你要发展的能力不直接相关，但是它可能是你进行“功能性”训练的基础，你不得不去做它！</p><p>所以，训练的逻辑很重要！</p><blockquote><p>转自<a href="https://zhuanlan.zhihu.com/p/20786373" target="_blank" rel="external nofollow noopener noreferrer">《体能训练之功能性》</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生活 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文件目录树状(tree)显示</title>
      <link href="/2017-3-07-%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E6%A0%91%E7%8A%B6(tree)%E6%98%BE%E7%A4%BA/"/>
      <url>/2017-3-07-%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E6%A0%91%E7%8A%B6(tree)%E6%98%BE%E7%A4%BA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>使用 <strong>tree</strong> 在终端显示树状文件结构</p></blockquote><p><img src="/img/loading.gif" class="lazyload" data-src="https://ww4.sinaimg.cn/large/006tKfTcgy1fdhotefcb5j315s0ugjwk.jpg"  alt></p><h4 id="安装-tree"><a href="#安装-tree" class="headerlink" title="安装 tree"></a>安装 tree</h4><p>使用 <strong>brew</strong> 进行安装</p><pre><code>$ brew install tree</code></pre><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><ul><li><p>直接使用 <code>tree</code> 命令，会在当前文件目录下，递归输出所有文件层级</p><pre><code>$ tree</code></pre></li><li><p>限制层级</p><pre><code>$ tree -L 2</code></pre></li><li><p>指定当前目录下的某个文件夹</p><pre><code>$ tree Desktop</code></pre></li></ul><h4 id="导出文件"><a href="#导出文件" class="headerlink" title="导出文件"></a>导出文件</h4><p>用<code>&gt; 文件名.格式</code> 的形式导出</p><pre><code>$ tree -L 1 &gt; tree.md</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 效率 </tag>
            
            <tag> 开发技巧 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用 .gitignore 忽略 Git 仓库中的文件</title>
      <link href="/2017-02-22-%E4%BD%BF%E7%94%A8-.gitignore-%E5%BF%BD%E7%95%A5-git-%E4%BB%93%E5%BA%93%E4%B8%AD%E7%9A%84%E6%96%87%E4%BB%B6/"/>
      <url>/2017-02-22-%E4%BD%BF%E7%94%A8-.gitignore-%E5%BF%BD%E7%95%A5-git-%E4%BB%93%E5%BA%93%E4%B8%AD%E7%9A%84%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>使用 <code>.gitignore</code> 文件忽略指定文件</p></blockquote><h2 id="gitignore"><a href="#gitignore" class="headerlink" title=".gitignore"></a>.gitignore</h2><p>在Git中，很多时候你只想将代码提交到仓库，而不是将当前文件目录下的文件全部提交到Git仓库中，例如在MacOS系统下面的<code>.DS_Store</code>文件，或者是Xocde的操作记录，又或者是pod库的中一大串的源代码。这种情况下使用<code>.gitignore</code>就能够在Git提交时自动忽略掉这些文件。</p><h2 id="忽略的格式"><a href="#忽略的格式" class="headerlink" title="忽略的格式"></a>忽略的格式</h2><ul><li><code>#</code> :此为注释 – 将被 Git 忽略</li><li><code>*.a</code> :忽略所有 <code>.a</code> 结尾的文件</li><li><code>!lib.a</code> : 不忽略 <code>lib.a</code> 文件</li><li><code>/TODO</code> :仅仅忽略项目根目录下的 <code>TODO</code> 文件,不包括 <code>subdir/TODO</code></li><li><code>build/</code> : 忽略 <code>build/</code> 目录下的所有文件</li><li><code>doc/*.txt</code> : 会忽略 <code>doc/notes.txt</code> 但不包括 <code>doc/server/arch.txt</code></li></ul><h2 id="创建方法"><a href="#创建方法" class="headerlink" title="创建方法"></a>创建方法</h2><h4 id="从-github-上获取"><a href="#从-github-上获取" class="headerlink" title="从 github 上获取"></a>从 <a href="https://github.com/github/gitignore.git" target="_blank" rel="external nofollow noopener noreferrer">github</a> 上获取</h4><p>github上整理了一些常用需要的项目中需要忽略的文件配置，根据需要进行获取</p><pre><code>https://github.com/github/gitignore.git</code></pre><p>与 Xcode 相关的三个文件</p><ul><li>Xcode.gitignore</li><li>Objective-C.gitignore</li><li>Swift.gitignore</li></ul><p><code>Xcode.gitignore</code>忽略 <code>Xcode</code> 配置信息，如操作记录，默认打开窗口等</p><p>其他两个在 <code>Xcode.gitignore</code> 基础上针对不同的语言进行忽略</p><p>将这些文件重写命名为 <code>.gittignore</code></p><pre><code>$ mv Swift.gitignore .gittignore</code></pre><h4 id="通过-gitignore-io-创建（推荐）"><a href="#通过-gitignore-io-创建（推荐）" class="headerlink" title="通过 gitignore.io 创建（推荐）"></a>通过 <a href="https://www.gitignore.io/" target="_blank" rel="external nofollow noopener noreferrer">gitignore.io</a> 创建（推荐）</h4><h6 id="先自定义终端命令："><a href="#先自定义终端命令：" class="headerlink" title="先自定义终端命令："></a>先自定义终端命令：</h6><p>macOS下默认是<code>\#!/bin/bash</code>：</p><pre><code>$ echo &quot;function gi() { curl -L -s https://www.gitignore.io/api/\$@ ;}&quot; &gt;&gt; ~/.bash_profile &amp;&amp; source ~/.bash_profile</code></pre><p>如果是 <code>#!/bin/zsh</code></p><pre><code>$ echo &quot;function gi() { curl -L -s https://www.gitignore.io/api/\$@ ;}&quot; &gt;&gt; ~/.zshrc &amp;&amp; source ~/.zshrc</code></pre><h6 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h6><p>在当前终端目录下</p><pre><code>$ gi swift &gt; .gitignore</code></pre><p>就会针对 Swifit 类型的工程创建 <code>.gitignore</code> 文件。</p>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 终端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git指令整理</title>
      <link href="/2017-02-15-Git%E6%8C%87%E4%BB%A4%E6%95%B4%E7%90%86/"/>
      <url>/2017-02-15-Git%E6%8C%87%E4%BB%A4%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>随便整理的一些自用的Git指令</p></blockquote><h1 id="GitHub创建仓库提示代码"><a href="#GitHub创建仓库提示代码" class="headerlink" title="GitHub创建仓库提示代码"></a>GitHub创建仓库提示代码</h1><pre><code>echo &quot;# 项目名&quot; &gt;&gt; README.mdgit initgit add README.mdgit commit -m &quot;first commit&quot;git remote add origin git@github.com:FrederickHou/项目名.gitgit push -u origin master</code></pre><p>若仓库存在直接push</p><pre><code>git remote add origin git@github.com:FrederickHou/test.gitgit push -u origin master</code></pre><h1 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h1><h4 id="创建仓库（初始化）"><a href="#创建仓库（初始化）" class="headerlink" title="创建仓库（初始化）"></a>创建仓库（初始化）</h4><pre><code>在当前指定目录下创建git init新建一个仓库目录git init [project-name]克隆一个远程项目git clone [url]</code></pre><h4 id="添加文件到缓存区"><a href="#添加文件到缓存区" class="headerlink" title="添加文件到缓存区"></a>添加文件到缓存区</h4><pre><code>添加所有变化的文件 git add .添加名称指定文件git add text.txt</code></pre><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><pre><code>设置提交代码时的用户信息git config [--global] user.name &quot;[name]&quot;git config [--global] user.email &quot;[email address]&quot;</code></pre><h4 id="提交"><a href="#提交" class="headerlink" title="提交"></a>提交</h4><pre><code>提交暂存区到仓库区git commit -m &quot;msg&quot;# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a# 提交时显示所有diff信息$ git commit -v# 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ...</code></pre><h4 id="远程同步"><a href="#远程同步" class="headerlink" title="远程同步"></a>远程同步</h4><pre><code># 下载远程仓库的所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程仓库的信息$ git remote show [remote]# 增加一个新的远程仓库，并命名$ git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch]# 上传本地指定分支到远程仓库$ git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force# 推送所有分支到远程仓库$ git push [remote] --all</code></pre><h4 id="分支"><a href="#分支" class="headerlink" title="分支"></a>分支</h4><pre><code># 列出所有本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出所有本地分支和远程分支$ git branch -a# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch]</code></pre><h4 id="标签Tags"><a href="#标签Tags" class="headerlink" title="标签Tags"></a>标签Tags</h4><pre><code>添加标签 在当前commitgit tag -a v1.0 -m &apos;xxx&apos; 添加标签 在指定commitgit tag v1.0 [commit]查看git tag删除git tag -d V1.0删除远程taggit push origin :refs/tags/[tagName]推送git push origin --tags拉取git fetch origin tag V1.0新建一个分支，指向某个taggit checkout -b [branch] [tag]</code></pre><h4 id="查看信息"><a href="#查看信息" class="headerlink" title="查看信息"></a>查看信息</h4><pre><code># 显示有变更的文件$ git status# 显示当前分支的版本历史$ git log# 显示commit历史，以及每次commit发生变更的文件$ git log --stat# 搜索提交历史，根据关键词$ git log -S [keyword]# 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s# 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件$ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file]# 显示指定文件相关的每一次diff$ git log -p [file]# 显示过去5次提交$ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序$ git shortlog -sn# 显示指定文件是什么人在什么时间修改过$ git blame [file]# 显示暂存区和工作区的差异$ git diff# 显示暂存区和上一个commit的差异$ git diff --cached [file]# 显示工作区与当前分支最新commit之间的差异$ git diff HEAD# 显示两次提交之间的差异$ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码$ git diff --shortstat &quot;@{0 day ago}&quot;# 显示某次提交的元数据和内容变化$ git show [commit]# 显示某次提交发生变化的文件$ git show --name-only [commit]# 显示某次提交时，某个文件的内容$ git show [commit]:[filename]# 显示当前分支的最近几次提交$ git reflog</code></pre><h4 id="撤销"><a href="#撤销" class="headerlink" title="撤销"></a>撤销</h4><pre><code># 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit]# 暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop</code></pre><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><pre><code># 生成一个可供发布的压缩包$ git archives</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac 文件的隐藏与显示</title>
      <link href="/2017-02-22-Mac-%E6%96%87%E4%BB%B6%E7%9A%84%E9%9A%90%E8%97%8F%E4%B8%8E%E6%98%BE%E7%A4%BA/"/>
      <url>/2017-02-22-Mac-%E6%96%87%E4%BB%B6%E7%9A%84%E9%9A%90%E8%97%8F%E4%B8%8E%E6%98%BE%E7%A4%BA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>让 Finder 显示隐藏文件和文件夹</p></blockquote><h1 id="基本"><a href="#基本" class="headerlink" title="基本"></a>基本</h1><h4 id="显示"><a href="#显示" class="headerlink" title="显示"></a>显示</h4><pre><code>$ defaults write com.apple.finder AppleShowAllFiles -boolean true ; killall Finder</code></pre><h4 id="隐藏"><a href="#隐藏" class="headerlink" title="隐藏"></a>隐藏</h4><pre><code>$ defaults write com.apple.finder AppleShowAllFiles -boolean false ; killall Finder</code></pre><h1 id="进阶"><a href="#进阶" class="headerlink" title="进阶"></a>进阶</h1><p>创建终端快捷命令</p><p>在 <strong>zsh</strong> shell 下，创建快捷命令</p><h4 id="创建显示命令-fd-（fileDisplay）"><a href="#创建显示命令-fd-（fileDisplay）" class="headerlink" title="创建显示命令 fd （fileDisplay）"></a>创建显示命令 fd （fileDisplay）</h4><pre><code>$ echo &quot;alias fd=&apos;defaults write com.apple.finder AppleShowAllFiles -boolean true ; killall Finder&apos;&quot;&gt;&gt; ~/.zshrc &amp;&amp; source ~/.zshrc</code></pre><h4 id="创建隐藏命令-fh（fileHide）"><a href="#创建隐藏命令-fh（fileHide）" class="headerlink" title="创建隐藏命令 fh（fileHide）"></a>创建隐藏命令 fh（fileHide）</h4><pre><code>$ echo &quot;alias fd=&apos;defaults write com.apple.finder AppleShowAllFiles -boolean false ; killall Finder&apos;&quot;&gt;&gt; ~/.zshrc &amp;&amp; source ~/.zshrc</code></pre><p>使用方法</p><p>显示隐藏文件</p><pre><code>$ fd</code></pre><p>隐藏文件</p><pre><code>$ fh</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 终端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git 代码回滚</title>
      <link href="/2017-02-16-Git-%E4%BB%A3%E7%A0%81%E5%9B%9E%E6%BB%9A/"/>
      <url>/2017-02-16-Git-%E4%BB%A3%E7%A0%81%E5%9B%9E%E6%BB%9A/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>并不适合阅读的个人文档。</p></blockquote><h1 id="git-revert-和-git-reset-的区别"><a href="#git-revert-和-git-reset-的区别" class="headerlink" title="git revert 和 git reset 的区别"></a><strong>git revert</strong> 和 <strong>git reset</strong> 的区别</h1><p> 先看图：</p><p><img src="/img/loading.gif" class="lazyload" data-src="https://ww3.sinaimg.cn/large/006tNbRwgy1fcr9tu6vdjj30t30ez0y8.jpg"  alt></p><p><strong>sourceTree</strong> 中 <strong>revert</strong> 译为<strong><code>提交回滚</code></strong>，作用为忽略你指定的版本，然后提交一个新的版本。新的版本中已近删除了你所指定的版本。</p><p><strong>reset</strong> 为 <strong>重置到这次提交</strong>，将内容重置到指定的版本。<code>git reset</code> 命令后面是需要加2种参数的：<code>–-hard</code> 和 <code>–-soft</code>。这条命令默认情况下是 <code>-–soft</code>。</p><p>执行上述命令时，这该条commit号之 后（时间作为参考点）的所有commit的修改都会退回到git缓冲区中。使用<code>git status</code> 命令可以在缓冲区中看到这些修改。而如果加上<code>-–hard</code>参数，则缓冲区中不会存储这些修改，git会直接丢弃这部分内容。可以使用 <code>git push origin HEAD --force</code> 强制将分区内容推送到远程服务器。</p><h4 id="代码回退"><a href="#代码回退" class="headerlink" title="代码回退"></a>代码回退</h4><p>默认参数 <code>-soft</code>,所有commit的修改都会退回到git缓冲区<br>参数<code>--hard</code>，所有commit的修改直接丢弃</p><pre><code>$ git reset --hard HEAD^         回退到上个版本$ git reset --hard commit_id    退到/进到 指定commit_id</code></pre><p>推送到远程    </p><pre><code>$ git push origin HEAD --force</code></pre><h4 id="可以吃的后悔药-gt-版本穿梭"><a href="#可以吃的后悔药-gt-版本穿梭" class="headerlink" title="可以吃的后悔药-&gt;版本穿梭"></a>可以吃的后悔药-&gt;版本穿梭</h4><p>当你回滚之后，又后悔了，想恢复到新的版本怎么办？</p><p>用<code>git reflog</code>打印你记录你的每一次操作记录</p><pre><code>$ git reflog输出：c7edbfe HEAD@{0}: reset: moving to c7edbfefab1bdbef6cb60d2a7bb97aa80f022687470e9c2 HEAD@{1}: reset: moving to 470e9c2b45959e HEAD@{2}: revert: Revert &quot;add img&quot;470e9c2 HEAD@{3}: reset: moving to 470e9c22c26183 HEAD@{4}: reset: moving to 2c261830f67bb7 HEAD@{5}: revert: Revert &quot;add img&quot;</code></pre><p>找到你操作的id如：<code>b45959e</code>，就可以回退到这个版本</p><pre><code>$ git reset --hard b45959e</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 终端 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
